services:
  speaches:
    image: ghcr.io/speaches-ai/speaches:latest-cpu
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - ./hf-cache:/home/ubuntu/.cache/huggingface/hub
    environment:
      # Keep model loaded in memory forever (zero-latency transcription)
      - STT_MODEL_TTL=-1
      # CPU inference configuration
      - WHISPER__INFERENCE_DEVICE=cpu
      - WHISPER__COMPUTE_TYPE=int8
      - WHISPER__CPU_THREADS=8
      - WHISPER__USE_BATCHED_MODE=true
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

