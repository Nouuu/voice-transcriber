# Quick Actions Feature Specification

**Feature**: Dynamic Quick Actions in System Tray Menu
**Created**: 2025-10-21
**Status**: üìã Planning / Future Enhancement
**Priority**: Medium
**Estimated Effort**: 4-6 hours

---

## üéØ Motivation

Les utilisateurs doivent actuellement √©diter `config.json` et recharger la configuration pour changer des param√®tres courants. Cette feature permettrait de **toggle des fonctionnalit√©s √† la vol√©e** directement depuis le menu du system tray, sans √©dition de fichier.

### Use Cases Principaux

1. **Toggle Formatter** : Activer/d√©sactiver le formatage GPT rapidement
2. **Switch Formatter Personalities** : Changer entre diff√©rents prompts de formatage pr√©d√©finis
3. **Switch Backend** : Basculer entre OpenAI et Ollama pour le formatage
4. **Toggle Benchmark Mode** : Comparer les performances et qualit√© des backends

---

## ‚ú® Features Propos√©es

### 1. Toggle Formatter (MVP) ‚≠ê

**Description** : Activer/d√©sactiver le formatage sans √©diter la config

**Menu Item** :
```
üé§ Voice Transcriber
‚îú‚îÄ‚îÄ üéôÔ∏è Start Recording
‚îú‚îÄ‚îÄ ‚èπÔ∏è Stop Recording
‚îú‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îú‚îÄ‚îÄ ‚úçÔ∏è Formatter: ON/OFF  ‚Üê NOUVEAU (checkable)
‚îú‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îú‚îÄ‚îÄ ‚öôÔ∏è Open Config
‚îú‚îÄ‚îÄ üîÑ Reload Config
‚îî‚îÄ‚îÄ ‚ùå Exit
```

**Comportement** :
- Menu item avec checkbox (‚úì = ON, ‚òê = OFF)
- Toggle instantan√© sans reload de config
- √âtat sauvegard√© en m√©moire (pas dans le fichier config)
- Ic√¥ne diff√©rente selon l'√©tat : ‚úçÔ∏è (ON) / ‚úèÔ∏è (OFF)

**Avantages** :
- Utile pour tests rapides
- √âconomie d'API calls OpenAI GPT
- Feedback imm√©diat

### 2. Formatter Personalities (Phase 2) üé≠

**Description** : Menu submenu avec diff√©rents prompts de formatage pr√©d√©finis

**Menu Structure** :
```
üé§ Voice Transcriber
‚îú‚îÄ‚îÄ üéôÔ∏è Start Recording
‚îú‚îÄ‚îÄ ‚èπÔ∏è Stop Recording
‚îú‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îú‚îÄ‚îÄ ‚úçÔ∏è Formatter: ON
‚îú‚îÄ‚îÄ‚îÄ‚îÄ üé≠ Personality  ‚Üê NOUVEAU (submenu)
‚îÇ     ‚îú‚îÄ‚îÄ ‚úì Default (Minimal formatting)
‚îÇ     ‚îú‚îÄ‚îÄ ‚òê Professional (Business style)
‚îÇ     ‚îú‚îÄ‚îÄ ‚òê Technical (Code-friendly)
‚îÇ     ‚îú‚îÄ‚îÄ ‚òê Creative (Expressive style)
‚îÇ     ‚îî‚îÄ‚îÄ ‚òê Custom (from config.json)
‚îú‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îú‚îÄ‚îÄ ‚öôÔ∏è Open Config
‚îú‚îÄ‚îÄ üîÑ Reload Config
‚îî‚îÄ‚îÄ ‚ùå Exit
```

**Prompts Pr√©d√©finis** :

```json
{
  "formatterPersonalities": {
    "default": {
      "name": "Default",
      "description": "Minimal formatting - Fix grammar only",
      "prompt": "Fix grammar and punctuation. Keep the original style and tone."
    },
    "professional": {
      "name": "Professional",
      "description": "Business communication style",
      "prompt": "Format as professional business communication. Use formal tone, clear structure, proper punctuation. Suitable for emails and reports."
    },
    "technical": {
      "name": "Technical",
      "description": "Technical documentation style",
      "prompt": "Format for technical documentation. Preserve technical terms, code references, and precision. Use clear, concise language."
    },
    "creative": {
      "name": "Creative",
      "description": "Expressive and natural style",
      "prompt": "Format naturally with expressive language. Maintain personality and tone. Make it engaging and conversational."
    },
    "custom": {
      "name": "Custom",
      "description": "User-defined prompt from config",
      "prompt": null  // Uses formattingPrompt from config.json
    }
  }
}
```

**Comportement** :
- Selection radio-style (un seul actif √† la fois)
- Changement instantan√© du prompt de formatage
- Sauvegarde en m√©moire (pas dans config.json)
- Option "Custom" utilise le `formattingPrompt` du fichier config

### 3. Backend Selector (Phase 3) üîÑ

**Description** : Switch rapide entre OpenAI et Ollama pour le formatage

**Menu Item** :
```
üé§ Voice Transcriber
‚îú‚îÄ‚îÄ üéôÔ∏è Start Recording
‚îú‚îÄ‚îÄ ‚èπÔ∏è Stop Recording
‚îú‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îú‚îÄ‚îÄ ‚úçÔ∏è Formatter: ON
‚îú‚îÄ‚îÄ‚îÄ‚îÄ üé≠ Personality: Professional
‚îú‚îÄ‚îÄ‚îÄ‚îÄ ü§ñ Backend
‚îÇ     ‚îú‚îÄ‚îÄ ‚úì OpenAI GPT
‚îÇ     ‚îî‚îÄ‚îÄ ‚òê Ollama LLM (if available)
‚îú‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îú‚îÄ‚îÄ ‚öôÔ∏è Open Config
‚îú‚îÄ‚îÄ üîÑ Reload Config
‚îî‚îÄ‚îÄ ‚ùå Exit
```

**Comportement** :
- D√©tection automatique si Ollama est disponible
- Si Ollama indisponible, griser l'option
- Changement instantan√© du backend de formatage
- Fallback sur OpenAI si Ollama fail

### 4. Toggle Benchmark Mode (Phase 4) üìä

**Description** : Activer le mode benchmark pour comparer les backends c√¥te √† c√¥te

**Menu Item** :
```
üé§ Voice Transcriber
‚îú‚îÄ‚îÄ üéôÔ∏è Start Recording
‚îú‚îÄ‚îÄ ‚èπÔ∏è Stop Recording
‚îú‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îú‚îÄ‚îÄ ‚úçÔ∏è Formatter: ON
‚îú‚îÄ‚îÄ‚îÄ‚îÄ üé≠ Personality: Professional
‚îú‚îÄ‚îÄ‚îÄ‚îÄ ü§ñ Backend: OpenAI GPT
‚îú‚îÄ‚îÄ‚îÄ‚îÄ üìä Benchmark Mode: OFF  ‚Üê NOUVEAU (checkable)
‚îú‚îÄ‚îÄ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îú‚îÄ‚îÄ ‚öôÔ∏è Open Config
‚îú‚îÄ‚îÄ üîÑ Reload Config
‚îî‚îÄ‚îÄ ‚ùå Exit
```

**Comportement** :
- Quand activ√© : ex√©cute TOUS les backends disponibles en parall√®le
- Copie le r√©sultat du backend principal dans le clipboard
- Affiche une notification comparative avec :
  - Temps de r√©ponse de chaque backend
  - Taille des r√©sultats (caract√®res)
  - Backend le plus rapide
- Log d√©taill√© dans la console pour analyse

**Exemple de notification** :
```
üèÅ Benchmark Results (3.2s total):
‚úÖ OpenAI GPT: 1.8s - 145 chars
‚úÖ Ollama (tinyllama): 2.1s - 142 chars
‚≠ê Fastest: OpenAI GPT
üìã Copied: OpenAI GPT result
```

**Avantages** :
- Compare qualit√© et vitesse des backends
- Aide √† choisir le meilleur backend pour son usage
- Utile pour tester de nouveaux mod√®les Ollama
- Donn√©es objectives pour optimiser la config

---

## üèóÔ∏è Architecture Technique

### Architecture Globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Audio Input    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Speaches (Whisper)      ‚îÇ  ‚Üê Transcription uniquement
    ‚îÇ faster-whisper-base     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Raw Transcription
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                 ‚îÇ                  ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ OpenAI    ‚îÇ   ‚îÇ   Ollama     ‚îÇ   ‚îÇ Pas de       ‚îÇ
    ‚îÇ GPT-3.5   ‚îÇ   ‚îÇ  TinyLlama   ‚îÇ   ‚îÇ formatage    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                 ‚îÇ                  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                      Formatted Text
                           ‚ñº
                       Clipboard
```

**S√©paration claire** :
- **Speaches** = Backend de transcription Whisper (d√©j√† impl√©ment√©)
- **OpenAI** = Backend de formatage LLM (d√©j√† impl√©ment√©)
- **Ollama** = Backend de formatage LLM local (nouveau)

### √âtat en M√©moire (Runtime State)

```typescript
interface RuntimeState {
  formatterEnabled: boolean;        // Toggle ON/OFF
  formatterPersonality: string;     // "default" | "professional" | ...
  formatterBackend: "openai" | "ollama";  // Backend de FORMATAGE uniquement
  benchmarkMode: boolean;           // Toggle benchmark mode
}
```

**Principe** :
- √âtat runtime s√©par√© de la config fichier
- Priorit√© : Runtime State > config.json
- Pas de sauvegarde automatique (reset au red√©marrage)
- Option future : "Save as default" pour persister dans config.json


---

## ü§ñ Ollama LLM pour le Formatage Local

### Pourquoi Ollama ?

**Ollama** est l'outil de r√©f√©rence pour ex√©cuter des LLM localement :
- ‚úÖ Simple √† installer (`curl https://ollama.ai/install.sh | sh`)
- ‚úÖ API compatible OpenAI (`/v1/chat/completions`)
- ‚úÖ Gestion automatique des mod√®les
- ‚úÖ Optimisations CPU/GPU int√©gr√©es
- ‚úÖ Large communaut√© et support

**Speaches** reste d√©di√© √† Whisper (transcription), ce qui simplifie l'architecture.

### Mod√®les LLM Recommand√©s pour CPU

#### 1. **TinyLlama-1.1B** ‚≠ê (Recommand√© pour d√©marrer)
- **Taille** : 1.1B param√®tres (~1.4GB)
- **Performance CPU** : Tr√®s rapide (inference <1s sur CPU moderne)
- **Usage m√©moire** : ~2GB RAM
- **Qualit√©** : Suffisant pour formatage basique (grammaire, ponctuation)
- **Installation** : `ollama pull tinyllama`

#### 2. **Phi-2 (2.7B)** (Alternative plus puissante)
- **Taille** : 2.7B param√®tres (~1.7GB)
- **Performance CPU** : Acceptable (inference 2-3s)
- **Usage m√©moire** : ~4GB RAM
- **Qualit√©** : Meilleure compr√©hension du contexte
- **Installation** : `ollama pull phi`

#### 3. **Gemma-2B** (Alternative Google performante)
- **Taille** : 2B param√®tres (~1.7GB)
- **Performance CPU** : Rapide (inference ~1.5s)
- **Usage m√©moire** : ~3GB RAM
- **Qualit√©** : Bon √©quilibre qualit√©/vitesse
- **Installation** : `ollama pull gemma:2b`

### Comparaison vs OpenAI GPT

| Aspect | TinyLlama (CPU) | Phi-2 (CPU) | OpenAI GPT-3.5 |
|--------|-----------------|-------------|----------------|
| **Latence** | ~0.5-1s | ~2-3s | ~1-2s |
| **Co√ªt** | Gratuit | Gratuit | ~$0.0005/req |
| **Qualit√©** | Basique | Bonne | Excellente |
| **Privacy** | 100% local | 100% local | Cloud |
| **RAM requise** | 2GB | 4GB | N/A |
| **Setup** | 1 commande | 1 commande | API key |

### Configuration √©tendue

```json
{
  "language": "en",
  "formatterEnabled": true,
  "transcription": {
    "backend": "speaches",  // Pour Whisper (transcription)
    "speaches": {
      "url": "http://localhost:8000/v1",
      "apiKey": "none",
      "model": "Systran/faster-whisper-base"
    }
  },
  "formatting": {
    "backend": "openai",  // ‚Üê NOUVEAU : "openai" ou "ollama"
    "openai": {
      "apiKey": "sk-...",
      "model": "gpt-3.5-turbo"
    },
    "ollama": {
      "url": "http://localhost:11434/v1",  // Port standard Ollama
      "model": "tinyllama"
    },
    "personalities": {
      "default": {
        "name": "Default",
        "prompt": "Fix grammar and punctuation. Keep original style."
      }
      // ... autres personalities
    }
  }
}
```

### V√©rification de Disponibilit√©

```typescript
// src/services/formatter.ts
public async checkOllamaAvailability(): Promise<boolean> {
  try {
    const response = await fetch(`${this.ollamaUrl}/api/tags`);
    const data = await response.json();
    return data.models && data.models.length > 0;
  } catch {
    return false;
  }
}
```

### Setup Rapide Ollama

```bash
# 1. Installer Ollama
curl https://ollama.ai/install.sh | sh

# 2. D√©marrer Ollama (d√©marre automatiquement en arri√®re-plan)
ollama serve

# 3. T√©l√©charger un mod√®le
ollama pull tinyllama

# 4. Tester
curl http://localhost:11434/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tinyllama",
    "messages": [{"role": "user", "content": "Fix: i gone to store"}]
  }'

# 5. Dans Voice Transcriber: Backend ‚Üí Ollama LLM
```

---

## üìä Plan d'Impl√©mentation

### Phase 1: Toggle Formatter (MVP) - 2h
- [ ] Ajouter RuntimeState dans VoiceTranscriberApp
- [ ] Ajouter menu item checkbox "Formatter ON/OFF"
- [ ] Impl√©menter handleFormatterToggle()
- [ ] Mettre √† jour processAudioFile() pour respecter runtimeState
- [ ] Tests unitaires (2-3 tests)

### Phase 2: Formatter Personalities - 2h
- [ ] D√©finir les 4 personalities pr√©d√©finies (default, professional, technical, creative)
- [ ] Ajouter submenu "Personality" avec radio buttons
- [ ] Impl√©menter handlePersonalityChange()
- [ ] Modifier FormatterService pour accepter personality
- [ ] Tests unitaires (3-4 tests)

### Phase 3: Ollama LLM Backend - 2h
- [ ] Installer et tester Ollama avec TinyLlama
- [ ] Ajouter FormatterService.checkOllamaAvailability()
- [ ] Ajouter submenu "Backend" (OpenAI/Ollama)
- [ ] Impl√©menter FormatterService avec backend switch
- [ ] Documentation Ollama setup
- [ ] Tests unitaires (4-5 tests)

### Phase 4: Benchmark Mode - 2h
- [ ] Ajouter benchmarkMode dans RuntimeState
- [ ] Ajouter menu item checkbox "Benchmark Mode ON/OFF"
- [ ] Impl√©menter ex√©cution parall√®le de tous les backends
- [ ] Cr√©er notification comparative avec timings et stats
- [ ] Logger d√©taill√© des r√©sultats pour analyse
- [ ] Tests unitaires (3-4 tests)

### Phase 5: Polish & Documentation - 1h
- [ ] Ic√¥nes diff√©rentes selon √©tat (‚úçÔ∏è/‚úèÔ∏è)
- [ ] Messages de feedback clairs
- [ ] Mise √† jour documentation utilisateur (Quick Actions)
- [ ] Guide de setup Ollama pour formatage
- [ ] Documentation Benchmark Mode (utilisation, interpr√©tation des r√©sultats)
- [ ] Guide de troubleshooting (Ollama, submenus, √©tat runtime)

**Total estim√©** : 9 heures

---

## üéØ B√©n√©fices Utilisateur

### Toggle Formatter
- ‚úÖ √âconomie d'API calls OpenAI (~$0.0005 par transcription)
- ‚úÖ Tests rapides sans √©dition de config
- ‚úÖ Transcriptions brutes pour analyse/debugging

### Personalities
- ‚úÖ Adaptation rapide au contexte (meeting, email, notes)
- ‚úÖ Pas besoin de m√©moriser les bons prompts
- ‚úÖ R√©sultats consistants par use case

### Ollama Local Backend
- ‚úÖ **Zero cost** pour formatage (apr√®s setup)
- ‚úÖ **100% privacy** - tout en local
- ‚úÖ **Pas de latence r√©seau** - plus rapide sur bon CPU
- ‚úÖ **Pas de limites** - formatage illimit√©
- ‚úÖ **Setup en 2 commandes** - Installation simple
- ‚úÖ **API compatible OpenAI** - Int√©gration facile
- ‚úÖ **Fallback automatique** si Ollama indisponible

### Benchmark Mode
- ‚úÖ **Comparaison objective** - Mesures pr√©cises de performance
- ‚úÖ **Aide √† la d√©cision** - Choisir le meilleur backend pour son usage
- ‚úÖ **Test de mod√®les** - √âvaluer rapidement de nouveaux mod√®les Ollama
- ‚úÖ **Optimisation** - Donn√©es concr√®tes pour ajuster sa config
- ‚úÖ **Transparence** - Voir la diff√©rence de qualit√©/vitesse entre backends

---

## üöß Limitations & Consid√©rations

### Limitations Techniques
- √âtat runtime non persist√© (reset au red√©marrage)
- Personalities limit√©es √† 4-5 pr√©d√©finies
- Ollama n√©cessite 2-6GB RAM selon le mod√®le
- Qualit√© formatage Ollama < OpenAI GPT (mais acceptable)

### D√©cisions de Design
- **Pas de sauvegarde auto dans config.json** : √âvite conflits avec fichier config
- **√âtat m√©moire prioritaire** : Plus simple √† g√©rer qu'un syst√®me de merge
- **Speaches = Whisper uniquement** : S√©paration claire transcription/formatage
- **Ollama = Formatage local** : Outil d√©di√© pour LLM locaux
- **Option "Save as default" future** : Si besoin de persistance

### UX
- Menu peut devenir long avec submenu (5-6 items)
- Besoin de tooltips clairs pour expliquer les personalities
- Icon feedback important pour √©tat actuel

---

## üìö Documentation Utilisateur

### Guide Rapide

**Toggle Formatter** :
1. Right-click system tray icon
2. Click "‚úçÔ∏è Formatter: ON" to toggle
3. Status changes immediately (no restart)

**Change Personality** :
1. Right-click ‚Üí "Personality" submenu
2. Select desired style (Default, Professional, Technical, Creative)
3. Next transcription uses new style

**Use Ollama for Local Formatting** :
1. Install Ollama: `curl https://ollama.ai/install.sh | sh`
2. Pull a model: `ollama pull tinyllama`
3. Right-click ‚Üí "Backend" ‚Üí "Ollama LLM"
4. Formatage local, zero cost, 100% private

### Ollama Setup D√©taill√©

```bash
# Installation (Linux)
curl https://ollama.ai/install.sh | sh

# Installation (macOS)
brew install ollama

# D√©marrer le service
ollama serve  # Ou d√©marre automatiquement

# T√©l√©charger des mod√®les
ollama pull tinyllama    # Rapide, 2GB RAM
ollama pull phi          # Plus puissant, 4GB RAM
ollama pull gemma:2b     # Alternative Google

# V√©rifier les mod√®les install√©s
ollama list

# Tester un mod√®le
ollama run tinyllama "Fix grammar: i gone to store yesterday"
```

### Configuration Voice Transcriber

```json
{
  "formatting": {
    "backend": "ollama",
    "ollama": {
      "url": "http://localhost:11434/v1",
      "model": "tinyllama"
    }
  }
}
```

---

## üîÑ Int√©gration dans la Roadmap

**Ajout dans Phase 7 : User Interface & Platform** :

```markdown
### Phase 7: User Interface & Platform üñ•Ô∏è
- **üéØ Quick Actions Menu**: Toggle formatter, switch personalities, change backend on-the-fly
  - ‚úçÔ∏è Formatter toggle (ON/OFF)
  - üé≠ Formatter personalities (Default, Professional, Technical, Creative)
  - ü§ñ Backend selector (OpenAI GPT / Ollama LLM)
  - üìä Benchmark mode (Compare backends performance)
- üíª CLI Interface: Command-line interface for automation
- ü™ü Windows Support: Replace arecord with Windows audio
- üçé macOS Support: Add macOS audio and system tray
- ‚å®Ô∏è Keyboard Shortcuts: Global shortcuts for transcription
- üñºÔ∏è Graphical Interface: Desktop GUI for configuration
```

---

## ‚úÖ Checklist de Validation

Avant de d√©marrer l'impl√©mentation :

- [ ] Valider les 4 personalities avec des tests utilisateur
- [ ] Installer et tester Ollama avec TinyLlama (qualit√© formatage acceptable ?)
- [ ] V√©rifier node-systray-v2 supporte les submenus
- [ ] Confirmer que l'√©tat runtime est suffisant (pas besoin de persistence)
- [ ] D√©finir le comportement lors du reload config (merge ou reset ?)
- [ ] Tester la latence Ollama vs OpenAI sur diff√©rents CPU

---


**Status** : ‚úÖ **Coh√©rent et pr√™t pour impl√©mentation**

