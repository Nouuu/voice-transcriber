{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Development Preview</p> <p>This is a preview of the documentation from PR #54.</p> <p>For the stable documentation, visit nouuu.github.io/voice-transcriber</p>"},{"location":"#voice-transcriber-documentation","title":"Voice Transcriber Documentation","text":""},{"location":"#voice-transcriber","title":"\ud83c\udfa4 Voice Transcriber","text":"<p>Lightweight desktop voice-to-text transcription with OpenAI Whisper and system tray integration</p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>Voice Transcriber is a lightweight desktop application that provides seamless voice-to-text conversion with system tray integration. Record audio with a single click, and transcribed text is automatically copied to your clipboard.</p> <ul> <li> <p> System Tray Integration</p> <p>Click to record, visual state feedback (green=idle, red=recording, purple=processing)</p> </li> <li> <p> Multilingual Support</p> <p>French, English, Spanish, German, Italian with strong language enforcement</p> </li> <li> <p> AI-Powered</p> <p>OpenAI Whisper transcription with optional GPT text formatting</p> </li> <li> <p> Self-Hosted Option</p> <p>Run 100% offline with Speaches - zero cost, complete privacy</p> </li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83c\udfaf System Tray Integration: Click to record, visual state feedback</li> <li>\ud83c\udf99\ufe0f High-Quality Recording: Audio capture using arecord on Linux</li> <li>\ud83c\udf0d Multilingual Support: French, English, Spanish, German, Italian</li> <li>\u270d\ufe0f Text Formatting: Optional GPT-based grammar improvement</li> <li>\ud83d\udccb Clipboard Integration: Automatic result copying</li> <li>\ud83c\udfe0 Self-Hosted Option: Run 100% offline with Speaches</li> <li>\ud83d\udd12 Privacy-Focused: No persistent audio storage, local processing</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get started in under 5 minutes:</p> Automated Setup (Recommended)Step-by-Step Setup <pre><code># Clone the repository\ngit clone https://github.com/Nouuu/voice-transcriber.git\ncd voice-transcriber\n\n# One-command setup (checks deps, installs, creates config)\nmake setup\n\n# Configure your OpenAI API key\nnano ~/.config/voice-transcriber/config.json\n\n# Run the application\nmake run\n</code></pre> <pre><code># Clone the repository\ngit clone https://github.com/Nouuu/voice-transcriber.git\ncd voice-transcriber\n\n# Check system dependencies (Bun, arecord, xsel)\nmake check-system-deps\n\n# Install Bun dependencies\nmake install\n\n# Initialize configuration file\nmake init-config\n\n# Configure your OpenAI API key\nnano ~/.config/voice-transcriber/config.json\n\n# Run the application\nmake run\n</code></pre> <p>Next Steps</p> <ul> <li>\u26a1 Quickstart - Get started in 5 minutes</li> <li>Installation Guide - Detailed setup instructions</li> <li>Configuration - Configure languages and backends</li> <li>Basic Usage - Learn how to use the app</li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":"<pre><code>sequenceDiagram\n    participant User\n    participant SystemTray\n    participant AudioRecorder\n    participant MP3Encoder\n    participant Backend as Whisper API&lt;br/&gt;(OpenAI or Speaches)\n    participant GPT as ChatGPT&lt;br/&gt;(optional)\n    participant Clipboard\n\n    User-&gt;&gt;SystemTray: Click tray icon\n    SystemTray-&gt;&gt;SystemTray: State: RECORDING (\ud83d\udd34)\n    SystemTray-&gt;&gt;AudioRecorder: Start recording\n    AudioRecorder-&gt;&gt;AudioRecorder: Capture audio (arecord)\n    User-&gt;&gt;SystemTray: Click again to stop\n    SystemTray-&gt;&gt;SystemTray: State: PROCESSING (\ud83d\udfe3)\n    AudioRecorder-&gt;&gt;AudioRecorder: Save WAV file\n    AudioRecorder-&gt;&gt;MP3Encoder: Convert to MP3\n    Note over MP3Encoder: Compress audio&lt;br/&gt;~75% size reduction&lt;br/&gt;(mono 16kHz 64kbps)\n    MP3Encoder--&gt;&gt;AudioRecorder: MP3 file\n    AudioRecorder-&gt;&gt;Backend: Upload MP3\n    Backend-&gt;&gt;Backend: Transcribe audio\n    Backend--&gt;&gt;AudioRecorder: Return text\n    opt Formatting Enabled\n        AudioRecorder-&gt;&gt;GPT: Format text\n        GPT--&gt;&gt;AudioRecorder: Formatted text\n    end\n    AudioRecorder-&gt;&gt;Clipboard: Copy text\n    Clipboard--&gt;&gt;User: Paste transcription\n    SystemTray-&gt;&gt;SystemTray: State: IDLE (\ud83d\udfe2)</code></pre> <p>Key Steps:</p> <ol> <li>Audio Capture - Records in WAV format (CD quality: 44.1kHz, 16-bit)</li> <li>MP3 Compression - Converts to mono 16kHz 64kbps MP3 (~75% size reduction)</li> <li>Transcription - Sends to OpenAI Whisper or self-hosted Speaches</li> <li>Optional Formatting - Improves grammar/punctuation with ChatGPT (if enabled)</li> <li>Clipboard - Automatically copies result for instant pasting</li> </ol> <p>System Tray Menu</p> <p>Right-click the tray icon to access:</p> <ul> <li>\ud83c\udf99\ufe0f Start Recording - Begin voice capture</li> <li>\u23f9\ufe0f Stop Recording - End recording and transcribe  </li> <li>\u274c Exit - Exit the application</li> </ul> <p>Menu items are automatically enabled/disabled based on current state.</p>"},{"location":"#popular-use-cases","title":"Popular Use Cases","text":"<ul> <li> <p>\ud83d\udcdd Note Taking</p> <p>Record meetings, lectures, or brainstorming sessions with automatic transcription</p> </li> <li> <p>\ud83d\udcac Message Dictation</p> <p>Quickly dictate messages, emails, or social media posts</p> </li> <li> <p>\ud83c\udf10 Language Learning</p> <p>Practice pronunciation and see transcriptions in multiple languages</p> </li> <li> <p>\u267f Accessibility</p> <p>Voice-to-text for users with typing difficulties</p> </li> </ul>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li> <p>Getting Started</p> <p>Installation, configuration, and first-run setup</p> </li> <li> <p>User Guide</p> <p>Basic usage, language support, and troubleshooting</p> </li> <li> <p>Development</p> <p>Architecture, development guide, and API reference</p> </li> <li> <p>Advanced</p> <p>Self-hosted setup, whisper models, and local inference</p> </li> </ul>"},{"location":"#community-and-support","title":"Community and Support","text":"<ul> <li>GitHub Repository: nouuu/voice-transcriber</li> <li>npm Package: voice-transcriber</li> <li>Issues: Report a bug or request a feature</li> <li>Discussions: GitHub Discussions</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License.</p> <p>Built with \u2764\ufe0f using Bun, TypeScript, and OpenAI</p>"},{"location":"MIGRATION_GUIDE/","title":"Documentation Migration Guide","text":"","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#summary-of-changes","title":"Summary of Changes","text":"<p>This document tracks the migration from inline README documentation to structured MkDocs documentation.</p>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#what-was-done","title":"What Was Done","text":"<ol> <li>Created MkDocs Structure (<code>documentation/</code> directory)</li> <li>Getting Started (3 pages)</li> <li>User Guide (4 pages)</li> <li>Development (4 pages)</li> <li>Advanced (3 pages)</li> <li> <p>Contributing (1 page)</p> </li> <li> <p>Migrated Existing Documentation</p> </li> <li>Copied from <code>docs/</code> (gitignored, local-only)</li> <li>Adapted for MkDocs Material theme</li> <li> <p>Added cross-references and navigation</p> </li> <li> <p>Setup CI/CD</p> </li> <li>GitHub Actions workflow (<code>.github/workflows/docs.yml</code>)</li> <li>Automatic deployment to GitHub Pages on <code>main</code> push</li> <li> <p>Build validation on pull requests</p> </li> <li> <p>Added Makefile Commands</p> </li> <li><code>make docs-install</code> - Install MkDocs dependencies</li> <li><code>make docs-build</code> - Build documentation site</li> <li><code>make docs-serve</code> - Preview locally at http://127.0.0.1:8000</li> <li> <p><code>make docs-deploy</code> - Manual deployment (CI handles this)</p> </li> <li> <p>Updated <code>.gitignore</code></p> </li> <li>Added <code>site/</code> (MkDocs build artifacts)</li> <li>Added <code>.cache/</code> (MkDocs cache)</li> <li>Kept <code>docs/</code> (local-only development documentation)</li> </ol>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#what-needs-to-be-done","title":"What Needs To Be Done","text":"","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#1-simplify-main-readmemd","title":"1. Simplify Main README.md","text":"<p>The main README should become a concise landing page that directs users to the comprehensive documentation:</p> <p>Recommended structure:</p> <pre><code># \ud83c\udfa4 Voice Transcriber\n\n[Badges here]\n\nLightweight desktop voice-to-text transcription with OpenAI Whisper and system tray integration.\n\n## \u2728 Features\n\n- \ud83c\udfaf System Tray Integration\n- \ud83c\udf0d Multilingual Support (5 languages)\n- \ud83c\udfe0 Self-Hosted Option (Speaches)\n- \ud83d\udccb Automatic Clipboard Copy\n\n## \ud83d\ude80 Quick Start\n\n```bash\ngit clone https://github.com/Nouuu/voice-transcriber.git\ncd voice-transcriber\nmake setup\nnano ~/.config/voice-transcriber/config.json  # Add API key\nmake run\n</code></pre>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#documentation","title":"\ud83d\udcda Documentation","text":"<p>Comprehensive documentation available at: https://nouuu.github.io/voice-transcriber</p> <ul> <li>Installation Guide</li> <li>Configuration</li> <li>User Guide</li> <li>Development Guide</li> </ul>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#contributing","title":"\ud83e\udd1d Contributing","text":"<p>See Contributing Guide for guidelines.</p>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#license","title":"\ud83d\udcc4 License","text":"<p>MIT License - see LICENSE file. <pre><code>**What to remove from README**:\n\n- \u274c Detailed installation steps (move to docs)\n- \u274c Complete configuration reference (move to docs)\n- \u274c Extensive usage examples (move to docs)\n- \u274c Full troubleshooting guide (move to docs)\n- \u274c Detailed development workflow (move to docs)\n- \u274c Complete roadmap (move to docs)\n\n**What to keep in README**:\n\n- \u2705 Project overview and features\n- \u2705 Quick start command sequence\n- \u2705 Links to comprehensive documentation\n- \u2705 Badges and basic metadata\n- \u2705 License information\n\n#### 2. Enable GitHub Pages\n\nIn your repository settings:\n\n1. Go to **Settings** &gt; **Pages**\n2. Source: **Deploy from a branch**\n3. Branch: **gh-pages** (will be created by CI)\n4. Wait for first deployment from CI\n\n#### 3. Test Documentation Locally\n\n```bash\n# Install dependencies\nmake docs-install\n\n# Preview locally\nmake docs-serve\n</code></pre></p> <p>Open http://127.0.0.1:8000 and verify:</p> <ul> <li>Navigation works correctly</li> <li>All pages load without errors</li> <li>Code examples are properly formatted</li> <li>Internal links resolve correctly</li> <li>Search functionality works</li> </ul>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#4-deploy-to-github-pages","title":"4. Deploy to GitHub Pages","text":"<p>Option 1: Automatic (Recommended)</p> <p>Push to <code>main</code> branch:</p> <pre><code>git add .\ngit commit -m \"docs: setup MkDocs documentation with CI/CD\"\ngit push origin main\n</code></pre> <p>GitHub Actions will automatically deploy to GitHub Pages.</p> <p>Option 2: Manual</p> <pre><code>make docs-deploy\n</code></pre>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#5-update-repository-links","title":"5. Update Repository Links","text":"<p>After documentation is live, update:</p> <ul> <li>README.md: Add documentation URL</li> <li>package.json: Update <code>homepage</code> field</li> <li>GitHub repository description: Add documentation link</li> </ul>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#files-createdmodified","title":"Files Created/Modified","text":"","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#created-files","title":"Created Files","text":"<pre><code>documentation/\n\u251c\u2500\u2500 index.md\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 installation.md\n\u2502   \u251c\u2500\u2500 configuration.md\n\u2502   \u2514\u2500\u2500 first-run.md\n\u251c\u2500\u2500 user-guide/\n\u2502   \u251c\u2500\u2500 basic-usage.md\n\u2502   \u251c\u2500\u2500 language-support.md\n\u2502   \u251c\u2500\u2500 transcription-backends.md\n\u2502   \u2514\u2500\u2500 troubleshooting.md\n\u251c\u2500\u2500 development/\n\u2502   \u251c\u2500\u2500 architecture.md\n\u2502   \u251c\u2500\u2500 development-guide.md\n\u2502   \u251c\u2500\u2500 testing.md\n\u2502   \u2514\u2500\u2500 api-reference.md\n\u251c\u2500\u2500 advanced/\n\u2502   \u251c\u2500\u2500 speaches-integration.md\n\u2502   \u251c\u2500\u2500 whisper-models.md\n\u2502   \u2514\u2500\u2500 local-inference.md\n\u2514\u2500\u2500 contributing.md\n\nmkdocs.yml\n.github/workflows/docs.yml\n</code></pre>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#modified-files","title":"Modified Files","text":"<pre><code>Makefile (added docs-* commands)\n.gitignore (added site/ and .cache/)\n</code></pre>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#unchanged-files","title":"Unchanged Files","text":"<pre><code>docs/ (still gitignored, local-only)\nREADME.md (to be simplified by user)\nCLAUDE.md (local-only, no changes needed)\n</code></pre>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#rollback-plan","title":"Rollback Plan","text":"<p>If needed, documentation migration can be rolled back:</p> <pre><code># Remove MkDocs files\nrm -rf documentation/ site/ mkdocs.yml\n\n# Restore Makefile (remove docs commands)\ngit checkout main -- Makefile\n\n# Restore .gitignore\ngit checkout main -- .gitignore\n\n# Remove GitHub Actions workflow\nrm .github/workflows/docs.yml\n</code></pre>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#benefits-of-migration","title":"Benefits of Migration","text":"","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#before-inline-readme","title":"Before (Inline README)","text":"<ul> <li>\u274c Single 650-line README file</li> <li>\u274c No search functionality</li> <li>\u274c No version history for docs</li> <li>\u274c Difficult to navigate</li> <li>\u274c No syntax highlighting in examples</li> </ul>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#after-mkdocs","title":"After (MkDocs)","text":"<ul> <li>\u2705 Organized, paginated documentation</li> <li>\u2705 Full-text search across all pages</li> <li>\u2705 Git-tracked version history</li> <li>\u2705 Clear navigation with sections</li> <li>\u2705 Syntax highlighting and admonitions</li> <li>\u2705 Mobile-friendly responsive design</li> <li>\u2705 Automatic deployment with CI/CD</li> </ul>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#next-steps","title":"Next Steps","text":"<ol> <li>Review all documentation pages for accuracy</li> <li>Simplify main README.md as described above</li> <li>Test local documentation preview with <code>make docs-serve</code></li> <li>Push to main to trigger automatic deployment</li> <li>Verify GitHub Pages deployment at https://nouuu.github.io/voice-transcriber</li> <li>Update repository links to documentation site</li> </ol>","tags":["development","reference","documentation"]},{"location":"MIGRATION_GUIDE/#questions","title":"Questions?","text":"<ul> <li>Check MkDocs Material Documentation</li> <li>Review Speaches Documentation for inspiration</li> <li>Ask on GitHub Discussions</li> </ul>","tags":["development","reference","documentation"]},{"location":"contributing/","title":"Contributing Guide","text":"<p>Thank you for considering contributing to Voice Transcriber! This guide will help you get started.</p>","tags":["development","guide","contributing"]},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Be respectful, inclusive, and considerate in all interactions.</p>","tags":["development","guide","contributing"]},{"location":"contributing/#how-to-contribute","title":"How to Contribute","text":"","tags":["development","guide","contributing"]},{"location":"contributing/#reporting-bugs","title":"Reporting Bugs","text":"<p>Before submitting a bug report:</p> <ol> <li>Check existing issues</li> <li>Try the latest version</li> <li>Enable debug mode: <code>voice-transcriber --debug</code></li> </ol> <p>Bug report should include:</p> <ul> <li>Voice Transcriber version</li> <li>Operating system and desktop environment</li> <li>Steps to reproduce</li> <li>Expected vs actual behavior</li> <li>Debug logs (if applicable)</li> </ul> <p>Submit at: https://github.com/Nouuu/voice-transcriber/issues/new</p>","tags":["development","guide","contributing"]},{"location":"contributing/#suggesting-features","title":"Suggesting Features","text":"<p>Feature requests should include:</p> <ul> <li>Problem description: What problem does this solve?</li> <li>Proposed solution: How should it work?</li> <li>Alternatives considered: What other approaches did you think about?</li> <li>Use cases: Who benefits from this feature?</li> </ul>","tags":["development","guide","contributing"]},{"location":"contributing/#submitting-pull-requests","title":"Submitting Pull Requests","text":"<p>Development workflow:</p> <pre><code># 1. Fork and clone\ngit clone https://github.com/YOUR_USERNAME/voice-transcriber.git\ncd voice-transcriber\n\n# 2. Create feature branch\ngit checkout -b feat/your-feature-name\n\n# 3. Setup development environment\nmake setup\n\n# 4. Make changes\n# Edit code...\n\n# 5. Run tests and linting\nmake test\nmake format-check\n\n# 6. Commit changes\ngit commit -m \"feat: add your feature\"\n\n# 7. Push and create PR\ngit push origin feat/your-feature-name\n</code></pre> <p>Pull request checklist:</p> <ul> <li> Code follows project conventions</li> <li> Tests added for new functionality</li> <li> All tests pass (<code>make test</code>)</li> <li> Linting passes (<code>make format-check</code>)</li> <li> Commit messages follow Conventional Commits</li> <li> Documentation updated if needed</li> </ul>","tags":["development","guide","contributing"]},{"location":"contributing/#development-guidelines","title":"Development Guidelines","text":"","tags":["development","guide","contributing"]},{"location":"contributing/#code-style","title":"Code Style","text":"<ul> <li>TypeScript: Strict typing, no <code>any</code> types</li> <li>Services: 3-5 methods maximum, simple interfaces</li> <li>Error handling: Consistent <code>{ success: boolean, error?: string }</code> pattern</li> <li>Testing: Focus on core functionality, use simple mocks</li> </ul>","tags":["development","guide","contributing"]},{"location":"contributing/#commit-messages","title":"Commit Messages","text":"<p>Use Conventional Commits format:</p> <pre><code>type: description\n\nfeat: add new feature\nfix: resolve bug in service\nrefactor: simplify code structure\ntest: add tests for component\ndocs: update documentation\nchore: update dependencies\n</code></pre> <p>Rules: - Keep descriptions under 50 characters - Use present tense (\"add\" not \"added\") - No capitalization after colon - No period at end</p>","tags":["development","guide","contributing"]},{"location":"contributing/#project-principles","title":"Project Principles","text":"","tags":["development","guide","contributing"]},{"location":"contributing/#keep-it-simple","title":"KEEP IT SIMPLE","text":"<p>\u2705 Do: - Basic error handling - Simple configuration - Direct API calls - Console logging (info/error) - Single responsibility</p> <p>\u274c Don't: - Complex retry logic - Advanced statistics - Batch processing (unless essential) - Complex validation - Advanced logging systems</p> <p>Each service should be under 100 lines with 3-5 core methods.</p>","tags":["development","guide","contributing"]},{"location":"contributing/#testing","title":"Testing","text":"<p>Run tests:</p> <pre><code>make test              # All tests\nmake test-watch        # Watch mode\nmake test-file FILE=   # Specific test\n</code></pre> <p>Testing philosophy:</p> <ul> <li>Test core functionality</li> <li>Use simple mocks</li> <li>Maximum 5-6 tests per service</li> <li>Focus on: success cases, basic errors, input validation</li> </ul>","tags":["development","guide","contributing"]},{"location":"contributing/#documentation","title":"Documentation","text":"","tags":["development","guide","contributing"]},{"location":"contributing/#updating-documentation","title":"Updating Documentation","text":"<p>Documentation uses MkDocs Material:</p> <pre><code># Install dependencies\nmake docs-install\n\n# Serve locally\nmake docs-serve\n\n# Build\nmake docs-build\n</code></pre> <p>Documentation structure:</p> <pre><code>documentation/\n\u251c\u2500\u2500 getting-started/    # Installation, configuration, first run\n\u251c\u2500\u2500 user-guide/         # Usage, language support, troubleshooting\n\u251c\u2500\u2500 development/        # Architecture, development guide, API\n\u2514\u2500\u2500 advanced/          # Speaches, models, roadmap\n</code></pre>","tags":["development","guide","contributing"]},{"location":"contributing/#writing-documentation","title":"Writing Documentation","text":"<ul> <li>Clear language: Write for users at different levels</li> <li>Code examples: Include practical examples</li> <li>Cross-references: Link related pages</li> <li>Admonitions: Use tips, warnings, and info boxes</li> </ul> <p>Example:</p> <pre><code>!!! tip \"Recommendation\"\n    Use the base model for best speed/accuracy balance.\n\n!!! warning \"Known Issue\"\n    System tray may not work on all desktop environments.\n</code></pre>","tags":["development","guide","contributing"]},{"location":"contributing/#community","title":"Community","text":"<ul> <li>GitHub Issues: https://github.com/Nouuu/voice-transcriber/issues</li> <li>GitHub Discussions: https://github.com/Nouuu/voice-transcriber/discussions</li> <li>Pull Requests: https://github.com/Nouuu/voice-transcriber/pulls</li> </ul>","tags":["development","guide","contributing"]},{"location":"contributing/#recognition","title":"Recognition","text":"<p>All contributors will be recognized in the project's README and release notes.</p> <p>Thank you for contributing to Voice Transcriber! \ud83c\udfa4</p>","tags":["development","guide","contributing"]},{"location":"contributing/#related-pages","title":"Related Pages","text":"<ul> <li>Development Guide - Complete development workflow and setup</li> <li>Technical Architecture - System architecture overview</li> <li>Testing Guide - Testing strategies and patterns</li> <li>API Reference - API documentation for all services</li> </ul>","tags":["development","guide","contributing"]},{"location":"advanced/configuration-management/","title":"Configuration Management","text":"<p>Advanced guide for managing Voice Transcriber configuration dynamically without restarting the application.</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#overview","title":"Overview","text":"<p>Voice Transcriber supports live configuration management, allowing you to modify settings and reload them on-the-fly without restarting the application.</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udd04 Hot Reload: Changes take effect immediately</li> <li>\u2705 Validation: Configuration is validated before applying</li> <li>\ud83d\udd19 Automatic Rollback: Previous config restored on failure</li> <li>\ud83d\udd0d Change Detection: See exactly what changed (debug mode)</li> <li>\ud83d\udee1\ufe0f Safety Checks: Reload blocked during recording/processing</li> </ul>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#quick-configuration-workflow","title":"Quick Configuration Workflow","text":"","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#basic-workflow","title":"Basic Workflow","text":"<ol> <li>Open Config: Right-click tray icon \u2192 \"\u2699\ufe0f Open Config\"</li> <li>Edit: Make your changes in the text editor</li> <li>Save: Save the configuration file</li> <li>Reload: Right-click tray icon \u2192 \"\ud83d\udd04 Reload Config\" (when idle)</li> </ol>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#example-switching-language","title":"Example: Switching Language","text":"<pre><code>// Before\n{\n  \"language\": \"en\"\n}\n\n// Edit config.json\n{\n  \"language\": \"fr\"\n}\n\n// Right-click tray \u2192 Reload Config\n// \u2705 Now transcribing in French\n</code></pre>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#save-as-default","title":"Save as Default","text":"<p>NEW in v1.x - Save your current settings with one click from the system tray menu.</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#how-it-works","title":"How It Works","text":"<p>Instead of manually editing <code>config.json</code>, you can:</p> <ol> <li>Adjust settings via the system tray menu (e.g., toggle personalities)</li> <li>Save by clicking \"\ud83d\udcbe Save as Default\"</li> <li>Persist your preferences automatically</li> </ol>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#what-gets-saved","title":"What Gets Saved","text":"<p>When you click \"\ud83d\udcbe Save as Default\", the entire configuration is saved:</p> <ul> <li>\u2705 Active personalities</li> <li>\u2705 Selected personalities (menu visibility)</li> <li>\u2705 Custom personalities</li> <li>\u2705 Language setting</li> <li>\u2705 Backend configurations</li> <li>\u2705 All other parameters</li> </ul> <p>Complete Save</p> <p>\"Save as Default\" saves everything, not just what you changed via the menu. Any manual config edits that were reloaded are also saved.</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#example-workflow","title":"Example Workflow","text":"<pre><code># 1. Start the application\nvoice-transcriber\n\n# 2. Via system tray menu:\n#    \u2611 Professional\n#    \u2611 Emojify\n#    \u2610 Default (uncheck)\n\n# 3. Click \"\ud83d\udcbe Save as Default\"\n#    Logs show:\n#    [INFO] \u2705 Configuration saved to file successfully\n#    [INFO] Active personalities saved: builtin:professional, builtin:emojify\n\n# 4. Restart \u2192 Professional + Emojify are active by default \u2705\n</code></pre>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#when-to-use","title":"When to Use","text":"<p>Perfect for: - Saving your preferred personality combinations - Quick workflow adjustments - Testing different setups before committing</p> <p>Not ideal for: - Complex configuration changes (edit config file directly) - One-time testing (changes persist)</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#safety-features","title":"Safety Features","text":"<ul> <li>State Check: Only available when IDLE (disabled during recording/processing)</li> <li>Confirmation: Logs confirm successful save with details</li> <li>Rollback: Edit <code>config.json</code> and reload if needed</li> </ul>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#change-detection-debug-mode","title":"Change Detection (Debug Mode)","text":"<p>In debug mode, Voice Transcriber detects and displays all configuration changes when you reload.</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#enabling-change-detection","title":"Enabling Change Detection","text":"<pre><code>voice-transcriber --debug\n# or\nvoice-transcriber -d\n</code></pre>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#what-is-detected","title":"What Is Detected","text":"<p>The system detects 15+ types of changes:</p> <p>Transcription: - Backend (openai \u2194 speaches) - Model changes - Speaches URL changes</p> <p>Formatter: - Backend (openai \u2194 ollama) - Model changes - Ollama URL changes</p> <p>Personalities: - Active personalities added/removed - Custom personalities added - Custom personalities removed - Custom personalities modified - Selected personalities (menu visibility)</p> <p>General: - Language changes - Benchmark mode toggled</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#example-logs","title":"Example Logs","text":"<p>No changes: <pre><code>[INFO] Reloading configuration...\n[DEBUG] \u2713 No configuration changes detected (config file matches live state)\n[INFO] \u2705 Configuration reloaded successfully\n</code></pre></p> <p>Single change: <pre><code>[INFO] Reloading configuration...\n[DEBUG] \ud83d\udd04 Configuration changes detected:\n[DEBUG]   \u2514\u2500 Language: en \u2192 fr\n[INFO] \u2705 Configuration reloaded successfully\n</code></pre></p> <p>Multiple changes: <pre><code>[INFO] Reloading configuration...\n[DEBUG] \ud83d\udd04 Configuration changes detected:\n[DEBUG]   \u2514\u2500 Transcription backend: openai \u2192 speaches\n[DEBUG]   \u2514\u2500 Transcription model: whisper-1 \u2192 Systran/faster-whisper-medium\n[DEBUG]   \u2514\u2500 Active personalities: builtin:default \u2192 builtin:professional, builtin:emojify\n[DEBUG]   \u2514\u2500 Custom personalities added: technical-fr\n[INFO] \u2705 Configuration reloaded successfully\n</code></pre></p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#use-cases","title":"Use Cases","text":"<p>Development &amp; Testing: <pre><code># Monitor all changes during development\nvoice-transcriber -d\n\n# Test different configs, see what changed\n# Perfect for iterating on personality combinations\n</code></pre></p> <p>Troubleshooting: <pre><code># Verify your changes are detected\nvoice-transcriber -d\n\n# If \"No changes detected\" but you made changes:\n# \u2192 Check JSON syntax (invalid JSON ignored)\n# \u2192 Verify file was saved\n# \u2192 Check file permissions\n</code></pre></p> <p>Production vs Debug</p> <p>Change detection logs only appear in debug mode. In normal mode, reloads are silent except for success/error messages.</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#reload-safety-validation","title":"Reload Safety &amp; Validation","text":"","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#state-restrictions","title":"State Restrictions","text":"<p>Reload Config is only available when the application is IDLE (green icon):</p> State Icon Reload Available? Why? Idle \ud83d\udfe2 \u2705 Yes Safe to reload Recording \ud83d\udd34 \u274c No Would interrupt audio capture Processing \ud83d\udfe3 \u274c No Would interfere with transcription","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#automatic-validation","title":"Automatic Validation","text":"<p>Before applying changes, the configuration is validated:</p> <pre><code>1. Load new config from file\n2. Validate required fields\n3. Check API keys format\n4. Verify backend compatibility\n5. \u2705 If valid \u2192 Apply changes\n6. \u274c If invalid \u2192 Show error, rollback\n</code></pre>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#rollback-on-failure","title":"Rollback on Failure","text":"<p>If reload fails, the previous configuration is automatically restored:</p> <pre><code>[INFO] Reloading configuration...\n[ERROR] Failed to reload configuration: Invalid API key format\n[INFO] Rolling back to previous configuration...\n[INFO] Previous configuration restored\n</code></pre>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#service-reinitialization","title":"Service Reinitialization","text":"<p>When you reload, these services are restarted with new settings:</p> <ul> <li>TranscriptionService: New API key, language, model, backend</li> <li>FormatterService: New API key, prompts, personalities</li> <li>AudioProcessor: Updated dependencies</li> </ul> <p>Old services are properly disposed to prevent memory leaks.</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#advanced-workflows","title":"Advanced Workflows","text":"","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#workflow-1-test-multiple-backends","title":"Workflow 1: Test Multiple Backends","text":"<pre><code># 1. Configure both backends in config.json\n{\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": { \"apiKey\": \"sk-...\" },\n    \"speaches\": { \"url\": \"http://localhost:8000/v1\" }\n  }\n}\n\n# 2. Test OpenAI\nvoice-transcriber\n# Make recording, check quality\n\n# 3. Switch to Speaches\n# Edit config: \"backend\": \"speaches\"\n# Right-click \u2192 Reload Config\n\n# 4. Test Speaches  \n# Make recording, compare quality\n\n# 5. Choose best backend\n# Edit config, Reload, Save as Default\n</code></pre>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#workflow-2-per-project-configs","title":"Workflow 2: Per-Project Configs","text":"<pre><code># Setup: Create config variants\n~/configs/\n\u251c\u2500\u2500 code-review.json\n\u251c\u2500\u2500 documentation.json\n\u2514\u2500\u2500 casual.json\n\n# Use: Load project-specific config\ncp ~/configs/code-review.json ~/.config/voice-transcriber/config.json\n# Right-click \u2192 Reload Config\n\n# When done: Save if you made improvements\n# Right-click \u2192 Save as Default\ncp ~/.config/voice-transcriber/config.json ~/configs/code-review.json\n</code></pre>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#workflow-3-sync-across-machines","title":"Workflow 3: Sync Across Machines","text":"<pre><code># Machine A: Configure and save\n# Right-click \u2192 Save as Default\n\n# Copy to dotfiles repo\ncp ~/.config/voice-transcriber/config.json ~/dotfiles/voice-transcriber/\ncd ~/dotfiles &amp;&amp; git add . &amp;&amp; git commit -m \"Update config\" &amp;&amp; git push\n\n# Machine B: Pull and reload\ncd ~/dotfiles &amp;&amp; git pull\ncp ~/dotfiles/voice-transcriber/config.json ~/.config/voice-transcriber/\n# Right-click \u2192 Reload Config\n# See changes in debug mode\n</code></pre>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#configuration-file-location","title":"Configuration File Location","text":"<p>The configuration file is located at:</p> <pre><code>~/.config/voice-transcriber/config.json\n</code></pre>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#opening-quickly","title":"Opening Quickly","text":"<p>Via System Tray: <pre><code>Right-click \u2192 \u2699\ufe0f Open Config\n</code></pre></p> <p>Via Terminal: <pre><code># Open in default editor\nxdg-open ~/.config/voice-transcriber/config.json\n\n# Or with specific editor\nnano ~/.config/voice-transcriber/config.json\ncode ~/.config/voice-transcriber/config.json\n</code></pre></p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#backup-strategies","title":"Backup Strategies","text":"<p>Manual Backup: <pre><code>cp ~/.config/voice-transcriber/config.json ~/.config/voice-transcriber/config.backup.json\n</code></pre></p> <p>Git Versioning: <pre><code>cd ~/.config/voice-transcriber\ngit init\ngit add config.json\ngit commit -m \"Initial config\"\n</code></pre></p> <p>Automatic Backup Script: <pre><code>#!/bin/bash\n# ~/bin/backup-voice-config\nDATE=$(date +%Y%m%d_%H%M%S)\ncp ~/.config/voice-transcriber/config.json \\\n   ~/.config/voice-transcriber/backups/config_$DATE.json\n</code></pre></p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#troubleshooting","title":"Troubleshooting","text":"","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#reload-fails-silently","title":"Reload Fails Silently","text":"<p>Problem: Click Reload, nothing happens</p> <p>Solutions: 1. Check application is IDLE (green icon) 2. Check logs for errors 3. Verify config file exists and is readable 4. Try in debug mode to see detailed logs</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#changes-not-detected","title":"Changes Not Detected","text":"<p>Problem: Made changes but \"No changes detected\"</p> <p>Check: 1. File was actually saved (check timestamp) 2. JSON syntax is valid (<code>cat config.json | jq .</code>) 3. Changed the right file (check path) 4. Not running multiple instances</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#config-validation-fails","title":"Config Validation Fails","text":"<p>Problem: \"Failed to reload configuration: ...\"</p> <p>Solutions: 1. Check error message for specific issue 2. Validate JSON syntax 3. Ensure required fields present (API keys, etc.) 4. Restore from backup if needed</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#rollback-not-working","title":"Rollback Not Working","text":"<p>Problem: Bad config persists after reload</p> <p>Solution: <pre><code># Force restore from backup\ncp ~/.config/voice-transcriber/config.backup.json \\\n   ~/.config/voice-transcriber/config.json\n\n# Or recreate default\nrm ~/.config/voice-transcriber/config.json\nvoice-transcriber  # Will trigger first-run setup\n</code></pre></p>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#best-practices","title":"Best Practices","text":"","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#dos","title":"Do's \u2705","text":"<ul> <li>Test changes in debug mode first</li> <li>Backup before major config changes</li> <li>Reload after each logical change (don't batch too many)</li> <li>Save as Default after finding good settings</li> <li>Use version control for important configs</li> </ul>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#donts","title":"Don'ts \u274c","text":"<ul> <li>Don't reload during recording (it's blocked anyway)</li> <li>Don't edit while app is reloading (race condition)</li> <li>Don't skip validation (invalid JSON breaks reload)</li> <li>Don't forget to save after editing (reload won't see changes)</li> </ul>","tags":["advanced","guide","configuration"]},{"location":"advanced/configuration-management/#related-documentation","title":"Related Documentation","text":"<ul> <li>Configuration Guide - All configuration options</li> <li>Formatting Personalities - Personality management</li> <li>Debug Mode - Detailed debug information</li> <li>Basic Usage - Getting started</li> </ul> <p>Last updated: 2025-10-29</p>","tags":["advanced","guide","configuration"]},{"location":"advanced/debug-mode/","title":"Debug Mode","text":"<p>Comprehensive guide to Voice Transcriber's debug mode for troubleshooting, performance analysis, and development.</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#overview","title":"Overview","text":"<p>Debug mode provides detailed logging and metrics about the entire transcription pipeline, from audio capture to clipboard copying.</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#enabling-debug-mode","title":"Enabling Debug Mode","text":"<pre><code>voice-transcriber --debug\n# or\nvoice-transcriber -d\n</code></pre>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#what-debug-mode-shows","title":"What Debug Mode Shows","text":"","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#1-audio-recording-details","title":"1. Audio Recording Details","text":"<p>File Information: <pre><code>[DEBUG] Starting audio recording to: /tmp/transcriber/recording-2025-10-29T10-30-00-000Z.wav\n[DEBUG] Stopping audio recording (duration: 15.42s)\n</code></pre></p> <p>File Sizes: <pre><code>[DEBUG] WAV file size: 2.75 MB (2888332 bytes)\n[DEBUG] WAV format: 2 channel(s), 44100 Hz sample rate\n</code></pre></p> <p>Audio Conversion: <pre><code>[DEBUG] Converting WAV to MP3: /tmp/transcriber/recording-2025-10-29T10-30-00-000Z.wav\n[DEBUG] Audio downsampled from 44100 Hz to 16000 Hz\n[DEBUG] MP3 file size: 0.13 MB (131616 bytes)\n[DEBUG] Compression ratio: 95.4% size reduction\n[DEBUG] WAV to MP3 conversion completed in 2.20 seconds\n</code></pre></p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#2-transcription-backend-details","title":"2. Transcription Backend Details","text":"<p>OpenAI Whisper: <pre><code>[DEBUG] Starting OpenAI Whisper transcription for file: /tmp/transcriber/recording.mp3\n[DEBUG] File size: 0.13 MB (131616 bytes)\n[DEBUG] Model: whisper-1\n[INFO] OpenAI transcription completed in 4.25s\n[DEBUG]   \u2514\u2500 Estimated breakdown: upload ~1.28s, processing ~2.55s, receive ~0.43s\n[DEBUG]   \u2514\u2500 Transcription length: 247 characters\n</code></pre></p> <p>Speaches: <pre><code>[DEBUG] Speaches client initialized with URL: https://speaches.example.com/v1/\n[DEBUG] Preloading Speaches model: Systran/faster-whisper-medium\n[INFO] Speaches model preloaded successfully: Systran/faster-whisper-medium\n[DEBUG] Starting Speaches transcription for file: /tmp/transcriber/recording.mp3\n[DEBUG] File size: 0.13 MB (131616 bytes)\n[DEBUG] Model: Systran/faster-whisper-medium\n[INFO] Speaches transcription completed in 2.18s\n[DEBUG]   \u2514\u2500 Estimated breakdown: upload ~0.65s, processing ~1.31s, receive ~0.22s\n[DEBUG]   \u2514\u2500 Transcription length: 247 characters\n</code></pre></p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#3-formatting-details","title":"3. Formatting Details","text":"<p>Personality Information: <pre><code>[INFO] Formatting text with personalities: builtin:professional, builtin:emojify\n[DEBUG] Using Professional personality prompt\n[DEBUG] Using Emojify personality prompt\n</code></pre></p> <p>Processing Metrics: <pre><code>[DEBUG] Formatting text (247 chars)\n[DEBUG] Language: fr\n[DEBUG] Model: gpt-4o-mini\n[DEBUG] Formatting completed in 1245ms\n</code></pre></p> <p>Results: <pre><code>[INFO] Original: \"le projet avance bien on a fait de bons progr\u00e8s\"\n[INFO] Formatted: \"Le projet avance bien! \ud83c\udfaf Nous avons r\u00e9alis\u00e9 de bons progr\u00e8s. \u2728\"\n</code></pre></p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#4-configuration-changes-reload","title":"4. Configuration Changes (Reload)","text":"<p>When reloading configuration: <pre><code>[INFO] Reloading configuration...\n[DEBUG] \ud83d\udd04 Configuration changes detected:\n[DEBUG]   \u2514\u2500 Transcription backend: openai \u2192 speaches\n[DEBUG]   \u2514\u2500 Transcription model: whisper-1 \u2192 Systran/faster-whisper-medium\n[DEBUG]   \u2514\u2500 Active personalities: builtin:default \u2192 builtin:professional, builtin:emojify\n[DEBUG]   \u2514\u2500 Language: en \u2192 fr\n[INFO] \u2705 Configuration reloaded successfully\n</code></pre></p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#use-cases","title":"Use Cases","text":"","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#1-performance-analysis","title":"1. Performance Analysis","text":"<p>Identify Bottlenecks: <pre><code>[DEBUG] WAV to MP3 conversion completed in 2.20 seconds  \u2190 Conversion time\n[INFO] OpenAI transcription completed in 4.25s           \u2190 Transcription time\n[DEBUG] Formatting completed in 1245ms                   \u2190 Formatting time\n</code></pre></p> <p>Total pipeline time = 2.20s + 4.25s + 1.25s = ~7.7s</p> <p>Optimization targets: - If conversion is slow (&gt;3s): Check CPU usage, consider different encoder - If transcription is slow (&gt;10s): Check network, try different backend - If formatting is slow (&gt;3s): Try faster model (gpt-3.5-turbo), reduce personalities</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#2-audio-quality-verification","title":"2. Audio Quality Verification","text":"<p>Check Compression: <pre><code>[DEBUG] WAV file size: 2.75 MB\n[DEBUG] MP3 file size: 0.13 MB\n[DEBUG] Compression ratio: 95.4% size reduction\n</code></pre></p> <p>Expectations: - Good compression: 90-96% reduction - Poor compression: &lt;85% reduction (check audio quality settings)</p> <p>Check Format: <pre><code>[DEBUG] WAV format: 2 channel(s), 44100 Hz sample rate\n[DEBUG] Audio downsampled from 44100 Hz to 16000 Hz\n</code></pre></p> <p>Verify: - Channels: Should be 1 (mono) or 2 (stereo) - Sample rate: 44100 Hz is ideal for recording - Downsample to 16000 Hz is normal (Whisper requirement)</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#3-backend-comparison","title":"3. Backend Comparison","text":"<p>Test OpenAI: <pre><code>voice-transcriber -d\n# Make recording\n# Note transcription time: 4.25s\n</code></pre></p> <p>Test Speaches: <pre><code># Edit config: \"backend\": \"speaches\"\n# Reload config\nvoice-transcriber -d\n# Make same recording\n# Note transcription time: 2.18s\n</code></pre></p> <p>Compare: - Speed: Speaches 2.18s vs OpenAI 4.25s (48% faster) - Quality: Compare transcription accuracy - Cost: Speaches free vs OpenAI paid</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#4-troubleshooting","title":"4. Troubleshooting","text":"<p>Problem: Transcription takes too long</p> <p>Debug: <pre><code>[DEBUG] File size: 5.42 MB (5685248 bytes)  \u2190 File too large?\n[INFO] OpenAI transcription completed in 25.5s \u2190 Upload bottleneck?\n</code></pre></p> <p>Solutions: - Reduce recording length (split into chunks) - Check internet speed - Use Speaches locally (no upload time)</p> <p>Problem: Low accuracy</p> <p>Debug: <pre><code>[DEBUG] WAV format: 1 channel(s), 16000 Hz sample rate  \u2190 Low quality?\n[DEBUG] Compression ratio: 82.3% size reduction          \u2190 Bad compression?\n</code></pre></p> <p>Solutions: - Increase recording quality (44100 Hz) - Check microphone settings - Reduce background noise</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#benchmark-mode","title":"Benchmark Mode","text":"<p>NEW in v1.x - Compare OpenAI and Speaches side-by-side.</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#enabling-benchmark-mode","title":"Enabling Benchmark Mode","text":"<p>In <code>config.json</code>: <pre><code>{\n  \"benchmarkMode\": true,\n  \"transcription\": {\n    \"backend\": \"speaches\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\",\n      \"model\": \"whisper-1\"\n    },\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"model\": \"Systran/faster-whisper-medium\"\n    }\n  }\n}\n</code></pre></p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#benchmark-output","title":"Benchmark Output","text":"<pre><code>[INFO] \ud83d\udd2c Benchmark Mode: Transcribing with both OpenAI and Speaches\n\n[INFO] \ud83d\udcca OpenAI Whisper Results:\n[INFO]   \u2514\u2500 Time: 4.25s\n[INFO]   \u2514\u2500 Text: \"Le projet avance bien. Nous avons fait de bons progr\u00e8s.\"\n\n[INFO] \ud83d\udcca Speaches Results:\n[INFO]   \u2514\u2500 Time: 2.18s\n[INFO]   \u2514\u2500 Text: \"Le projet avance bien, nous avons fait de bons progr\u00e8s.\"\n\n[INFO] \u26a1 Performance Comparison:\n[INFO]   \u2514\u2500 Speaches was 48.7% faster (2.07s saved)\n\n[INFO] \ud83d\udcdd Text Similarity:\n[INFO]   \u2514\u2500 Similarity: 94.2%\n[INFO]   \u2514\u2500 Differences found: 2\n[INFO]     - Word 2: \"bien.\" \u2192 \"bien,\"\n[INFO]     - Word 4: \"Nous avons\" \u2192 \"nous avons\"\n\n[INFO] \ud83c\udfaf Selected Result: Speaches (higher similarity to combined text)\n</code></pre>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#interpreting-results","title":"Interpreting Results","text":"<p>Speed: - Faster is better for responsiveness - Speaches usually faster (local processing) - OpenAI may be faster for very short audio (&lt;5s)</p> <p>Similarity: - &gt;95%: Virtually identical - 90-95%: Minor differences (punctuation, capitalization) - &lt;90%: Significant differences (review both)</p> <p>Differences: - Punctuation: Usually insignificant - Capitalization: Can affect meaning - Words: Review for accuracy</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#log-levels","title":"Log Levels","text":"<p>Debug mode shows all log levels:</p> Level Color When Shown Use DEBUG Gray Debug only Technical details INFO White Always Important info WARN Yellow Always Warnings ERROR Red Always Errors","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#example-log-with-all-levels","title":"Example Log with All Levels","text":"<pre><code>2025-10-29T10:30:00.000Z [INFO] Starting recording...\n2025-10-29T10:30:00.005Z [DEBUG] Starting audio recording to: /tmp/transcriber/recording.wav\n2025-10-29T10:30:15.420Z [DEBUG] Stopping audio recording (duration: 15.42s)\n2025-10-29T10:30:15.425Z [INFO] Audio recording stopped and converted to MP3\n2025-10-29T10:30:15.430Z [INFO] Transcribing audio...\n2025-10-29T10:30:19.680Z [INFO] OpenAI transcription completed in 4.25s\n2025-10-29T10:30:19.685Z [WARN] Transcription result is empty (silence detected?)\n2025-10-29T10:30:19.690Z [ERROR] Failed to copy to clipboard: No text to copy\n</code></pre>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#performance-metrics","title":"Performance Metrics","text":"","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#expected-times","title":"Expected Times","text":"<p>Audio Recording (real-time): - 10s recording = 10s elapsed - No processing time</p> <p>WAV to MP3 Conversion: - 10s audio \u2192 ~0.5-2s conversion - Depends on CPU speed</p> <p>Transcription (varies): - OpenAI: ~2-6s for 10s audio - Speaches (local): ~1-3s for 10s audio - Network dependent for OpenAI</p> <p>Formatting: - Single personality: ~500ms-1.5s - Multiple personalities: ~1-2s - Depends on text length and LLM</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#total-pipeline","title":"Total Pipeline","text":"<p>For 30 seconds of audio:</p> <pre><code>Recording:     30.0s (real-time)\nConversion:     1.5s\nTranscription:  5.0s\nFormatting:     1.5s\nClipboard:      0.1s\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal:         38.1s\n</code></pre> <p>Optimization: - Recording: Cannot optimize (real-time) - Conversion: Use faster CPU or reduce quality - Transcription: Use Speaches locally - Formatting: Use faster model or fewer personalities</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#advanced-debugging","title":"Advanced Debugging","text":"","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#enable-extra-verbose-logging","title":"Enable Extra Verbose Logging","text":"<p>For development or deep troubleshooting:</p> <pre><code># Set log level via environment\nLOG_LEVEL=debug voice-transcriber -d\n\n# Or modify logger.ts temporarily\n</code></pre>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#capture-logs-to-file","title":"Capture Logs to File","text":"<pre><code>voice-transcriber -d 2&gt;&amp;1 | tee debug.log\n</code></pre> <p>Analyze later: <pre><code># Find slow operations\ngrep \"completed in\" debug.log\n\n# Find errors\ngrep ERROR debug.log\n\n# Find warnings\ngrep WARN debug.log\n</code></pre></p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#profile-with-timestamps","title":"Profile with timestamps","text":"<p>All logs include ISO timestamps: <pre><code>2025-10-29T10:30:15.420Z [INFO] Transcribing audio...\n2025-10-29T10:30:19.680Z [INFO] OpenAI transcription completed in 4.25s\n</code></pre></p> <p>Calculate exact durations between events.</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#common-debug-patterns","title":"Common Debug Patterns","text":"","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#pattern-1-slow-transcription","title":"Pattern 1: Slow Transcription","text":"<p>Look for: <pre><code>[DEBUG] File size: 8.52 MB (8937472 bytes)  \u2190 Large file\n[INFO] OpenAI transcription completed in 45.2s \u2190 Slow\n</code></pre></p> <p>Likely cause: Large file upload over slow connection</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#pattern-2-empty-transcription","title":"Pattern 2: Empty Transcription","text":"<p>Look for: <pre><code>[WARN] Transcription result is empty (silence detected?)\n[DEBUG] Audio format: 1 channel(s), 44100 Hz\n</code></pre></p> <p>Likely cause: No speech detected or microphone issue</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#pattern-3-format-mismatch","title":"Pattern 3: Format Mismatch","text":"<p>Look for: <pre><code>[DEBUG] WAV format: 1 channel(s), 8000 Hz sample rate  \u2190 Low quality\n[INFO] Transcription accuracy may be reduced\n</code></pre></p> <p>Likely cause: Wrong recording device or settings</p>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#best-practices","title":"Best Practices","text":"","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#dos","title":"Do's \u2705","text":"<ul> <li>Always use debug mode when troubleshooting</li> <li>Save logs for complex issues</li> <li>Compare metrics across recordings</li> <li>Check timestamps to find bottlenecks</li> <li>Use benchmark mode to compare backends</li> </ul>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#donts","title":"Don'ts \u274c","text":"<ul> <li>Don't leave debug on in production (verbose)</li> <li>Don't ignore warnings (they indicate issues)</li> <li>Don't assume (verify with logs)</li> </ul>","tags":["advanced","debugging","development"]},{"location":"advanced/debug-mode/#related-documentation","title":"Related Documentation","text":"<ul> <li>Configuration Management - Config reload and validation</li> <li>Troubleshooting - Common issues</li> <li>Speaches Integration - Local inference setup</li> <li>Whisper Models - Model selection guide</li> </ul> <p>Last updated: 2025-10-29</p>","tags":["advanced","debugging","development"]},{"location":"advanced/local-inference/","title":"Local Inference Roadmap - Whisper Local Transcription","text":"<p>Goal: Implement local Whisper transcription using CPU-only inference for offline usage and cost reduction.</p> <p>Status: \u2705 Implementation Complete - Documentation Pending Priority: High \ud83d\udd25</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#implementation-summary","title":"Implementation Summary","text":"<p>Approach: Speaches (Self-hosted OpenAI-compatible server)</p> <p>Why Speaches: - \u2705 OpenAI API-compatible (drop-in replacement, zero code changes) - \u2705 Docker-based deployment (simple setup) - \u2705 Dynamic model loading (on-demand) - \u2705 Production-ready and actively maintained - \u2705 CPU/GPU support</p> <p>Configuration-Based Routing: <pre><code>{\n  \"transcription\": {\n    \"backend\": \"openai\",  // or \"speaches\"\n    \"openai\": {\n      \"apiKey\": \"sk-...\",\n      \"model\": \"whisper-1\"\n    },\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"apiKey\": \"none\",\n      \"model\": \"Systran/faster-whisper-base\"\n    }\n  }\n}\n</code></pre></p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#deployment-modes","title":"Deployment Modes","text":"","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#1-openai-cloud-default","title":"1. OpenAI Cloud (Default) \u2601\ufe0f","text":"<p><pre><code>{ \"transcription\": { \"backend\": \"openai\" } }\n</code></pre> - \u2705 Zero setup - \u2705 Proven reliability - \u274c Requires internet - \u274c API costs</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#2-speaches-local","title":"2. Speaches Local \ud83c\udfe0","text":"<p><pre><code>{ \"transcription\": { \"backend\": \"speaches\" } }\n</code></pre> - \u2705 100% offline - \u2705 Zero API costs - \u2705 Complete privacy - \u274c Requires Docker</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#3-speaches-remote","title":"3. Speaches Remote \ud83c\udf10","text":"<p><pre><code>{ \n  \"transcription\": { \n    \"backend\": \"speaches\",\n    \"speaches\": {\n      \"url\": \"http://your-server:8000/v1\"\n    }\n  }\n}\n</code></pre> - \u2705 Dedicated resources - \u2705 Multi-user support - \u2705 GPU acceleration - \u274c Requires server setup</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#docker-setup-local","title":"Docker Setup (Local)","text":"<p>docker-compose.speaches.yml: <pre><code>services:\n  speaches:\n    image: ghcr.io/speaches-ai/speaches:latest-cpu\n    restart: unless-stopped\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - ./hf-cache:/home/ubuntu/.cache/huggingface/hub\n    environment:\n      # Keep model loaded in memory forever (zero-latency transcription)\n      - STT_MODEL_TTL=-1\n      # CPU inference configuration\n      - WHISPER__INFERENCE_DEVICE=cpu\n      - WHISPER__COMPUTE_TYPE=int8\n      - WHISPER__CPU_THREADS=8\n      - WHISPER__USE_BATCHED_MODE=true\n    deploy:\n      resources:\n        limits:\n          cpus: '8'\n          memory: 4G\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"--fail\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n</code></pre></p> <p>Commands: <pre><code>docker compose -f docker-compose.speaches.yml up -d\ncurl http://localhost:8000/health\n</code></pre></p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#model-selection","title":"Model Selection","text":"Model Size Memory Use Case Speed tiny 75 MB ~273 MB Fast, lower accuracy Very fast base 142 MB ~388 MB Good balance \u2b50 Fast small 466 MB ~852 MB Better accuracy Medium medium 1.5 GB ~2.1 GB High accuracy Slower large-v3 2.9 GB ~3.9 GB Best accuracy Slowest <p>Recommendation: Use <code>base</code> for voice dictation (fast + good accuracy)</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#implementation-phases","title":"Implementation Phases","text":"","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#phase-41-research-architecture-completed","title":"\u2705 Phase 4.1: Research &amp; Architecture (COMPLETED)","text":"<ul> <li> Research Speaches capabilities</li> <li> Validate OpenAI compatibility</li> <li> Design configuration architecture</li> </ul> <p>Status: Completed - Speaches validated as best solution</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#phase-42-configuration-support-completed","title":"\u2705 Phase 4.2: Configuration Support (COMPLETED)","text":"<p>Goal: Add configuration-based backend selection</p> <p>Implemented Config Schema: <pre><code>{\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\",\n      \"model\": \"whisper-1\"\n    },\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"apiKey\": \"none\",\n      \"model\": \"Systran/faster-whisper-base\"\n    }\n  }\n}\n</code></pre></p> <p>Completed Tasks: - [x] Add <code>transcription.backend</code> field ('openai' | 'speaches') - [x] Add <code>transcription.speaches.url</code> and <code>transcription.speaches.model</code> - [x] Add <code>transcription.openai.apiKey</code> and <code>transcription.openai.model</code> - [x] Update <code>Config.getTranscriptionConfig()</code> to return all fields - [x] Add URL validation for Speaches (<code>validateSpeachesUrl()</code>) - [x] Update <code>config.example.json</code> with new structure - [x] Add tests for new config fields - [x] Add <code>benchmarkMode</code> for side-by-side comparison</p> <p>Files Modified:  - \u2705 <code>src/config/config.ts</code> - Full implementation - \u2705 <code>config.example.json</code> - Updated with new schema - \u2705 <code>src/config/config.test.ts</code> - Tests added</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#phase-43-transcriptionservice-refactor-completed","title":"\u2705 Phase 4.3: TranscriptionService Refactor (COMPLETED)","text":"<p>Goal: Lazy initialization + unified transcription method</p> <p>Implemented Architecture: - \u2705 Lazy client initialization via <code>getClient(backend)</code> - \u2705 <code>initializeSpeaches()</code> with proper async/await and error handling - \u2705 <code>loadSpeachesModel()</code> for model preloading - \u2705 Single unified <code>transcribe()</code> method (no separate methods) - \u2705 <code>warmup()</code> method for startup model preloading</p> <p>Completed Tasks: - [x] Add <code>getClient(backend: 'openai' | 'speaches')</code> method - [x] Implement lazy initialization (clients created on-demand) - [x] Add <code>initializeSpeaches()</code> with full error handling - [x] Add <code>loadSpeachesModel()</code> with POST to <code>/v1/models/{model}</code> - [x] Single <code>transcribe()</code> method supporting both backends - [x] Add <code>warmup()</code> for preloading at startup - [x] Proper error propagation and logging - [x] Add tests for both backends - [x] Add tests for lazy initialization - [x] Add tests for error handling</p> <p>Implementation Details: <pre><code>// Lazy initialization - clients created only when needed\nprivate async getClient(backend: \"openai\" | \"speaches\"): Promise&lt;...&gt;\n\n// Preload Speaches model at startup (called from VoiceTranscriberApp)\npublic async warmup(forceSpeaches = false): Promise&lt;...&gt;\n\n// Single transcribe method - backend determined by config\npublic async transcribe(filePath: string): Promise&lt;...&gt;\n</code></pre></p> <p>Files Modified:  - \u2705 <code>src/services/transcription.ts</code> - Full refactor - \u2705 <code>src/services/transcription.test.ts</code> - Comprehensive tests - \u2705 <code>src/index.ts</code> - Calls <code>warmup()</code> on startup</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#phase-43b-speaches-model-preloading-completed","title":"\u2705 Phase 4.3b: Speaches Model Preloading (COMPLETED)","text":"<p>Goal: Keep model loaded in memory for zero-latency transcription</p> <p>Implementation: 1. Application-level preloading:     - <code>TranscriptionService.warmup()</code> called at app startup    - <code>loadSpeachesModel()</code> POSTs to <code>/v1/models/{model}</code>    - Conditional preload (Speaches backend OR benchmark mode)</p> <ol> <li>Docker-level persistence:</li> <li><code>STT_MODEL_TTL=-1</code> in environment variables (never unload)</li> <li>Healthcheck validates server availability</li> </ol> <p>Completed Tasks: - [x] Implement <code>loadSpeachesModel()</code> with POST to model endpoint - [x] Add <code>warmup()</code> method for startup preloading - [x] Call <code>warmup()</code> from main app when using Speaches - [x] Add <code>STT_MODEL_TTL=-1</code> to docker-compose environment - [x] Docker healthcheck for server availability - [x] Cache directory mounted (<code>./hf-cache</code>)</p> <p>Files Modified:  - \u2705 <code>src/services/transcription.ts</code> - <code>warmup()</code> and <code>loadSpeachesModel()</code> - \u2705 <code>src/index.ts</code> - Calls <code>warmup()</code> on startup - \u2705 <code>docker-compose.speaches.yml</code> - All environment variables included</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#phase-43c-main-application-integration-completed","title":"\u2705 Phase 4.3c: Main Application Integration (COMPLETED)","text":"<p>Goal: Clean architecture with unified processing</p> <p>Implementation: - \u2705 Single <code>processAudioFile()</code> for normal mode - \u2705 Separate <code>processBenchmark()</code> for comparison mode - \u2705 No legacy methods (clean architecture from start) - \u2705 Benchmark mode creates two TranscriptionService instances - \u2705 Detailed comparison metrics (performance, similarity, differences)</p> <p>Completed Tasks: - [x] Implement <code>processAudioFile()</code> using unified transcription - [x] Implement <code>processBenchmark()</code> for side-by-side comparison - [x] Add similarity analysis (Levenshtein distance) - [x] Add text difference detection - [x] Choose best result automatically (longest transcription) - [x] Update tests for new architecture</p> <p>Architecture: <pre><code>// Normal mode: Uses configured backend\nasync processAudioFile(filePath: string): Promise&lt;void&gt;\n\n// Benchmark mode: Compares both backends side-by-side\nasync processBenchmark(filePath: string): Promise&lt;void&gt;\n</code></pre></p> <p>Files Modified:  - \u2705 <code>src/services/audio-processor.ts</code> - Both modes implemented - \u2705 <code>src/services/audio-processor.test.ts</code> - Tests for both modes - \u2705 <code>src/index.ts</code> - Conditional logic based on <code>benchmarkMode</code> - \u2705 <code>src/utils/text-similarity.ts</code> - Similarity utilities</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#phase-44-documentation-partial","title":"\u26a0\ufe0f Phase 4.4: Documentation (PARTIAL)","text":"<p>Goal: Complete user-facing documentation</p> <p>Completed: - [x] <code>docker-compose.speaches.yml</code> with environment variables - [x] <code>config.example.json</code> with new schema - [x] Code documentation (JSDoc comments) - [x] This roadmap document</p> <p>Missing: - [ ] Create <code>docs/SPEACHES_SETUP.md</code> guide - [ ] Update main <code>README.md</code> with Speaches section - [ ] Add troubleshooting guide for Speaches - [ ] Document benchmark mode usage - [ ] Add performance comparison data</p> <p>Priority: \ud83d\udd25 High - Users need setup instructions</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#phase-45-testing-validation-completed","title":"\u2705 Phase 4.5: Testing &amp; Validation (COMPLETED)","text":"<p>Completed: - [x] Unit tests for TranscriptionService - [x] Unit tests for Config - [x] Unit tests for AudioProcessor - [x] Tests for both OpenAI and Speaches backends - [x] Tests for lazy initialization - [x] Tests for error handling - [x] Tests for benchmark mode - [x] Similarity calculation tests</p> <p>Test Coverage: - \u2705 <code>src/config/config.test.ts</code> - Configuration validation - \u2705 <code>src/services/transcription.test.ts</code> - Backend switching - \u2705 <code>src/services/audio-processor.test.ts</code> - Processing workflows - \u2705 <code>src/utils/text-similarity.test.ts</code> - Comparison utilities</p> <p>Manual Testing Needed: - [ ] Real Speaches deployment test - [ ] Model loading performance benchmarks - [ ] Multi-language validation - [ ] Long audio file tests</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#phase-46-release-planned","title":"\ud83d\udccb Phase 4.6: Release (PLANNED)","text":"<p>Goal: Prepare for production release</p> <p>Tasks: - [ ] Complete documentation (Phase 4.4) - [ ] Manual testing with real Speaches instance - [ ] Performance benchmarking documentation - [ ] Update CHANGELOG.md - [ ] Version bump to 0.3.0 - [ ] Git tag and release notes - [ ] Update README badges/status</p> <p>Blocked by: Phase 4.4 (Documentation)</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#implementation-timeline","title":"Implementation Timeline","text":"<p>Total Duration: ~4 days (3.5 days completed)</p> Phase Estimated Actual Status 4.1 Research 1 day 1 day \u2705 Done 4.2 Config 0.5 days 0.5 days \u2705 Done 4.3 Service 0.5 days 1 day \u2705 Done (more comprehensive) 4.3b Preload - 0.5 days \u2705 Done (added scope) 4.3c Integration - 0.5 days \u2705 Done (added scope) 4.4 Docs 1 day - \u26a0\ufe0f Partial 4.5 Testing 1 day 0.5 days \u2705 Done 4.6 Release 0.5 days - \ud83d\udccb Planned <p>Progress: 85% complete (implementation done, documentation pending)</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#additional-features-implemented","title":"Additional Features Implemented","text":"","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#benchmark-mode","title":"\ud83d\udd2c Benchmark Mode","text":"<ul> <li>Compare OpenAI and Speaches side-by-side</li> <li>Performance metrics (speed, duration)</li> <li>Text similarity analysis (Levenshtein distance)</li> <li>Word-level difference detection</li> <li>Automatic best result selection</li> <li>Enable via <code>\"benchmarkMode\": true</code> in config</li> </ul>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#text-similarity-analysis","title":"\ud83c\udfaf Text Similarity Analysis","text":"<ul> <li>Levenshtein distance calculation</li> <li>Character-level and word-level comparison</li> <li>Difference highlighting</li> <li>Similarity percentage scoring</li> </ul>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#zero-latency-transcription","title":"\u26a1 Zero-Latency Transcription","text":"<ul> <li>Model preloading at startup</li> <li>Persistent model in Docker (STT_MODEL_TTL=-1)</li> <li>Lazy client initialization</li> <li>Minimal overhead for second+ transcriptions</li> </ul>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#known-issues-limitations","title":"Known Issues &amp; Limitations","text":"","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#current-limitations","title":"Current Limitations:","text":"<ol> <li>Documentation: Setup guides incomplete (Phase 4.4)</li> <li>Manual Testing: No real-world Speaches deployment tested yet</li> <li>Performance Data: No documented benchmarks yet</li> </ol>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#future-improvements","title":"Future Improvements:","text":"<ol> <li>GPU support documentation</li> <li>Multiple model support (runtime switching)</li> <li>Remote Speaches server examples</li> <li>Performance tuning guide</li> <li>Cost analysis (OpenAI vs self-hosted)</li> </ol>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#next-steps","title":"Next Steps","text":"","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#immediate-phase-44-documentation","title":"Immediate (Phase 4.4 - Documentation):","text":"<ol> <li>Create <code>docs/SPEACHES_SETUP.md</code> comprehensive guide</li> <li>Update main <code>README.md</code> with Speaches section</li> <li>Add troubleshooting section</li> <li>Document benchmark mode</li> </ol>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#before-release-phase-46","title":"Before Release (Phase 4.6):","text":"<ol> <li>Manual test with real Speaches deployment</li> <li>Run benchmark mode with sample audio</li> <li>Document performance results</li> <li>Update CHANGELOG</li> <li>Version bump and release</li> </ol>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/local-inference/#references","title":"References","text":"<ul> <li>Speaches GitHub</li> <li>faster-whisper</li> <li>OpenAI API Docs</li> <li>Docker Docs</li> <li>Levenshtein Distance</li> </ul> <p>Version: v3.0 (Updated with actual implementation status) Last Updated: 2025-01-11 Project Status: \ud83d\udfe2 Implementation Complete - Documentation Pending</p>","tags":["advanced","integration","self-hosted"]},{"location":"advanced/speaches-integration/","title":"Speaches Integration Guide","text":"<p>Complete guide for setting up self-hosted transcription with Speaches.</p>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#why-speaches","title":"Why Speaches?","text":"<ul> <li> <p>\ud83d\udcb0 Zero Cost</p> <p>No API fees - unlimited transcriptions for free</p> </li> <li> <p>\ud83d\udd12 Complete Privacy</p> <p>100% offline - audio never leaves your machine</p> </li> <li> <p>\u26a1 Same Speed</p> <p>Base model performs identically to OpenAI (3.7s vs 3.8s)</p> </li> <li> <p>\ud83c\udfaf High Accuracy</p> <p>91-100% text similarity with OpenAI depending on model</p> </li> </ul>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#quick-setup","title":"Quick Setup","text":"","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#step-1-create-docker-compose-file","title":"Step 1: Create Docker Compose File","text":"<p>Create <code>docker-compose.speaches.yml</code>:</p> <pre><code>services:\n  speaches:\n    image: ghcr.io/speaches-ai/speaches:latest-cpu\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - ./hf-cache:/home/ubuntu/.cache/huggingface/hub\n    environment:\n      - STT_MODEL_TTL=-1  # Keep model in memory\n      - WHISPER__INFERENCE_DEVICE=cpu\n      - WHISPER__COMPUTE_TYPE=int8\n      - WHISPER__CPU_THREADS=8\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n</code></pre>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#step-2-start-speaches","title":"Step 2: Start Speaches","text":"<pre><code>docker compose -f docker-compose.speaches.yml up -d\n</code></pre> <p>First startup: Downloads model (~140MB for base) - takes 1-2 minutes</p>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#step-3-configure-voice-transcriber","title":"Step 3: Configure Voice Transcriber","text":"<p>Edit config:</p> <pre><code>nano ~/.config/voice-transcriber/config.json\n</code></pre> <p>Update:</p> <pre><code>{\n  \"language\": \"fr\",\n  \"formatterEnabled\": false,\n  \"transcription\": {\n    \"backend\": \"speaches\",\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"apiKey\": \"none\",\n      \"model\": \"Systran/faster-whisper-base\"\n    }\n  }\n}\n</code></pre>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#step-4-restart-application","title":"Step 4: Restart Application","text":"<pre><code># Restart Voice Transcriber\nvoice-transcriber\n</code></pre> <p>\u2705 Done! First transcription will auto-download the model.</p>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#available-models","title":"Available Models","text":"Model Size Memory Speed Accuracy Use Case tiny 75 MB ~273 MB \u26a1\u26a1\u26a1 \u2b50\u2b50 Quick testing base \u2b50 142 MB ~388 MB \u26a1\u26a1 \u2b50\u2b50\u2b50 Recommended small 466 MB ~852 MB \u26a1 \u2b50\u2b50\u2b50\u2b50 Better accuracy medium 1.5 GB ~2.1 GB \ud83d\udc22 \u2b50\u2b50\u2b50\u2b50\u2b50 High accuracy large-v3 2.9 GB ~3.9 GB \ud83d\udc22\ud83d\udc22 \u2b50\u2b50\u2b50\u2b50\u2b50 Maximum accuracy <p>Recommendation: Base Model</p> <ul> <li>Comparable speed to OpenAI (0.97x)</li> <li>91% accuracy - excellent for daily use</li> <li>Low resource usage (~400MB RAM)</li> <li>Zero cost</li> </ul>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#performance-comparison","title":"Performance Comparison","text":"<p>Benchmark: 30s French audio, Remote server (8 CPU / 8GB RAM)</p> <p>Real-World Performance Benchmark:</p> Model OpenAI Whisper Speaches (CPU) Speed Ratio Text Similarity tiny 1.98s 2.81s 0.70x (comparable) 92.4% base \u2b50 3.70s 3.81s 0.97x (comparable) 91.4% small 2.23s 7.15s 0.31x (3x slower) 97.4% medium 3.70s 25.82s 0.14x (7x slower) 96.1% large-v3 2.55s 30.80s 0.08x (12x slower) 100.0% <p>Key Insights:</p> <ul> <li>Base model: Nearly identical speed to OpenAI (0.97x), 91% accuracy - best for daily use</li> <li>Small model: Excellent 97% accuracy, acceptable 3x slowdown</li> <li>Medium/Large: Maximum quality (96-100%) but significantly slower (7-12x)</li> </ul> <p>Recommendations:</p> <ul> <li>For speed &amp; cost: Use <code>base</code> model - nearly identical speed to OpenAI, 91% accuracy, zero cost</li> <li>For accuracy: Use <code>small</code> model - excellent 97% accuracy, acceptable 3x slower</li> <li>For maximum quality: Use <code>medium</code> or <code>large-v3</code> - 96-100% accuracy but significantly slower (7-12x)</li> </ul> <p>Performance Context</p> <p>Performance tested on remote server (8 CPU cores, 8GB RAM). GPU acceleration would significantly improve medium/large model speeds (5-10x faster). Tiny and base models are CPU-optimized and run efficiently without GPU.</p>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#changing-models","title":"Changing Models","text":"<p>Edit config to use different model:</p> <pre><code>{\n  \"transcription\": {\n    \"backend\": \"speaches\",\n    \"speaches\": {\n      \"model\": \"Systran/faster-whisper-small\"\n    }\n  }\n}\n</code></pre> <p>Available models: - <code>Systran/faster-whisper-tiny</code> - <code>Systran/faster-whisper-base</code> \u2b50 - <code>Systran/faster-whisper-small</code> - <code>Systran/faster-whisper-medium</code> - <code>Systran/faster-whisper-large-v3</code></p> <p>Restart application for changes to take effect.</p>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#gpu-acceleration","title":"GPU Acceleration","text":"<p>For significantly faster processing with medium/large models:</p> <pre><code>services:\n  speaches:\n    image: ghcr.io/speaches-ai/speaches:latest-cuda  # GPU image\n    runtime: nvidia\n    environment:\n      - WHISPER__INFERENCE_DEVICE=cuda\n      - WHISPER__COMPUTE_TYPE=float16\n</code></pre> <p>Requirements: NVIDIA GPU with CUDA support</p>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#troubleshooting","title":"Troubleshooting","text":"","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#model-download-fails","title":"Model Download Fails","text":"<pre><code># Check logs\ndocker compose -f docker-compose.speaches.yml logs -f speaches\n</code></pre> <p>Solution: Ensure internet connection for initial download</p>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#service-not-responding","title":"Service Not Responding","text":"<pre><code># Check health\ncurl http://localhost:8000/health\n\n# Restart service\ndocker compose -f docker-compose.speaches.yml restart\n</code></pre>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#out-of-memory","title":"Out of Memory","text":"<p>Solution: Use smaller model or increase Docker memory limit</p> <pre><code>services:\n  speaches:\n    deploy:\n      resources:\n        limits:\n          memory: 4G  # Increase memory\n</code></pre>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#advanced-configuration","title":"Advanced Configuration","text":"","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#custom-whisper-parameters","title":"Custom Whisper Parameters","text":"<pre><code>environment:\n  - WHISPER__BEAM_SIZE=5\n  - WHISPER__BEST_OF=5\n  - WHISPER__TEMPERATURE=0.0\n</code></pre>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#remote-speaches-server","title":"Remote Speaches Server","text":"<p>Run Speaches on a VPS and connect remotely:</p> <pre><code>{\n  \"transcription\": {\n    \"backend\": \"speaches\",\n    \"speaches\": {\n      \"url\": \"https://your-server.com/v1\",\n      \"apiKey\": \"your-api-key\",\n      \"model\": \"Systran/faster-whisper-base\"\n    }\n  }\n}\n</code></pre>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#cost-comparison","title":"Cost Comparison","text":"<p>OpenAI Whisper: - $0.006 per minute - 100 hours = $36/month - No local resources needed</p> <p>Speaches (Self-Hosted): - \\(0 transcription cost - VPS: ~\\)5-10/month (optional) - Requires local/VPS resources</p> <p>Break-Even Point</p> <p>After ~100 hours of transcription, Speaches becomes more cost-effective than OpenAI.</p>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/speaches-integration/#next-steps","title":"Next Steps","text":"<ul> <li>Whisper Models Comparison - Detailed model benchmarks</li> <li>Transcription Backends - Backend comparison</li> <li>Configuration Guide - Advanced settings</li> </ul> <p>Need Help?</p> <ul> <li>Speaches Documentation</li> <li>Voice Transcriber Issues</li> </ul>","tags":["advanced","integration","backends","self-hosted"]},{"location":"advanced/whisper-models/","title":"Faster-Whisper Models Comparison","text":"","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#model-variants-overview","title":"Model Variants Overview","text":"Model Parameters Multilingual English-Only Distilled tiny 39M \u2705 \u2705 <code>.en</code> \u274c base 74M \u2705 \u2705 <code>.en</code> \u274c small 244M \u2705 \u2705 <code>.en</code> \u2705 <code>distil-*.en</code> medium 769M \u2705 \u2705 <code>.en</code> \u2705 <code>distil-*.en</code> large-v3 1550M \u2705 \u274c \u2705 <code>distil-*</code>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#quick-selection-guide","title":"Quick Selection Guide","text":"","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#base-recommended-default","title":"Base (recommended default) \u2b50","text":"<ul> <li>Good balance speed/accuracy</li> <li>74M parameters</li> <li>Use for: voice dictation, development</li> </ul>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#small-better-quality","title":"Small (better quality)","text":"<ul> <li>Better accuracy</li> <li>244M parameters</li> <li>Use for: production, professional apps</li> </ul>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#medium-high-quality","title":"Medium (high quality)","text":"<ul> <li>High accuracy</li> <li>769M parameters</li> <li>Use for: meetings, subtitling</li> </ul>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#large-v3-maximum-quality","title":"Large-v3 (maximum quality)","text":"<ul> <li>Best accuracy</li> <li>1550M parameters</li> <li>Use for: critical apps (legal, medical)</li> </ul>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#distilled-distil-","title":"Distilled (<code>distil-*</code>)","text":"<ul> <li>30-50% faster</li> <li>Similar accuracy (~1-3% WER difference)</li> <li>Available: small.en, medium.en, large-v2, large-v3</li> </ul>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#english-only-en","title":"English-only (<code>.en</code>)","text":"<ul> <li>English transcription only</li> <li>20-30% faster than multilingual</li> <li>Better English accuracy</li> </ul>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#performance-comparison","title":"Performance Comparison","text":"Model CPU Time* Memory (RAM) Speed Accuracy tiny 1x ~1 GB \u26a1\u26a1\u26a1\u26a1\u26a1 \u2b50\u2b50 base 2x ~1 GB \u26a1\u26a1\u26a1\u26a1 \u2b50\u2b50\u2b50 small 5x ~2 GB \u26a1\u26a1\u26a1 \u2b50\u2b50\u2b50\u2b50 medium 12x ~5 GB \u26a1\u26a1 \u2b50\u2b50\u2b50\u2b50\u2b50 large-v3 30x ~10 GB \u26a1 \u2b50\u2b50\u2b50\u2b50\u2b50\u2b50 <p>*Relative to tiny model on 1 minute of audio</p>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#speaches-integration","title":"Speaches Integration","text":"<p>Dynamic model loading (specify in API request):</p> <pre><code>// In transcription.ts\nconst transcription = await openai.audio.transcriptions.create({\n  file: audioFile,\n  model: 'base',  // or 'small', 'medium', 'large-v3', etc.\n  language: 'en'\n});\n</code></pre> <p>Available models: - <code>tiny</code>, <code>tiny.en</code> - <code>base</code>, <code>base.en</code> - <code>small</code>, <code>small.en</code> - <code>medium</code>, <code>medium.en</code> - <code>large-v1</code>, <code>large-v2</code>, <code>large-v3</code> - <code>distil-small.en</code>, <code>distil-medium.en</code> - <code>distil-large-v2</code>, <code>distil-large-v3</code></p> <p>Models are auto-downloaded on first use.</p>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#recommendations-by-use-case","title":"Recommendations by Use Case","text":"Use Case Model Why Voice dictation <code>base</code> or <code>small</code> Fast + good accuracy Meetings <code>medium</code> High accuracy + multi-speaker Real-time <code>tiny.en</code> or <code>base.en</code> Low latency Critical <code>large-v3</code> Maximum accuracy Development <code>base</code> Fast iteration","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#language-support","title":"Language Support","text":"<p>Multilingual (99+ languages): - Western European: en, fr, de, es, it, pt - Eastern European: ru, pl, uk, cs - Asian: zh, ja, ko, hi, ar</p> <p>English-only (<code>.en</code> suffix): - Cannot transcribe other languages - 20-30% faster for English - Smaller model size</p>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#configuration","title":"Configuration","text":"<pre><code>{\n  \"language\": \"en\",\n  \"formatterEnabled\": true,\n  \"transcription\": {\n    \"backend\": \"speaches\",\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"apiKey\": \"none\",\n      \"model\": \"Systran/faster-whisper-base\"\n    }\n  }\n}\n</code></pre>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#related-pages","title":"Related Pages","text":"<ul> <li>Speaches Integration - Setup guide for self-hosted transcription</li> <li>Transcription Backends - Compare OpenAI vs Speaches</li> <li>Configuration Guide - How to configure models</li> </ul>","tags":["advanced","reference","transcription","backends"]},{"location":"advanced/whisper-models/#references","title":"References","text":"<ul> <li>Faster-Whisper GitHub</li> <li>Hugging Face Collection</li> <li>Speaches</li> </ul> <p>Version: v2.0 Last Updated: 2025-10-11</p>","tags":["advanced","reference","transcription","backends"]},{"location":"development/api-reference/","title":"Voice Transcriber - API Reference","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#overview","title":"Overview","text":"<p>This document provides detailed API reference for all services and interfaces in the Voice Transcriber application. All services follow consistent patterns with simple interfaces and standardized error handling.</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#common-patterns","title":"Common Patterns","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#result-interface","title":"Result Interface","text":"<p>All service methods return a consistent result interface:</p> <pre><code>interface ServiceResult {\n  success: boolean;\n  error?: string;\n  // Additional data fields specific to the operation\n}\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#error-handling","title":"Error Handling","text":"<ul> <li>Services never throw exceptions in normal operation</li> <li>All errors are returned via the result interface</li> <li>Error messages are user-friendly and actionable</li> <li>Logging is handled internally by each service</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#core-application","title":"Core Application","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#voicetranscriberapp","title":"VoiceTranscriberApp","text":"<p>Main application class that orchestrates all services.</p> <pre><code>class VoiceTranscriberApp {\n  constructor(configPath?: string)\n\n  // Lifecycle Methods\n  initialize(): Promise&lt;{ success: boolean; error?: string }&gt;\n  shutdown(): Promise&lt;void&gt;\n\n  // Private Event Handlers (called by system tray)\n  private handleRecordingStart(): Promise&lt;void&gt;\n  private handleRecordingStop(): Promise&lt;void&gt;\n  private handleQuit(): Promise&lt;void&gt;\n  private processAudioFile(filePath: string): Promise&lt;void&gt;\n}\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#methods","title":"Methods","text":"<p><code>initialize()</code> - Loads configuration with setup wizard if needed - Initializes all services with proper dependency injection - Sets up system tray with event callbacks - Returns initialization result</p> <p><code>shutdown()</code> - Stops any active recording - Cleanly shuts down system tray - Performs cleanup operations</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#configuration-service","title":"Configuration Service","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#config","title":"Config","text":"<p>Manages application configuration with user-friendly setup.</p> <pre><code>interface ConfigData {\n  openaiApiKey: string;\n  formatterEnabled: boolean;\n}\n\nclass Config {\n  openaiApiKey: string;\n  formatterEnabled: boolean;\n\n  constructor(configPath?: string)\n\n  // Configuration Methods\n  load(): Promise&lt;void&gt;\n  loadWithSetup(): Promise&lt;void&gt;\n  save(): Promise&lt;void&gt;\n\n  // Private Methods\n  private setupWizard(): Promise&lt;void&gt;\n  private promptForApiKey(): Promise&lt;string&gt;\n  private getUserConfigPath(): string\n  private getUserConfigDir(): string\n}\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#methods_1","title":"Methods","text":"<p><code>load()</code> - Loads configuration from JSON file - Uses defaults if file doesn't exist or is invalid - Silent failure with default values</p> <p><code>loadWithSetup()</code> - Loads configuration - Runs setup wizard for first-time users - Creates config directory and file as needed</p> <p><code>save()</code> - Saves current configuration to JSON file - Creates config directory if needed - Overwrites existing configuration</p> <p><code>setupWizard()</code> - Interactive first-run setup - Prompts for OpenAI API key - Creates initial configuration file</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#configuration-paths","title":"Configuration Paths","text":"<ul> <li>Default: <code>~/.config/voice-transcriber/config.json</code></li> <li>Custom: Provided via constructor parameter</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#system-tray-service","title":"System Tray Service","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#systemtrayservice","title":"SystemTrayService","text":"<p>Manages system tray integration with visual state feedback.</p> <pre><code>enum TrayState {\n  IDLE = \"idle\",\n  RECORDING = \"recording\",\n  PROCESSING = \"processing\"\n}\n\ninterface TrayConfig {\n  callbacks: {\n    onRecordingStart: () =&gt; void;\n    onRecordingStop: () =&gt; void;\n    onQuit: () =&gt; void;\n  };\n}\n\ninterface TrayResult {\n  success: boolean;\n  error?: string;\n}\n\nclass SystemTrayService {\n  constructor(config: TrayConfig, systrayConstructor?: typeof SysTray)\n\n  // Public Methods\n  initialize(): Promise&lt;TrayResult&gt;\n  setState(state: TrayState): Promise&lt;TrayResult&gt;\n  shutdown(): Promise&lt;TrayResult&gt;\n\n  // Private Methods\n  private getIconBase64(state: TrayState): string\n  private getTooltip(state: TrayState): string\n}\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#methods_2","title":"Methods","text":"<p><code>initialize()</code> - Creates system tray with menu items - Sets up click event handlers - Waits for tray to be ready - Returns initialization result</p> <p><code>setState(state: TrayState)</code> - Updates tray icon based on application state - Modifies menu item availability - Updates tooltip text - Handles icon recreation for state changes</p> <p><code>shutdown()</code> - Cleanly destroys system tray - Releases system resources</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#states-and-icons","title":"States and Icons","text":"<ul> <li>IDLE: Green circle - Ready to record</li> <li>RECORDING: Red circle - Actively recording</li> <li>PROCESSING: Purple circle - Transcribing audio</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#menu-items","title":"Menu Items","text":"<ul> <li>\ud83c\udfa4 Start Recording: Enabled when IDLE</li> <li>\u23f9\ufe0f Stop Recording: Enabled when RECORDING</li> <li>\u274c Exit: Always enabled</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#audio-recording-service","title":"Audio Recording Service","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#audiorecorder","title":"AudioRecorder","text":"<p>Handles system audio capture using Linux arecord.</p> <pre><code>interface AudioRecorderConfig {\n  tempDir?: string;\n}\n\ninterface RecordingResult {\n  success: boolean;\n  filePath?: string;\n  error?: string;\n}\n\nclass AudioRecorder {\n  constructor(config?: AudioRecorderConfig)\n\n  // Public Methods\n  startRecording(): Promise&lt;RecordingResult&gt;\n  stopRecording(): Promise&lt;RecordingResult&gt;\n  isRecording(): boolean\n}\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#methods_3","title":"Methods","text":"<p><code>startRecording()</code> - Creates temporary directory if needed - Generates timestamped filename - Spawns arecord process with CD quality settings - Returns recording result with file path</p> <p><code>stopRecording()</code> - Sends SIGTERM to arecord process - Cleans up process references - Returns result with final file path</p> <p><code>isRecording()</code> - Returns true if recording process is active - Used for state validation</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#audio-format","title":"Audio Format","text":"<ul> <li>Format: WAV (CD quality)</li> <li>Sample Rate: 44.1kHz</li> <li>Bit Depth: 16-bit</li> <li>Channels: Stereo</li> <li>Device: ALSA default input</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#file-management","title":"File Management","text":"<ul> <li>Location: <code>/tmp/transcriber/recording-{timestamp}.wav</code></li> <li>Naming: ISO timestamp with safe characters</li> <li>Cleanup: Manual cleanup required (handled by main app)</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#transcription-service","title":"Transcription Service","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#transcriptionservice","title":"TranscriptionService","text":"<p>Converts audio files to text using OpenAI Whisper API.</p> <pre><code>interface TranscriptionConfig {\n  apiKey: string;\n  language?: string;\n  prompt?: string;\n}\n\ninterface TranscriptionResult {\n  success: boolean;\n  text?: string;\n  error?: string;\n}\n\nclass TranscriptionService {\n  constructor(config: TranscriptionConfig)\n\n  // Public Methods\n  transcribe(filePath: string): Promise&lt;TranscriptionResult&gt;\n}\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#methods_4","title":"Methods","text":"<p><code>transcribe(filePath: string)</code> - Validates audio file exists - Creates read stream for file upload - Calls OpenAI Whisper API with optimized settings - Returns transcribed text or error</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#configuration","title":"Configuration","text":"<p>Default Settings: <pre><code>{\n  language: undefined,  // Auto-detect French/English\n  prompt: \"Please transcribe this audio exactly as spoken, preserving the original language. The speaker may mix French and English in the same sentence. Keep technical terms in their original language (English), but preserve French sentence structure and grammar. Do not translate between languages.\"\n}\n</code></pre></p> <p>API Parameters: - Model: <code>whisper-1</code> (OpenAI's production model) - Language: Auto-detect if undefined - Prompt: Enhanced for French/English mixed speech</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#multilingual-support","title":"Multilingual Support","text":"<ul> <li>Auto-Detection: Automatic language identification</li> <li>Mixed Speech: Preserves French/English code-switching</li> <li>Technical Terms: Keeps English technical vocabulary</li> <li>Grammar: Maintains original language sentence structure</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#text-formatting-service","title":"Text Formatting Service","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#formatterservice","title":"FormatterService","text":"<p>Optional text enhancement using ChatGPT API.</p> <pre><code>interface FormatterConfig {\n  apiKey: string;\n  enabled: boolean;\n  language: string;\n  prompt?: string;\n}\n\ninterface FormatResult {\n  success: boolean;\n  text?: string;\n  error?: string;\n}\n\nclass FormatterService {\n  constructor(config: FormatterConfig)\n\n  // Public Methods\n  formatText(text: string, language: string): Promise&lt;FormatResult&gt;\n}\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#methods_5","title":"Methods","text":"<p><code>formatText(text: string, language: string)</code> - Returns original text if formatting disabled - Validates input text is not empty - Calls ChatGPT API for text enhancement - Uses language-specific prompt to preserve original language - Returns formatted text or error</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#configuration_1","title":"Configuration","text":"<p>Default Settings: <pre><code>{\n  prompt: null,  // Uses auto-generated language-aware prompt\n  enabled: true,\n  language: \"en\" // Supported: en, fr, es, de, it\n}\n</code></pre></p> <p>Auto-generated prompts (when prompt is null): - Maintains the specified language - Prevents translation to other languages - Preserves original meaning and tone</p> <p>API Parameters: - Model: <code>gpt-3.5-turbo</code> (fast and cost-effective) - Temperature: 0.3 (consistent, low-creativity output) - Max Tokens: 1000 (sufficient for typical transcriptions)</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#text-enhancement","title":"Text Enhancement","text":"<ul> <li>Grammar: Corrects grammatical errors</li> <li>Punctuation: Adds proper punctuation</li> <li>Language Preservation: Maintains original language (French/English/Spanish/German/Italian)</li> <li>Structure: Improves text structure and flow</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#clipboard-service","title":"Clipboard Service","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#clipboardservice","title":"ClipboardService","text":"<p>Cross-platform clipboard operations.</p> <pre><code>interface ClipboardResult {\n  success: boolean;\n  error?: string;\n}\n\nclass ClipboardService {\n  // Public Methods\n  writeText(text: string): Promise&lt;ClipboardResult&gt;\n}\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#methods_6","title":"Methods","text":"<p><code>writeText(text: string)</code> - Validates input text is not empty - Writes text to system clipboard - Returns operation result</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#platform-support","title":"Platform Support","text":"<ul> <li>Linux: Uses <code>clipboardy</code> with xsel/xclip backend</li> <li>Windows: Native Windows clipboard API</li> <li>macOS: Native macOS clipboard API</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#logging-service","title":"Logging Service","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#logger","title":"Logger","text":"<p>Simple console-based logging utility.</p> <pre><code>interface Logger {\n  info(message: string): void\n  error(message: string): void\n}\n\nconst logger: Logger\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#methods_7","title":"Methods","text":"<p><code>info(message: string)</code> - Logs informational messages to console - Includes timestamp and formatted output</p> <p><code>error(message: string)</code> - Logs error messages to console - Includes timestamp and error formatting</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#log-levels","title":"Log Levels","text":"<ul> <li>INFO: General application flow and status</li> <li>ERROR: Errors and exceptions</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#output-format","title":"Output Format","text":"<pre><code>[TIMESTAMP] [LEVEL] MESSAGE\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#error-codes-and-messages","title":"Error Codes and Messages","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#common-error-patterns","title":"Common Error Patterns","text":"<p>Configuration Errors: - <code>\"OpenAI API key not configured\"</code> - <code>\"Config file could not be loaded\"</code></p> <p>Audio Recording Errors: - <code>\"Already recording\"</code> - <code>\"Not recording\"</code> - <code>\"Failed to start recording: {details}\"</code></p> <p>Transcription Errors: - <code>\"Audio file does not exist\"</code> - <code>\"No transcription text received\"</code> - <code>\"Failed to transcribe audio: {details}\"</code></p> <p>System Tray Errors: - <code>\"System tray not initialized\"</code> - <code>\"Failed to initialize: {details}\"</code></p> <p>Clipboard Errors: - <code>\"Text cannot be empty\"</code> - <code>\"Failed to write to clipboard: {details}\"</code></p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#api-rate-limiting","title":"API Rate Limiting","text":"<p>The application does not implement automatic retry logic. Rate limiting is handled by: - Using conservative API call patterns - Single transcription per recording session - Optional formatting (can be disabled)</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#network-error-handling","title":"Network Error Handling","text":"<p>Network errors are returned as operation failures: - Connection timeouts - Invalid API keys - Service unavailable - Rate limit exceeded</p>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#usage-examples","title":"Usage Examples","text":"","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#basic-application-lifecycle","title":"Basic Application Lifecycle","text":"<pre><code>// Initialize application\nconst app = new VoiceTranscriberApp();\nconst result = await app.initialize();\n\nif (!result.success) {\n  console.error(result.error);\n  process.exit(1);\n}\n\n// Application runs via system tray events\n// Shutdown when needed\nawait app.shutdown();\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#custom-configuration","title":"Custom Configuration","text":"<pre><code>// Load custom config path\nconst config = new Config('/path/to/custom/config.json');\nawait config.load();\n\n// Modify settings\nconfig.formatterEnabled = false;\nawait config.save();\n\n// Use with application\nconst app = new VoiceTranscriberApp('/path/to/custom/config.json');\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#manual-service-usage","title":"Manual Service Usage","text":"<pre><code>// Direct transcription service usage\nconst transcriber = new TranscriptionService({\n  apiKey: 'your-api-key'\n});\n\nconst result = await transcriber.transcribe('/path/to/audio.wav');\nif (result.success) {\n  console.log('Transcription:', result.text);\n}\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#error-handling-pattern","title":"Error Handling Pattern","text":"<pre><code>// Consistent error handling across all services\nconst result = await service.someOperation();\n\nif (!result.success) {\n  logger.error(`Operation failed: ${result.error}`);\n  // Handle error appropriately\n  return;\n}\n\n// Use result.data if operation succeeded\nconsole.log('Success:', result.data);\n</code></pre>","tags":["expert","reference","development","api"]},{"location":"development/api-reference/#related-pages","title":"Related Pages","text":"<ul> <li>Technical Architecture - System architecture and design principles</li> <li>Testing Guide - How to test services and write unit tests</li> <li>Development Guide - Development workflow and setup</li> <li>Configuration Guide - Configuration schema and options</li> </ul>","tags":["expert","reference","development","api"]},{"location":"development/architecture/","title":"Voice Transcriber - Technical Architecture","text":"","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#overview","title":"Overview","text":"<p>Voice Transcriber is a lightweight desktop application that provides seamless voice-to-text conversion with system tray integration. The application follows a service-oriented architecture with clear separation of concerns and minimal dependencies.</p>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#core-architecture-principles","title":"Core Architecture Principles","text":"","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#1-simplicity-first","title":"1. Simplicity First","text":"<ul> <li>Each service has 3-5 core methods maximum</li> <li>Simple interfaces: <code>{ success: boolean, error?: string }</code></li> <li>No overengineering or complex retry logic</li> <li>Console logging only (info/error levels)</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#2-service-oriented-design","title":"2. Service-Oriented Design","text":"<ul> <li>Clear separation of concerns</li> <li>Dependency injection for testability</li> <li>Consistent error handling patterns</li> <li>Graceful degradation when services fail</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#3-user-centric-approach","title":"3. User-Centric Approach","text":"<ul> <li>First-run setup wizard</li> <li>Visual feedback via system tray states</li> <li>Automatic clipboard integration</li> <li>Multilingual support (French/English auto-detection)</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#system-components","title":"System Components","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                Main Application                     \u2502\n\u2502            (VoiceTranscriberApp)                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502         \u2502         \u2502\n        \u25bc         \u25bc         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   System    \u2502 \u2502    Audio    \u2502 \u2502   Configuration \u2502\n\u2502    Tray     \u2502 \u2502  Recording  \u2502 \u2502     Service     \u2502\n\u2502   Service   \u2502 \u2502   Service   \u2502 \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                              \u2502\n        \u25bc                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Clipboard  \u2502                \u2502  OpenAI API     \u2502\n\u2502   Service   \u2502                \u2502   Services      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502                 \u2502\n                               \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n                               \u2502 \u2502Transcription\u2502 \u2502\n                               \u2502 \u2502   Service   \u2502 \u2502\n                               \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n                               \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n                               \u2502 \u2502 Formatter   \u2502 \u2502\n                               \u2502 \u2502   Service   \u2502 \u2502\n                               \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#service-descriptions","title":"Service Descriptions","text":"","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#main-application-srcindexts","title":"Main Application (<code>src/index.ts</code>)","text":"<p>Purpose: Central orchestrator that manages all services and application lifecycle.</p> <p>Key Responsibilities: - Service initialization and dependency injection - Event handling and workflow coordination - Error management and recovery - Graceful shutdown handling</p> <p>State Machine: <pre><code>IDLE \u2192 RECORDING \u2192 PROCESSING \u2192 IDLE\n  \u2191                              \u2193\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 ERROR \u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#system-tray-service-srcservicessystem-trayts","title":"System Tray Service (<code>src/services/system-tray.ts</code>)","text":"<p>Purpose: Manages system tray integration with visual state feedback.</p> <p>Features: - Three visual states with distinct icons:   - \ud83d\udfe2 IDLE: Green circle (ready to record)   - \ud83d\udd34 RECORDING: Red circle (actively recording)   - \ud83d\udfe3 PROCESSING: Purple circle (transcribing audio) - Click-to-record functionality - Context menu with Start/Stop/Exit options - Cross-platform icon compatibility (Base64 encoded)</p> <p>Icon Management: - Icons embedded as Base64 strings for npm distribution - Automatic menu state updates based on recording status - Workaround for node-systray-v2 double icon issues</p>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#audio-recording-service-srcservicesaudio-recorderts","title":"Audio Recording Service (<code>src/services/audio-recorder.ts</code>)","text":"<p>Purpose: Handles system audio capture using Linux arecord.</p> <p>Features: - Spawns arecord process for high-quality audio capture - Temporary file management in system temp directory - Process lifecycle management (start/stop/cleanup) - CD-quality WAV format (44.1kHz, 16-bit)</p> <p>System Dependencies: <pre><code># Required for audio recording\nsudo apt-get install alsa-utils\n</code></pre></p>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#transcription-service-srcservicestranscriptionts","title":"Transcription Service (<code>src/services/transcription.ts</code>)","text":"<p>Purpose: Converts audio files to text using OpenAI Whisper API.</p> <p>Features: - Automatic language detection (French/English mixed speech) - Enhanced prompting for preserving original language structure - Technical term preservation in mixed-language contexts - Robust error handling for API failures</p> <p>Configuration: <pre><code>{\n  apiKey: string;           // OpenAI API key\n  language?: string;        // Auto-detect if undefined\n  prompt?: string;          // Custom transcription prompt\n}\n</code></pre></p>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#formatter-service-srcservicesformatterts","title":"Formatter Service (<code>src/services/formatter.ts</code>)","text":"<p>Purpose: Optional text enhancement using ChatGPT API.</p> <p>Features: - Grammar and punctuation improvement - Language preservation (French/English/Spanish/German/Italian) - Configurable enable/disable - Temperature-controlled generation (0.3 for consistency)</p>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#configuration-service-srcconfigconfigts","title":"Configuration Service (<code>src/config/config.ts</code>)","text":"<p>Purpose: Manages application configuration with user-friendly setup.</p> <p>Features: - User config directory (<code>~/.config/voice-transcriber/</code>) - Interactive first-run setup wizard - API key validation and storage - JSON-based configuration file</p> <p>Config Location: <pre><code>~/.config/voice-transcriber/config.json\n</code></pre></p>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#clipboard-service-srcservicesclipboardts","title":"Clipboard Service (<code>src/services/clipboard.ts</code>)","text":"<p>Purpose: Cross-platform clipboard operations.</p> <p>Features: - Automatic text copying after transcription - Cross-platform compatibility (Linux/Windows/macOS) - Simple success/error feedback</p>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#data-flow","title":"Data Flow","text":"","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#recording-workflow","title":"Recording Workflow","text":"<pre><code>1. User clicks tray icon\n   \u2193\n2. System tray \u2192 RECORDING state\n   \u2193\n3. Audio recorder starts arecord process\n   \u2193\n4. User clicks again to stop\n   \u2193\n5. System tray \u2192 PROCESSING state\n   \u2193\n6. Audio file saved to temp directory (WAV format)\n   \u2193\n7. MP3 Encoder converts WAV to MP3 (~75% compression)\n   \u2193\n8. Transcription service \u2192 Whisper API (OpenAI or Speaches)\n   \u2193\n9. [Optional] Formatter service \u2192 ChatGPT API\n   \u2193\n10. Clipboard service writes final text\n   \u2193\n11. System tray \u2192 IDLE state\n</code></pre>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#error-handling-flow","title":"Error Handling Flow","text":"<pre><code>Error occurs in any service\n   \u2193\nService returns { success: false, error: string }\n   \u2193\nMain application logs error\n   \u2193\nSystem tray returns to IDLE state\n   \u2193\nUser can retry operation\n</code></pre>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#technology-stack","title":"Technology Stack","text":"","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#runtime-build","title":"Runtime &amp; Build","text":"<ul> <li>Development: Bun \u22651.2.0 with TypeScript</li> <li>Production: Node.js \u226522 (npm distribution)</li> <li>Build: Bun bundler for single-file distribution</li> <li>Package Management: Bun for development, npm for distribution</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#core-dependencies","title":"Core Dependencies","text":"<pre><code>{\n  \"openai\": \"^5.11.0\",              // OpenAI API integration\n  \"node-systray-v2\": \"...\",         // System tray (improved fork)\n  \"clipboardy\": \"^4.0.0\"            // Cross-platform clipboard\n}\n</code></pre>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#system-requirements","title":"System Requirements","text":"<ul> <li>Linux: Ubuntu 22.04+ with alsa-utils and xsel</li> <li>Audio: ALSA-compatible sound system</li> <li>Desktop: System tray support (GNOME, KDE, XFCE)</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#performance-characteristics","title":"Performance Characteristics","text":"","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#memory-usage","title":"Memory Usage","text":"<ul> <li>Base: ~50MB (Node.js runtime + dependencies)</li> <li>Recording: +10MB (audio buffer)</li> <li>Processing: +20MB (API requests/responses)</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#api-usage","title":"API Usage","text":"<ul> <li>Whisper: ~$0.006 per minute of audio</li> <li>GPT-3.5-turbo: ~$0.002 per transcription formatting</li> <li>Rate Limits: Respects OpenAI API limits (no built-in retry)</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#file-system","title":"File System","text":"<ul> <li>Temp Files: Created in <code>/tmp/transcriber/</code></li> <li>Config: Stored in <code>~/.config/voice-transcriber/</code></li> <li>Cleanup: Automatic temp file cleanup on process exit</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#security-considerations","title":"Security Considerations","text":"","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#api-key-management","title":"API Key Management","text":"<ul> <li>Config file permissions: 600 (user read/write only)</li> <li>API key validation on startup</li> <li>No API key logging or exposure</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#audio-privacy","title":"Audio Privacy","text":"<ul> <li>Local audio processing only</li> <li>Temporary files cleaned up automatically</li> <li>No persistent audio storage</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#system-integration","title":"System Integration","text":"<ul> <li>Minimal system permissions required</li> <li>No elevated privileges needed</li> <li>Sandboxed execution environment</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#testing-strategy","title":"Testing Strategy","text":"","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#test-coverage","title":"Test Coverage","text":"<ul> <li>Unit Tests: 37 tests across all services</li> <li>Integration Tests: Full workflow validation</li> <li>Mock Strategy: Simple mocks for external dependencies</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#test-categories","title":"Test Categories","text":"<pre><code>// Service Tests\nAudioRecorder.test.ts     // Recording lifecycle\nTranscriptionService.test.ts  // API integration\nSystemTrayService.test.ts // UI state management\nConfig.test.ts           // Configuration handling\n\n// Integration Tests\nindex.test.ts            // Full application workflow\n</code></pre>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#testing-commands","title":"Testing Commands","text":"<pre><code>make test              # Run all tests\nmake test-watch        # Watch mode for development\nmake test-file FILE=   # Run specific test file\n</code></pre>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#development-workflow","title":"Development Workflow","text":"","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#setup","title":"Setup","text":"<pre><code>git clone &lt;repository&gt;\ncd voice-transcriber\nmake install           # Install dependencies\nmake check-deps        # Verify system requirements\ncp config.example.json config.json  # Setup config\n</code></pre>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#development-loop","title":"Development Loop","text":"<pre><code>make dev              # Start with auto-reload\nmake test             # Run tests\nmake format-check     # Lint and format\n</code></pre>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#build-release","title":"Build &amp; Release","text":"<pre><code>make build            # Build for production\nmake release-patch    # Create patch release\nnpm publish           # Publish to npm\n</code></pre>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#future-architecture-considerations","title":"Future Architecture Considerations","text":"","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#scalability","title":"Scalability","text":"<ul> <li>Plugin system for additional AI providers</li> <li>Configurable audio backends (PulseAudio, JACK)</li> <li>Multi-language prompt templates</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#platform-expansion","title":"Platform Expansion","text":"<ul> <li>Windows support (replace arecord with Windows Audio API)</li> <li>macOS support (replace arecord with Core Audio)</li> <li>Web version using WebRTC</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Local Whisper model integration (faster-whisper)</li> <li>Audio compression before API upload</li> <li>Streaming transcription for long recordings</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#enhanced-features","title":"Enhanced Features","text":"<ul> <li>Keyboard shortcut integration (when Wayland supports it)</li> <li>Multiple output formats (Markdown, structured text)</li> <li>Batch processing capabilities</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/architecture/#related-pages","title":"Related Pages","text":"<ul> <li>API Reference - Complete API documentation for all services</li> <li>Development Guide - Development workflow and best practices</li> <li>Testing Guide - Testing strategies and patterns</li> <li>Contributing Guide - How to contribute to the project</li> </ul>","tags":["expert","reference","development","architecture"]},{"location":"development/development-guide/","title":"Voice Transcriber - Development Guide","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#quick-start","title":"Quick Start","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#prerequisites","title":"Prerequisites","text":"<p>System Requirements: <pre><code># Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install alsa-utils xsel curl\n\n# Verify installations\nwhich arecord  # Should return /usr/bin/arecord\nwhich xsel     # Should return /usr/bin/xsel\n</code></pre></p> <p>Runtime Requirements: - Bun: \u22651.2.0 (development) - Node.js: \u226522 (production/npm) - OpenAI API Key: From https://platform.openai.com/api-keys</p>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#initial-setup","title":"Initial Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/Nouuu/voice-transcriber.git\ncd voice-transcriber\n\n# Install dependencies\nmake install\n\n# Verify system dependencies\nmake check-deps\n\n# Setup configuration\ncp config.example.json config.json\n# Edit config.json and add your OpenAI API key\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#first-run","title":"First Run","text":"<pre><code># Run tests to verify setup\nmake test\n\n# Start development mode\nmake dev\n\n# The app will prompt for API key if not configured\n# Look for green system tray icon\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#development-workflow","title":"Development Workflow","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#daily-development-loop","title":"Daily Development Loop","text":"<ol> <li> <p>Start Development Mode <pre><code>make dev  # Auto-reload on file changes\n</code></pre></p> </li> <li> <p>Code Changes</p> </li> <li>Edit TypeScript files in <code>src/</code></li> <li>Bun automatically recompiles and restarts</li> <li> <p>Check console for errors/logs</p> </li> <li> <p>Test Changes <pre><code># Run all tests\nmake test\n\n# Run specific test file\nmake test-file FILE=src/services/system-tray.test.ts\n\n# Watch mode for TDD\nmake test-watch\n</code></pre></p> </li> <li> <p>Code Quality <pre><code># Check formatting and linting\nmake format-check\n\n# Fix formatting issues\nmake format\n</code></pre></p> </li> <li> <p>Build &amp; Verify <pre><code># Build for production\nmake build\n\n# Test production build\nnode dist/index.js\n</code></pre></p> </li> </ol>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#project-structure","title":"Project Structure","text":"<pre><code>voice-transcriber/\n\u251c\u2500\u2500 src/                    # Source code\n\u2502   \u251c\u2500\u2500 index.ts           # Main application entry\n\u2502   \u251c\u2500\u2500 config/            # Configuration management\n\u2502   \u2502   \u251c\u2500\u2500 config.ts\n\u2502   \u2502   \u2514\u2500\u2500 config.test.ts\n\u2502   \u251c\u2500\u2500 services/          # Core services\n\u2502   \u2502   \u251c\u2500\u2500 audio-recorder.ts\n\u2502   \u2502   \u251c\u2500\u2500 system-tray.ts\n\u2502   \u2502   \u251c\u2500\u2500 transcription.ts\n\u2502   \u2502   \u251c\u2500\u2500 formatter.ts\n\u2502   \u2502   \u251c\u2500\u2500 clipboard.ts\n\u2502   \u2502   \u2514\u2500\u2500 *.test.ts      # Unit tests\n\u2502   \u2514\u2500\u2500 utils/             # Utilities\n\u2502       \u251c\u2500\u2500 logger.ts\n\u2502       \u2514\u2500\u2500 logger.test.ts\n\u251c\u2500\u2500 docs/                  # Documentation\n\u2502   \u251c\u2500\u2500 ARCHITECTURE.md\n\u2502   \u251c\u2500\u2500 API_REFERENCE.md\n\u2502   \u2514\u2500\u2500 DEVELOPMENT_GUIDE.md\n\u251c\u2500\u2500 assets/                # Icons and resources\n\u2502   \u251c\u2500\u2500 icon-idle.png\n\u2502   \u251c\u2500\u2500 icon-recording.png\n\u2502   \u2514\u2500\u2500 icon-processing.png\n\u251c\u2500\u2500 dist/                  # Built application\n\u251c\u2500\u2500 Makefile              # Development commands\n\u2514\u2500\u2500 package.json          # Dependencies and scripts\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#available-make-commands","title":"Available Make Commands","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#core-commands","title":"Core Commands","text":"<pre><code>make help          # Show all available commands\nmake install       # Install bun dependencies\nmake run          # Run the application\nmake dev          # Run in development mode with watch\nmake build        # Build for production\nmake clean        # Clean build artifacts and temporary files\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#testing-commands","title":"Testing Commands","text":"<pre><code>make test         # Run all tests with bun test\nmake test-watch   # Run tests in watch mode\nmake test-file    # Run specific test (usage: make test-file FILE=path/to/test.ts)\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#code-quality-commands","title":"Code Quality Commands","text":"<pre><code>make lint         # Run ESLint linting\nmake format       # Format code with Prettier\nmake format-check # Check code formatting and linting\nmake check-deps   # Check system dependencies\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#release-commands","title":"Release Commands","text":"<pre><code>make release-patch  # Create patch release (x.x.X) - Bug fixes\nmake release-minor  # Create minor release (x.X.0) - New features\nmake release-major  # Create major release (X.0.0) - Breaking changes\nmake get-version   # Show current version from package.json\nmake pre-release   # Validate code before release\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#development-patterns","title":"Development Patterns","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#service-development-pattern","title":"Service Development Pattern","text":"<p>All services follow a consistent pattern:</p> <pre><code>// 1. Define interfaces\nexport interface ServiceConfig {\n  // Configuration options\n}\n\nexport interface ServiceResult {\n  success: boolean;\n  error?: string;\n  // Additional result data\n}\n\n// 2. Implement service class\nexport class MyService {\n  private config: ServiceConfig;\n\n  constructor(config: ServiceConfig) {\n    this.config = config;\n  }\n\n  public async doSomething(): Promise&lt;ServiceResult&gt; {\n    try {\n      // Implementation logic\n      return { success: true };\n    } catch (error) {\n      return {\n        success: false,\n        error: `Operation failed: ${error}`\n      };\n    }\n  }\n}\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#error-handling-pattern","title":"Error Handling Pattern","text":"<pre><code>// Services never throw - always return result objects\nconst result = await service.doSomething();\n\nif (!result.success) {\n  logger.error(`Service failed: ${result.error}`);\n  // Handle error appropriately\n  return;\n}\n\n// Use result data\nconsole.log('Success:', result.data);\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#testing-pattern","title":"Testing Pattern","text":"<pre><code>import { describe, test, expect } from \"bun:test\";\nimport { MyService } from \"./my-service\";\n\ndescribe(\"MyService\", () =&gt; {\n  test(\"should handle success case\", async () =&gt; {\n    const service = new MyService({ /* config */ });\n    const result = await service.doSomething();\n\n    expect(result.success).toBe(true);\n    expect(result.error).toBeUndefined();\n  });\n\n  test(\"should handle error case\", async () =&gt; {\n    const service = new MyService({ /* invalid config */ });\n    const result = await service.doSomething();\n\n    expect(result.success).toBe(false);\n    expect(result.error).toContain(\"expected error message\");\n  });\n});\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#code-quality-guidelines","title":"Code Quality Guidelines","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#simplicity-principles","title":"Simplicity Principles","text":"<p>\u2705 What to Implement: - Basic error handling (try/catch, return success/error) - Simple configuration loading from JSON - Direct API calls to OpenAI (Whisper + GPT) - Basic audio recording (start/stop/save) - Simple system tray with 3 states - Console logging (info/error only)</p> <p>\u274c What to Avoid: - Complex retry logic with exponential backoff - Advanced statistics tracking and usage metrics - Batch processing capabilities - Complex validation with detailed error messages - Advanced logging with rotation and file management</p>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#service-guidelines","title":"Service Guidelines","text":"<ul> <li>Size: Keep services under 100 lines each</li> <li>Methods: 3-5 core methods maximum per service</li> <li>Interfaces: Use simple <code>{ success: boolean, error?: string }</code> pattern</li> <li>Dependencies: Minimize external dependencies</li> <li>Single Responsibility: Each service has one clear purpose</li> </ul>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#typescript-guidelines","title":"TypeScript Guidelines","text":"<pre><code>// Use explicit interfaces\ninterface MyConfig {\n  apiKey: string;\n  enabled: boolean;\n}\n\n// Use type-safe result objects\ninterface MyResult {\n  success: boolean;\n  data?: MyData;\n  error?: string;\n}\n\n// Use async/await consistently\npublic async doWork(): Promise&lt;MyResult&gt; {\n  // Implementation\n}\n\n// Use proper error handling\ntry {\n  const result = await externalService();\n  return { success: true, data: result };\n} catch (error) {\n  return { success: false, error: `Failed: ${error}` };\n}\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#file-organization","title":"File Organization","text":"<pre><code>// File: src/services/my-service.ts\n\n// 1. Imports\nimport { external } from \"external-package\";\nimport { internal } from \"../utils/internal\";\n\n// 2. Interfaces\nexport interface MyConfig { }\nexport interface MyResult { }\n\n// 3. Implementation\nexport class MyService {\n  // Private fields first\n  private config: MyConfig;\n\n  // Constructor\n  constructor(config: MyConfig) { }\n\n  // Public methods\n  public async method(): Promise&lt;MyResult&gt; { }\n\n  // Private methods last\n  private helper(): void { }\n}\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#testing-strategy","title":"Testing Strategy","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#test-organization","title":"Test Organization","text":"<pre><code>src/services/\n\u251c\u2500\u2500 audio-recorder.ts\n\u251c\u2500\u2500 audio-recorder.test.ts    # Unit tests for audio recorder\n\u251c\u2500\u2500 system-tray.ts\n\u251c\u2500\u2500 system-tray.test.ts       # Unit tests for system tray\n\u2514\u2500\u2500 ...\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#testing-commands_1","title":"Testing Commands","text":"<pre><code># Run all tests (37 tests total)\nmake test\n\n# Run specific service tests\nmake test-file FILE=src/services/system-tray.test.ts\n\n# Watch mode for TDD\nmake test-watch\n\n# Test with coverage (manual analysis)\nbun test --coverage\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#test-categories","title":"Test Categories","text":"<ol> <li>Unit Tests: Individual service functionality</li> <li>Integration Tests: Service interaction (index.test.ts)</li> <li>Mock Tests: External API simulation</li> <li>Error Tests: Error handling validation</li> </ol>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#testing-best-practices","title":"Testing Best Practices","text":"<pre><code>describe(\"Service Tests\", () =&gt; {\n  test(\"success case - primary functionality\", async () =&gt; {\n    // Test main use case\n  });\n\n  test(\"error case - invalid input\", async () =&gt; {\n    // Test error handling\n  });\n\n  test(\"edge case - boundary conditions\", async () =&gt; {\n    // Test edge cases only if critical\n  });\n});\n\n// Keep tests simple and focused\n// Maximum 5-6 tests per service\n// Test behavior, not implementation\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#mock-strategy","title":"Mock Strategy","text":"<pre><code>// Simple mocks for external dependencies\nconst mockOpenAI = {\n  audio: {\n    transcriptions: {\n      create: async () =&gt; ({ text: \"mock transcription\" })\n    }\n  }\n};\n\n// Inject mocks via constructor\nconst service = new TranscriptionService(config, mockOpenAI);\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#debugging","title":"Debugging","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#common-development-issues","title":"Common Development Issues","text":"<p>Application Won't Start: <pre><code># Check system dependencies\nmake check-deps\n\n# Verify API key in config\ncat config.json | grep apiKey\n\n# Check Bun installation\nbun --version\n</code></pre></p> <p>System Tray Not Visible: <pre><code># Test different desktop environments\necho $XDG_CURRENT_DESKTOP\n\n# Check system tray support\nps aux | grep -i tray\n\n# Try manual icon update\n# Restart window manager if needed\n</code></pre></p> <p>Audio Recording Issues: <pre><code># Test arecord directly\narecord -l  # List audio devices\narecord -D default -f cd -t wav test.wav  # Test recording\n\n# Check ALSA configuration\ncat /proc/asound/cards\n</code></pre></p> <p>API Issues: <pre><code># Test API key manually\ncurl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  https://api.openai.com/v1/models\n\n# Check rate limits\n# Monitor API usage in OpenAI dashboard\n</code></pre></p>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#logging-and-diagnostics","title":"Logging and Diagnostics","text":"<p>Console Output: <pre><code># Development mode shows all logs\nmake dev\n\n# Production mode - minimal logging\nmake run\n</code></pre></p> <p>Debug Mode: <pre><code>// Add temporary debug logging\nconsole.log(\"Debug:\", { variable, state });\n\n// Use logger for permanent logging\nlogger.info(\"Operation completed\");\nlogger.error(\"Operation failed\");\n</code></pre></p> <p>File System Debugging: <pre><code># Check temp files\nls -la /tmp/transcriber/\n\n# Check config file\ncat ~/.config/voice-transcriber/config.json\n\n# Monitor file creation\nwatch -n 1 'ls -la /tmp/transcriber/'\n</code></pre></p>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#building-and-distribution","title":"Building and Distribution","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#development-build","title":"Development Build","text":"<pre><code># Build for testing\nmake build\n\n# Output: dist/index.js (single file)\n# Test build\nnode dist/index.js\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#production-release-process","title":"Production Release Process","text":"<pre><code># 1. Validate code quality\nmake pre-release\n\n# 2. Update version and create git tag\nmake release-patch  # or release-minor, release-major\n\n# 3. Verify build\nmake build\nmake test\n\n# 4. Publish to npm (manual step)\nnpm publish\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#build-configuration","title":"Build Configuration","text":"<pre><code>// bun build configuration (package.json)\n{\n  \"scripts\": {\n    \"build\": \"bun build src/index.ts --outdir dist --target node --format esm\"\n  }\n}\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#asset-handling","title":"Asset Handling","text":"<ul> <li>Icons: Embedded as Base64 in TypeScript files</li> <li>Config: Template provided as <code>config.example.json</code></li> <li>Dependencies: Bundled in single output file</li> </ul>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#performance-optimization","title":"Performance Optimization","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#development-performance","title":"Development Performance","text":"<pre><code># Fast restart in development\nmake dev  # Uses --watch flag for instant reload\n\n# Fast testing\nmake test-file FILE=specific-test.ts\n\n# Parallel testing (automatic with bun)\nbun test  # Runs tests in parallel by default\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#production-performance","title":"Production Performance","text":"<ul> <li>Bundle Size: ~2MB single file (including dependencies)</li> <li>Memory Usage: ~50MB base + 30MB during processing</li> <li>Startup Time: &lt;1 second on modern hardware</li> <li>API Latency: Depends on OpenAI response times</li> </ul>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>Minimize API Calls: Batch operations when possible</li> <li>Audio Compression: Consider implementing before API upload</li> <li>Caching: Cache successful configurations</li> <li>Error Recovery: Implement graceful degradation</li> </ol>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#contributing-guidelines","title":"Contributing Guidelines","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#git-workflow","title":"Git Workflow","text":"<pre><code># Create feature branch\ngit checkout -b feature/my-feature\n\n# Make changes and commit\ngit add .\ngit commit -m \"feat: add new feature\"\n\n# Keep commits small and focused\n# Use conventional commit messages\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#commit-message-format","title":"Commit Message Format","text":"<pre><code># Format: type: description\nfeat: add system tray icon updates\nfix: resolve menu actions not working\nrefactor: simplify clipboard service\ntest: add system tray state tests\ndocs: update development guide\nchore: update dependencies\n\n# Keep under 50 characters\n# Use present tense\n# No capitalization after colon\n# No period at end\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#code-review-checklist","title":"Code Review Checklist","text":"<ul> <li> Follows simplicity principles</li> <li> Has unit tests for new functionality</li> <li> Uses consistent error handling pattern</li> <li> Maintains under 100 lines per service</li> <li> Includes appropriate logging</li> <li> Updates documentation if needed</li> <li> Passes all existing tests</li> </ul>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Create Feature Branch: <code>git checkout -b feature/description</code></li> <li>Implement Changes: Follow development patterns</li> <li>Add Tests: Ensure new functionality is tested</li> <li>Update Docs: If API or behavior changes</li> <li>Run Quality Checks: <code>make format-check &amp;&amp; make test</code></li> <li>Create PR: With clear description and testing notes</li> <li>Code Review: Address feedback and iterate</li> <li>Merge: Squash commits for clean history</li> </ol>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#advanced-topics","title":"Advanced Topics","text":"","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#custom-icon-development","title":"Custom Icon Development","text":"<pre><code># Create new icons (128x128 PNG)\n# Convert to Base64\nbase64 -w 0 icon.png &gt; icon.base64\n\n# Update src/services/system-tray.ts\n# Add to iconsBase64 object\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#api-integration-testing","title":"API Integration Testing","text":"<pre><code>// Create integration test with real API\nconst integrationTest = process.env.TEST_WITH_REAL_API;\n\nif (integrationTest) {\n  // Test with real OpenAI API\n  // Use test API key with low limits\n} else {\n  // Use mocks for regular testing\n}\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#performance-profiling","title":"Performance Profiling","text":"<pre><code># Profile memory usage\nbun --heap-usage src/index.ts\n\n# Profile startup time\ntime bun run src/index.ts\n\n# Monitor system resources\nhtop  # CPU and memory usage\niotop # Disk I/O usage\n</code></pre>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#cross-platform-development","title":"Cross-Platform Development","text":"<pre><code>// Platform detection\nimport { platform } from \"node:os\";\n\nswitch (platform()) {\n  case 'linux':\n    // Linux-specific code (arecord)\n    break;\n  case 'win32':\n    // Windows-specific code (future)\n    break;\n  case 'darwin':\n    // macOS-specific code (future)\n    break;\n}\n</code></pre> <p>This development guide provides comprehensive information for contributing to and extending the Voice Transcriber application. Follow these patterns and practices to maintain code quality and consistency.</p>","tags":["expert","guide","development","setup"]},{"location":"development/development-guide/#related-pages","title":"Related Pages","text":"<ul> <li>Technical Architecture - System architecture and design principles</li> <li>API Reference - Complete API documentation</li> <li>Testing Guide - Testing strategies and best practices</li> <li>Contributing Guide - Contributing guidelines and workflow</li> </ul>","tags":["expert","guide","development","setup"]},{"location":"development/testing/","title":"Voice Transcriber - Testing Guide","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#testing-overview","title":"Testing Overview","text":"<p>The Voice Transcriber application uses Bun's built-in test runner with a comprehensive test suite covering all services. The testing strategy emphasizes simplicity, reliability, and maintainability following the project's core principles.</p>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-strategy","title":"Test Strategy","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#testing-philosophy","title":"Testing Philosophy","text":"<ul> <li>Keep It Simple: Test core functionality, not edge cases</li> <li>Focus on Behavior: Test what the service does, not how it does it</li> <li>Simple Mocks: Use straightforward mocks, avoid complex scenarios</li> <li>Maximum Coverage: 5-6 tests per service focusing on critical paths</li> <li>Fast Execution: Tests should run quickly for TDD workflow</li> </ul>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-categories","title":"Test Categories","text":"<ol> <li>Unit Tests: Individual service functionality</li> <li>Integration Tests: Service interaction and full workflow</li> <li>Error Handling Tests: Validation of error scenarios</li> <li>Mock Tests: External dependency simulation</li> </ol>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-structure","title":"Test Structure","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#current-test-coverage","title":"Current Test Coverage","text":"<pre><code>Total Tests: 37 tests across all services\n\u251c\u2500\u2500 src/config/config.test.ts          (6 tests)\n\u251c\u2500\u2500 src/services/audio-recorder.test.ts (5 tests)\n\u251c\u2500\u2500 src/services/clipboard.test.ts      (5 tests)\n\u251c\u2500\u2500 src/services/formatter.test.ts      (6 tests)\n\u251c\u2500\u2500 src/services/system-tray.test.ts    (6 tests)\n\u251c\u2500\u2500 src/services/transcription.test.ts  (3 tests)\n\u251c\u2500\u2500 src/utils/logger.test.ts            (3 tests)\n\u2514\u2500\u2500 src/index.test.ts                   (3 tests)\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-organization-pattern","title":"Test Organization Pattern","text":"<p>Each service follows a consistent test structure:</p> <pre><code>import { beforeEach, describe, expect, it, mock } from \"bun:test\";\nimport { ServiceClass } from \"./service-name\";\n\ndescribe(\"ServiceClass\", () =&gt; {\n  let service: ServiceClass;\n  let config: ServiceConfig;\n\n  beforeEach(() =&gt; {\n    // Reset mocks\n    // Setup test configuration\n    // Initialize service\n  });\n\n  describe(\"methodName\", () =&gt; {\n    it(\"should handle success case\", async () =&gt; {\n      // Test primary functionality\n    });\n\n    it(\"should handle error case\", async () =&gt; {\n      // Test error scenarios\n    });\n\n    it(\"should validate input\", async () =&gt; {\n      // Test input validation\n    });\n  });\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#running-tests","title":"Running Tests","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#basic-test-commands","title":"Basic Test Commands","text":"<pre><code># Run all tests\nmake test\n\n# Run tests in watch mode (for TDD)\nmake test-watch\n\n# Run specific test file\nmake test-file FILE=src/services/system-tray.test.ts\n\n# Run tests with verbose output\nbun test --verbose\n\n# Run tests with coverage analysis\nbun test --coverage\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-output-interpretation","title":"Test Output Interpretation","text":"<pre><code># Successful test run example\n$ make test\n\u2713 Config should load default configuration\n\u2713 Config should handle missing config file\n\u2713 SystemTrayService should initialize successfully\n\u2713 TranscriptionService should handle API errors\n\n37 tests passed\n0 tests failed\n</code></pre> <p>Test Status Indicators: - \u2713 Test passed - \u2717 Test failed - \u23f8 Test skipped - \u26a0 Test had warnings</p>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-examples","title":"Test Examples","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#unit-test-example-systemtrayservice","title":"Unit Test Example - SystemTrayService","text":"<pre><code>// File: src/services/system-tray.test.ts\n\nimport { beforeEach, describe, expect, it, mock } from \"bun:test\";\n\n// Mock external dependency\nconst mockSystray = {\n  onClick: mock(),\n  onReady: mock(),\n  sendAction: mock(),\n  kill: mock(),\n};\n\nconst mockSysTrayConstructor = mock(() =&gt; mockSystray);\n\n// Mock the module before importing\nmock.module(\"node-systray-v2\", () =&gt; ({\n  SysTray: mockSysTrayConstructor,\n}));\n\nimport { SystemTrayService, TrayState } from \"./system-tray\";\n\ndescribe(\"SystemTrayService\", () =&gt; {\n  let service: SystemTrayService;\n  let config: TrayConfig;\n\n  beforeEach(() =&gt; {\n    // Reset all mocks\n    mockSysTrayConstructor.mockReset();\n    mockSystray.onClick.mockReset();\n\n    // Setup test configuration\n    config = {\n      callbacks: {\n        onRecordingStart: mock(),\n        onRecordingStop: mock(),\n        onQuit: mock(),\n      },\n    };\n\n    // Create service with mocked constructor\n    service = new SystemTrayService(config, mockSysTrayConstructor);\n  });\n\n  describe(\"initialize\", () =&gt; {\n    it(\"should initialize successfully\", async () =&gt; {\n      // Setup mock behavior\n      mockSysTrayConstructor.mockReturnValue(mockSystray);\n      mockSystray.onReady.mockImplementation(callback =&gt; callback());\n\n      // Execute test\n      const result = await service.initialize();\n\n      // Verify results\n      expect(result.success).toBe(true);\n      expect(mockSysTrayConstructor).toHaveBeenCalled();\n    });\n\n    it(\"should handle constructor errors\", async () =&gt; {\n      // Setup error scenario\n      mockSysTrayConstructor.mockImplementation(() =&gt; {\n        throw new Error(\"Mock constructor failed\");\n      });\n\n      // Execute test\n      const result = await service.initialize();\n\n      // Verify error handling\n      expect(result.success).toBe(false);\n      expect(result.error).toContain(\"Failed to initialize\");\n    });\n  });\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#integration-test-example-main-application","title":"Integration Test Example - Main Application","text":"<pre><code>// File: src/index.test.ts\n\nimport { describe, expect, it, mock } from \"bun:test\";\nimport { VoiceTranscriberApp } from \"./index\";\n\ndescribe(\"VoiceTranscriberApp\", () =&gt; {\n  it(\"should fail to initialize without API key\", async () =&gt; {\n    const app = new VoiceTranscriberApp(\"/tmp/empty-config.json\");\n    const result = await app.initialize();\n\n    expect(result.success).toBe(false);\n    expect(result.error).toContain(\"API key not configured\");\n  });\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#mock-strategy-example-transcriptionservice","title":"Mock Strategy Example - TranscriptionService","text":"<pre><code>// File: src/services/transcription.test.ts\n\nimport { beforeEach, describe, expect, it, mock } from \"bun:test\";\nimport { writeFileSync } from \"node:fs\";\nimport { TranscriptionService } from \"./transcription\";\n\n// Create simple mock for OpenAI\nconst mockOpenAI = {\n  audio: {\n    transcriptions: {\n      create: mock(),\n    },\n  },\n};\n\ndescribe(\"TranscriptionService\", () =&gt; {\n  let service: TranscriptionService;\n\n  beforeEach(() =&gt; {\n    // Reset mock between tests\n    mockOpenAI.audio.transcriptions.create.mockReset();\n\n    // Create service\n    service = new TranscriptionService({\n      apiKey: \"test-key\",\n    });\n\n    // Inject mock (bypassing private field)\n    (service as any).openai = mockOpenAI;\n  });\n\n  describe(\"transcribe\", () =&gt; {\n    it(\"should handle API errors\", async () =&gt; {\n      // Create temp test file\n      const tempFile = \"/tmp/test-transcription.txt\";\n      writeFileSync(tempFile, \"test audio content\");\n\n      // Setup mock to throw error\n      mockOpenAI.audio.transcriptions.create.mockRejectedValueOnce(\n        new Error(\"API Error\")\n      );\n\n      // Execute test\n      const result = await service.transcribe(tempFile);\n\n      // Verify error handling\n      expect(result.success).toBe(false);\n      expect(result.error).toContain(\"API Error\");\n    });\n  });\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#testing-patterns","title":"Testing Patterns","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#mock-setup-pattern","title":"Mock Setup Pattern","text":"<pre><code>// 1. Create mock objects\nconst mockDependency = {\n  method1: mock(),\n  method2: mock(),\n};\n\n// 2. Mock module before importing\nmock.module(\"external-library\", () =&gt; ({\n  ExternalClass: mock(() =&gt; mockDependency),\n}));\n\n// 3. Import after mocking\nimport { ServiceToTest } from \"./service\";\n\n// 4. Reset mocks in beforeEach\nbeforeEach(() =&gt; {\n  mockDependency.method1.mockReset();\n  mockDependency.method2.mockReset();\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#error-testing-pattern","title":"Error Testing Pattern","text":"<pre><code>it(\"should handle service errors\", async () =&gt; {\n  // Setup error scenario\n  mockDependency.method.mockRejectedValueOnce(new Error(\"Test Error\"));\n\n  // Execute operation\n  const result = await service.doSomething();\n\n  // Verify error handling\n  expect(result.success).toBe(false);\n  expect(result.error).toContain(\"Test Error\");\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#file-system-testing-pattern","title":"File System Testing Pattern","text":"<pre><code>it(\"should handle file operations\", async () =&gt; {\n  // Create temporary test file\n  const tempFile = \"/tmp/test-file.txt\";\n  writeFileSync(tempFile, \"test content\");\n\n  // Test file operation\n  const result = await service.processFile(tempFile);\n\n  // Verify results\n  expect(result.success).toBe(true);\n\n  // Cleanup handled by OS (/tmp)\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#async-testing-pattern","title":"Async Testing Pattern","text":"<pre><code>it(\"should handle async operations\", async () =&gt; {\n  // Setup async mock\n  mockDependency.asyncMethod.mockResolvedValueOnce({\n    data: \"test result\"\n  });\n\n  // Execute async operation\n  const result = await service.asyncOperation();\n\n  // Verify async result\n  expect(result.success).toBe(true);\n  expect(result.data).toBe(\"test result\");\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-data-management","title":"Test Data Management","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#configuration-testing","title":"Configuration Testing","text":"<pre><code>// Test configuration objects\nconst validConfig = {\n  apiKey: \"test-key\",\n  enabled: true\n};\n\nconst invalidConfig = {\n  apiKey: \"\", // Invalid empty key\n  enabled: true\n};\n\n// Use in tests\nit(\"should validate configuration\", () =&gt; {\n  expect(() =&gt; new Service(validConfig)).not.toThrow();\n  expect(() =&gt; new Service(invalidConfig)).toThrow();\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#file-testing","title":"File Testing","text":"<pre><code>// Create test files in /tmp\nconst createTestFile = (content: string): string =&gt; {\n  const tempFile = `/tmp/test-${Date.now()}.txt`;\n  writeFileSync(tempFile, content);\n  return tempFile;\n};\n\n// Use in tests\nit(\"should process files\", async () =&gt; {\n  const testFile = createTestFile(\"test audio data\");\n  const result = await service.processFile(testFile);\n  expect(result.success).toBe(true);\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-development-workflow","title":"Test Development Workflow","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-driven-development-tdd","title":"Test-Driven Development (TDD)","text":"<pre><code># 1. Start test watcher\nmake test-watch\n\n# 2. Write failing test\nit(\"should do something new\", async () =&gt; {\n  const result = await service.newMethod();\n  expect(result.success).toBe(true);\n});\n\n# 3. Implement minimum code to pass\npublic async newMethod(): Promise&lt;ServiceResult&gt; {\n  return { success: true };\n}\n\n# 4. Refactor while keeping tests green\n# 5. Repeat cycle\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#adding-new-tests","title":"Adding New Tests","text":"<pre><code># 1. Create test file alongside source\ntouch src/services/new-service.test.ts\n\n# 2. Follow test structure pattern\n# 3. Run specific test during development\nmake test-file FILE=src/services/new-service.test.ts\n\n# 4. Run full suite to ensure no regressions\nmake test\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#debugging-test-failures","title":"Debugging Test Failures","text":"<pre><code>// Add debug logging to tests\nit(\"should debug test issue\", async () =&gt; {\n  console.log(\"Debug: service state\", service);\n\n  const result = await service.doSomething();\n\n  console.log(\"Debug: result\", result);\n  expect(result.success).toBe(true);\n});\n</code></pre> <pre><code># Run single test with verbose output\nbun test src/services/service.test.ts --verbose\n\n# Add temporary console.log statements\n# Remove debug code before committing\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#common-testing-issues","title":"Common Testing Issues","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#mock-issues","title":"Mock Issues","text":"<p>Problem: Mock not working as expected <pre><code>// Wrong - mock after import\nimport { Service } from \"./service\";\nmock.module(\"dependency\", () =&gt; ({ Mock: mock() }));\n\n// Right - mock before import\nmock.module(\"dependency\", () =&gt; ({ Mock: mock() }));\nimport { Service } from \"./service\";\n</code></pre></p> <p>Solution: Always mock modules before importing the service under test.</p>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#async-issues","title":"Async Issues","text":"<p>Problem: Test fails intermittently <pre><code>// Wrong - not awaiting async operation\nit(\"should handle async\", () =&gt; {\n  service.asyncMethod(); // Missing await\n  expect(mockDependency.method).toHaveBeenCalled();\n});\n\n// Right - properly await async operations\nit(\"should handle async\", async () =&gt; {\n  await service.asyncMethod();\n  expect(mockDependency.method).toHaveBeenCalled();\n});\n</code></pre></p>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#file-system-issues","title":"File System Issues","text":"<p>Problem: Tests interfere with each other <pre><code>// Wrong - using same file names\nconst testFile = \"/tmp/test.txt\";\n\n// Right - unique file names\nconst testFile = `/tmp/test-${Date.now()}.txt`;\n</code></pre></p>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#mock-reset-issues","title":"Mock Reset Issues","text":"<p>Problem: Mocks retain state between tests <pre><code>// Wrong - no reset between tests\ndescribe(\"Service\", () =&gt; {\n  it(\"test 1\", () =&gt; { /* uses mock */ });\n  it(\"test 2\", () =&gt; { /* mock still has state from test 1 */ });\n});\n\n// Right - reset in beforeEach\nbeforeEach(() =&gt; {\n  mockDependency.method.mockReset();\n});\n</code></pre></p>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#performance-testing","title":"Performance Testing","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-execution-speed","title":"Test Execution Speed","text":"<pre><code># Measure test execution time\ntime make test\n\n# Profile individual test files\ntime bun test src/services/system-tray.test.ts\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#memory-usage-testing","title":"Memory Usage Testing","text":"<pre><code>// Basic memory usage check\nit(\"should not leak memory\", async () =&gt; {\n  const initialMemory = process.memoryUsage().heapUsed;\n\n  // Perform operations\n  for (let i = 0; i &lt; 100; i++) {\n    await service.doSomething();\n  }\n\n  const finalMemory = process.memoryUsage().heapUsed;\n  const memoryIncrease = finalMemory - initialMemory;\n\n  // Should not increase significantly\n  expect(memoryIncrease).toBeLessThan(10 * 1024 * 1024); // 10MB\n});\n</code></pre>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-maintenance","title":"Test Maintenance","text":"","tags":["expert","guide","development","testing"]},{"location":"development/testing/#keeping-tests-updated","title":"Keeping Tests Updated","text":"<ol> <li>Update tests when APIs change</li> <li>Remove tests for deleted functionality</li> <li>Add tests for new features</li> <li>Refactor tests when refactoring code</li> </ol>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#test-quality-checklist","title":"Test Quality Checklist","text":"<ul> <li> Tests are focused and test one thing</li> <li> Tests have descriptive names</li> <li> Tests use appropriate mocks</li> <li> Tests clean up after themselves</li> <li> Tests are deterministic (no random failures)</li> <li> Tests run quickly (&lt; 100ms each)</li> </ul>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#common-maintenance-tasks","title":"Common Maintenance Tasks","text":"<pre><code># Update all test dependencies\nbun update\n\n# Check for unused test files\nfind src -name \"*.test.ts\" -exec grep -L \"describe\\|it\\|test\" {} \\;\n\n# Validate test naming conventions\ngrep -r \"it\\|test\" src --include=\"*.test.ts\" | grep -v \"should\"\n</code></pre> <p>This testing guide provides comprehensive information for understanding, writing, and maintaining tests in the Voice Transcriber application. Follow these patterns to ensure robust and maintainable test coverage.</p>","tags":["expert","guide","development","testing"]},{"location":"development/testing/#related-pages","title":"Related Pages","text":"<ul> <li>Development Guide - Development workflow and setup</li> <li>API Reference - Service interfaces and methods to test</li> <li>Technical Architecture - System architecture and components</li> <li>Contributing Guide - Contributing guidelines and testing requirements</li> </ul>","tags":["expert","guide","development","testing"]},{"location":"getting-started/configuration/","title":"Configuration Guide","text":"","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#overview","title":"Overview","text":"<p>Voice Transcriber uses a simple JSON configuration file located at: <pre><code>~/.config/voice-transcriber/config.json\n</code></pre></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#configuration-settings","title":"Configuration Settings","text":"","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#required-settings","title":"Required Settings","text":"","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#transcriptionbackend-string","title":"<code>transcription.backend</code> (string)","text":"<p>The transcription backend to use: <code>\"openai\"</code> or <code>\"speaches\"</code>.</p> <p>Default: <code>\"openai\"</code></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#transcriptionopenaiapikey-string","title":"<code>transcription.openai.apiKey</code> (string)","text":"<p>Your OpenAI API key for accessing Whisper and GPT services (required when using OpenAI backend).</p> <p>How to get one: https://platform.openai.com/api-keys</p> <p>Example: <pre><code>{\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\"\n    }\n  }\n}\n</code></pre></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#optional-settings","title":"Optional Settings","text":"","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#language-string","title":"<code>language</code> (string)","text":"<p>The primary language for transcription and formatting.</p> <p>Supported languages: - <code>\"fr\"</code> - French - <code>\"en\"</code> - English (default) - <code>\"es\"</code> - Spanish - <code>\"de\"</code> - German - <code>\"it\"</code> - Italian</p> <p>Default: <code>\"en\"</code></p> <p>How it works: - Whisper API uses this as the primary transcription language - A strong language-specific prompt prevents Whisper from switching languages mid-transcription - Formatter (GPT) maintains this language when formatting text</p> <p>Example: <pre><code>{\n  \"language\": \"fr\"\n}\n</code></pre></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#transcriptionprompt-string-or-null","title":"<code>transcriptionPrompt</code> (string or null)","text":"<p>Custom prompt for Whisper transcription.</p> <p>Default: <code>null</code> (uses automatic language-specific prompt)</p> <p>When to use: Only if you need very specific transcription behavior that differs from the built-in prompts.</p> <p>Built-in prompt (when null): <pre><code>This is a [Language] audio recording. Transcribe the entire audio in [Language] only.\nDo NOT switch to English or translate. Keep all content in [Language], preserving\n[Language] sentence structure and grammar throughout the entire transcription.\n</code></pre></p> <p>Example: <pre><code>{\n  \"transcriptionPrompt\": \"Transcribe this technical French presentation, keeping technical English terms but French grammar.\"\n}\n</code></pre></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#benchmarkmode-boolean","title":"<code>benchmarkMode</code> (boolean)","text":"<p>NEW FEATURE - Compare OpenAI and Speaches side-by-side.</p> <p>Default: <code>false</code></p> <p>When enabled: - Transcribes audio with BOTH OpenAI Whisper and Speaches - Displays detailed comparison (speed, accuracy, text differences) - Automatically selects best result based on similarity score - Requires <code>--debug</code> flag to see comparison output - Requires both backends configured (OpenAI API key AND Speaches URL)</p> <p>Example: <pre><code>{\n  \"benchmarkMode\": true,\n  \"transcription\": {\n    \"backend\": \"speaches\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\",\n      \"model\": \"whisper-1\"\n    },\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"apiKey\": \"none\",\n      \"model\": \"Systran/faster-whisper-base\"\n    }\n  }\n}\n</code></pre></p> <p>Usage: <pre><code>voice-transcriber --debug\n# Records audio, then shows:\n# - OpenAI transcription time\n# - Speaches transcription time\n# - Speed comparison\n# - Text similarity percentage\n# - Differences analysis\n</code></pre></p> <p>Best Use Cases</p> <ul> <li>Testing different Speaches models</li> <li>Comparing cloud vs self-hosted performance</li> <li>Validating Speaches accuracy for your use case</li> <li>Optimizing your transcription setup</li> </ul>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#transcription-object","title":"<code>transcription</code> (object)","text":"<p>Backend configuration for transcription service.</p> <p>Structure: <pre><code>{\n  \"transcription\": {\n    \"backend\": \"openai\" | \"speaches\",\n    \"openai\": {\n      \"apiKey\": \"string\",\n      \"model\": \"string\"\n    },\n    \"speaches\": {\n      \"url\": \"string\",\n      \"apiKey\": \"string\",\n      \"model\": \"string\"\n    }\n  }\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>backend</code> (required): <code>\"openai\"</code> or <code>\"speaches\"</code> - which backend to use</li> <li><code>openai.apiKey</code> (required for OpenAI): Your OpenAI API key</li> <li><code>openai.model</code> (optional): Whisper model, default <code>\"whisper-1\"</code></li> <li><code>speaches.url</code> (required for Speaches): Speaches server URL</li> <li><code>speaches.apiKey</code> (optional): API key for Speaches, default <code>\"none\"</code></li> <li><code>speaches.model</code> (optional): Whisper model, default <code>\"Systran/faster-whisper-base\"</code></li> </ul> <p>Note: For <code>benchmarkMode</code>, both <code>openai</code> and <code>speaches</code> sections must be configured.</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#formatter-object","title":"<code>formatter</code> (object)","text":"<p>Backend configuration for text formatting service.</p> <p>Structure: <pre><code>{\n  \"formatter\": {\n    \"backend\": \"openai\" | \"ollama\",\n    \"openai\": {\n      \"apiKey\": \"string\",\n      \"model\": \"string\"\n    },\n    \"ollama\": {\n      \"url\": \"string\",\n      \"model\": \"string\"\n    }\n  }\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>backend</code> (required): <code>\"openai\"</code> or <code>\"ollama\"</code> - which backend to use for formatting</li> <li><code>openai.apiKey</code> (required for OpenAI): Your OpenAI API key</li> <li><code>openai.model</code> (optional): GPT model, default <code>\"gpt-4o-mini\"</code></li> <li><code>ollama.url</code> (optional): Ollama server URL, default <code>\"http://localhost:11434\"</code></li> <li><code>ollama.model</code> (optional): Model name, default <code>\"llama3.1:8b\"</code></li> </ul>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#activepersonalities-array-of-strings","title":"<code>activePersonalities</code> (array of strings)","text":"<p>List of personalities to apply during formatting. Multiple personalities can be active simultaneously, and their prompts will be concatenated into a single request.</p> <p>Default: <code>[\"builtin:default\"]</code></p> <p>Format: <code>\"builtin:&lt;name&gt;\"</code> for built-in personalities, <code>\"custom:&lt;id&gt;\"</code> for custom ones</p> <p>Built-in personalities: - <code>builtin:default</code> - Minimal formatting, fix grammar only - <code>builtin:professional</code> - Business communication style - <code>builtin:technical</code> - Technical documentation style - <code>builtin:creative</code> - Expressive and natural style - <code>builtin:emojify</code> - Add context-appropriate emojis</p> <p>Example: <pre><code>{\n  \"activePersonalities\": [\n    \"builtin:professional\",\n    \"builtin:emojify\",\n    \"custom:myStyle\"\n  ]\n}\n</code></pre></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#custompersonalities-object","title":"<code>customPersonalities</code> (object)","text":"<p>Define your own custom formatting styles.</p> <p>Structure: <pre><code>{\n  \"customPersonalities\": {\n    \"myStyleId\": {\n      \"name\": \"Display Name\",\n      \"description\": \"Optional description\",\n      \"prompt\": \"Formatting instructions for GPT\"\n    }\n  }\n}\n</code></pre></p> <p>Example: <pre><code>{\n  \"customPersonalities\": {\n    \"technical-french\": {\n      \"name\": \"Technical French\",\n      \"description\": \"French technical documentation style\",\n      \"prompt\": \"Format as French technical documentation. Keep technical English terms. Use formal tone.\"\n    },\n    \"email-style\": {\n      \"name\": \"Email Style\",\n      \"description\": \"Professional email format\",\n      \"prompt\": \"Format as a professional email: greeting, body, closing signature.\"\n    }\n  }\n}\n</code></pre></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#maxpromptlength-number","title":"<code>maxPromptLength</code> (number)","text":"<p>Maximum total length (in characters) when concatenating multiple personality prompts.</p> <p>Default: <code>4000</code></p> <p>How it works: - When multiple personalities are active, their prompts are concatenated with <code>\\n\\n---\\n\\n</code> separator - If adding a new prompt would exceed <code>maxPromptLength</code>, concatenation stops - Helps prevent exceeding LLM token limits while using multiple personalities</p> <p>Example: <pre><code>{\n  \"maxPromptLength\": 4000,\n  \"activePersonalities\": [\n    \"builtin:professional\",\n    \"builtin:technical\",\n    \"custom:myLongPrompt\"\n  ]\n}\n</code></pre></p> <p>Personality Concatenation</p> <p>When using multiple personalities, they are combined into a single formatting request rather than applied sequentially. This is faster and more cost-effective, but means personalities should be complementary rather than contradictory.</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#selectedpersonalities-array-of-strings","title":"<code>selectedPersonalities</code> (array of strings)","text":"<p>List of personalities that appear in the system tray menu. This controls which personalities are visible, while <code>activePersonalities</code> controls which ones are checked/enabled by default.</p> <p>Default: All built-in personalities</p> <p>Format: <code>\"builtin:&lt;name&gt;\"</code> for built-in personalities, <code>\"custom:&lt;id&gt;\"</code> for custom ones</p> <p>Example: <pre><code>{\n  \"selectedPersonalities\": [\n    \"builtin:default\",\n    \"builtin:professional\",\n    \"custom:myStyle\"\n  ]\n}\n</code></pre></p> <p>Use cases: - Hide personalities you never use to keep the menu clean - Show only personalities relevant to your workflow - Add custom personalities to the menu</p> <p>Menu Organization</p> <p>Keep <code>selectedPersonalities</code> short (3-5 items) for a cleaner menu. You can always add personalities when needed by editing the config and reloading.</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#managing-configuration","title":"Managing Configuration","text":"","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#save-as-default-system-tray","title":"Save as Default (System Tray)","text":"<p>NEW in v1.x - You can now save your current configuration directly from the system tray menu, eliminating the need to manually edit <code>config.json</code> for common changes.</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#how-it-works","title":"How It Works","text":"<ol> <li>Adjust Settings: Use the system tray menu to check/uncheck personalities</li> <li>Save: Click \"\ud83d\udcbe Save as Default\" in the menu</li> <li>Persist: Your current settings are saved to <code>config.json</code></li> <li>Restart: Next time you start the app, your preferences are restored</li> </ol>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#what-gets-saved","title":"What Gets Saved","text":"<p>When you click \"\ud83d\udcbe Save as Default\", the entire configuration is saved:</p> <ul> <li>\u2705 Active personalities (<code>activePersonalities</code>)</li> <li>\u2705 Selected personalities (menu visibility)</li> <li>\u2705 Custom personalities</li> <li>\u2705 Language setting</li> <li>\u2705 Transcription backend and settings</li> <li>\u2705 Formatter backend and settings</li> <li>\u2705 All other configuration parameters</li> </ul> <p>Complete Save</p> <p>\"Save as Default\" saves everything, not just personalities. Any changes made via the config file and reloaded are included in the save.</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#when-to-use","title":"When to Use","text":"<p>Perfect for: - Saving your preferred personality combinations - Quick workflow adjustments - Testing different setups before committing</p> <p>Not ideal for: - Complex configuration changes (use config file directly) - Temporary testing (changes will persist)</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#example-workflow","title":"Example Workflow","text":"<pre><code># 1. Start the application\nvoice-transcriber\n\n# 2. Via system tray menu:\n#    \u2611 Professional\n#    \u2611 Emojify\n#    \u2610 Default (uncheck)\n\n# 3. Click \"\ud83d\udcbe Save as Default\"\n\n# 4. Restart \u2192 Professional + Emojify are active by default \u2705\n</code></pre>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#safety-features","title":"Safety Features","text":"<ul> <li>State check: Only available when app is IDLE (not during recording/processing)</li> <li>Confirmation: Logs confirm successful save with details</li> <li>Rollback: Edit <code>config.json</code> and reload if needed</li> </ul>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#logs","title":"Logs","text":"<p>When you save, you'll see: <pre><code>[INFO] \u2705 Configuration saved to file successfully\n[INFO] Config file: /home/user/.config/voice-transcriber/config.json\n[INFO] Active personalities saved: builtin:professional, builtin:emojify\n</code></pre></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#change-detection-debug-mode","title":"Change Detection (Debug Mode)","text":"<p>NEW in v1.x - When reloading configuration in debug mode, the application detects and displays all changes between the live configuration and the file.</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#how-to-see-change-detection","title":"How to See Change Detection","text":"<ol> <li> <p>Start in debug mode:    <pre><code>voice-transcriber --debug\n# or\nvoice-transcriber -d\n</code></pre></p> </li> <li> <p>Modify <code>config.json</code> manually</p> </li> <li> <p>Reload via \"\ud83d\udd04 Reload Config\" in system tray</p> </li> <li> <p>See changes in the terminal output</p> </li> </ol>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#what-is-detected","title":"What Is Detected","text":"<p>The system detects 15+ types of changes:</p> <p>Transcription: - Backend (openai \u2194 speaches) - Model changes - Speaches URL changes</p> <p>Formatter: - Backend (openai \u2194 ollama) - Model changes - Ollama URL changes</p> <p>Personalities: - Active personalities added/removed - Custom personalities added - Custom personalities removed - Custom personalities modified - Selected personalities (menu visibility)</p> <p>General: - Language changes - Benchmark mode toggled</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#example-output","title":"Example Output","text":"<p>No changes: <pre><code>[INFO] Reloading configuration...\n[DEBUG] \u2713 No configuration changes detected (config file matches live state)\n[INFO] \u2705 Configuration reloaded successfully\n</code></pre></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#complete-configuration-examples","title":"Complete Configuration Examples","text":"","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#minimal-configuration-openai-backend","title":"Minimal Configuration (OpenAI Backend)","text":"<pre><code>{\n  \"language\": \"en\",\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\"\n    }\n  },\n  \"formatter\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\",\n      \"model\": \"gpt-4o-mini\"\n    }\n  },\n  \"activePersonalities\": [\"builtin:default\"]\n}\n</code></pre>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#full-configuration-with-all-options","title":"Full Configuration with All Options","text":"<pre><code>{\n  \"language\": \"en\",\n  \"transcriptionPrompt\": null,\n  \"benchmarkMode\": false,\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\",\n      \"model\": \"whisper-1\"\n    },\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"apiKey\": \"none\",\n      \"model\": \"Systran/faster-whisper-base\"\n    }\n  },\n  \"formatter\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\",\n      \"model\": \"gpt-4o-mini\"\n    },\n    \"ollama\": {\n      \"url\": \"http://localhost:11434\",\n      \"model\": \"llama3.1:8b\"\n    }\n  },\n  \"activePersonalities\": [\"builtin:default\"],\n  \"selectedPersonalities\": [\n    \"builtin:default\",\n    \"builtin:professional\",\n    \"builtin:technical\",\n    \"builtin:creative\",\n    \"builtin:emojify\"\n  ],\n  \"customPersonalities\": {},\n  \"maxPromptLength\": 4000,\n  \"logTruncateThreshold\": 1000\n}\n</code></pre>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#speaches-backend-configuration-no-formatting","title":"Speaches Backend Configuration (No Formatting)","text":"<pre><code>{\n  \"language\": \"fr\",\n  \"transcription\": {\n    \"backend\": \"speaches\",\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"apiKey\": \"none\",\n      \"model\": \"Systran/faster-whisper-base\"\n    }\n  },\n  \"activePersonalities\": []\n}\n</code></pre>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#multiple-personalities-configuration","title":"Multiple Personalities Configuration","text":"<pre><code>{\n  \"language\": \"fr\",\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\"\n    }\n  },\n  \"formatter\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\",\n      \"model\": \"gpt-4o-mini\"\n    }\n  },\n  \"activePersonalities\": [\n    \"builtin:professional\",\n    \"builtin:emojify\",\n    \"custom:myStyle\"\n  ],\n  \"customPersonalities\": {\n    \"myStyle\": {\n      \"name\": \"My Custom Style\",\n      \"description\": \"My personal formatting style\",\n      \"prompt\": \"Format text in my personal style with...\"\n    }\n  },\n  \"maxPromptLength\": 4000\n}\n</code></pre>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#benchmark-mode-configuration","title":"Benchmark Mode Configuration","text":"<pre><code>{\n  \"language\": \"fr\",\n  \"benchmarkMode\": true,\n  \"transcription\": {\n    \"backend\": \"speaches\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\",\n      \"model\": \"whisper-1\"\n    },\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"apiKey\": \"none\",\n      \"model\": \"Systran/faster-whisper-medium\"\n    }\n  },\n  \"formatter\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\",\n      \"model\": \"gpt-4o-mini\"\n    }\n  },\n  \"activePersonalities\": [\"builtin:default\"]\n}\n</code></pre>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#custom-prompts-configuration","title":"Custom Prompts Configuration","text":"<pre><code>{\n  \"language\": \"fr\",\n  \"transcriptionPrompt\": \"Transcribe this French audio with proper names and technical terms.\",\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\"\n    }\n  },\n  \"formatter\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-proj-abc123...\"\n    }\n  },\n  \"activePersonalities\": [\"builtin:professional\"],\n  \"customPersonalities\": {\n    \"myStyle\": {\n      \"name\": \"My Custom Style\",\n      \"description\": \"Concise professional style\",\n      \"prompt\": \"Format this French text in a concise, professional style.\"\n    }\n  }\n}\n</code></pre>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#configuration-architecture","title":"Configuration Architecture","text":"<p>The configuration system uses a centralized, single-source-of-truth design:</p> <ol> <li>User Config (<code>~/.config/voice-transcriber/config.json</code>)</li> <li>Simple JSON file with core settings</li> <li> <p>Easy to understand and modify</p> </li> <li> <p>Config Class (<code>src/config/config.ts</code>)</p> </li> <li>Loads and validates user configuration</li> <li>Generates service-specific configurations</li> <li> <p>Provides strong language-specific prompts</p> </li> <li> <p>Service Configuration</p> </li> <li>Services receive fully-configured objects</li> <li>No configuration logic in services</li> <li>Services focus only on their core functionality</li> </ol>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#flow-diagram","title":"Flow Diagram","text":"<pre><code>config.json\n    \u2193\nConfig.load()\n    \u2193\nConfig.getTranscriptionConfig() \u2192 TranscriptionService\nConfig.getFormatterConfig()     \u2192 FormatterService\n</code></pre>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#troubleshooting","title":"Troubleshooting","text":"","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#french-transcriptions-switching-to-english","title":"French Transcriptions Switching to English","text":"<p>Problem: Long French transcriptions switch to English mid-way.</p> <p>Solution: The new configuration system includes strong language-specific prompts that prevent this. Make sure: 1. Your config has <code>\"language\": \"fr\"</code> 2. You're not using a custom <code>transcriptionPrompt</code> (use <code>null</code> for default) 3. Restart the application after config changes</p> <p>How it works: - The <code>language</code> setting triggers a strong prompt like: \"This is a French audio recording. Transcribe the entire audio in French only. Do NOT switch to English...\"</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#live-configuration-management","title":"Live Configuration Management","text":"<p>You can now reload configuration changes without restarting the application using the system tray menu.</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#how-it-works_1","title":"How It Works","text":"<p>The live reload process follows these steps:</p> <ol> <li>Open Configuration: Right-click tray icon \u2192 \"Open Config\"</li> <li>Edit Settings: Make changes in your default text editor</li> <li>Save File: Save the configuration file</li> <li>Reload: Right-click tray icon \u2192 \"Reload Config\" (when application is idle)</li> </ol>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#state-validation","title":"State Validation","text":"<p>Reload Config is only available when the application is idle (green icon):</p> <ul> <li>\u2705 Available: When idle and ready</li> <li>\u274c Blocked: During recording (would interrupt audio capture)</li> <li>\u274c Blocked: During processing (would interfere with transcription)</li> </ul> <p>This safety mechanism prevents configuration changes from corrupting ongoing operations.</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#what-gets-reloaded","title":"What Gets Reloaded","text":"<p>When you reload configuration, the following services are reinitialized:</p> <ul> <li>TranscriptionService: Updated with new API key, language, model, backend</li> <li>FormatterService: Updated with new API key, enabled state, prompts</li> <li>AudioProcessor: Reinitialized with updated service dependencies</li> </ul>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#safety-features_1","title":"Safety Features","text":"<p>The reload process includes automatic protections:</p> Feature Description Validation Configuration is validated before applying changes Rollback Previous configuration is automatically restored on failure Error Handling Clear error messages guide you to fix issues Service Cleanup Old services are properly disposed to prevent memory leaks","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#common-use-cases","title":"Common Use Cases","text":"<p>Testing Language Settings <pre><code>// Try different languages without restarting\n{ \"language\": \"fr\" }  // Test French\n\u2192 Reload Config\n{ \"language\": \"en\" }  // Back to English\n\u2192 Reload Config\n</code></pre></p> <p>Switching Backends <pre><code>// Switch between OpenAI and Speaches\n{\n  \"transcription\": {\n    \"backend\": \"speaches\"  // Use local Speaches\n  }\n}\n\u2192 Reload Config\n</code></pre></p> <p>Updating API Keys <pre><code>{\n  \"transcription\": {\n    \"openai\": {\n      \"apiKey\": \"sk-proj-new-key-here\"\n    }\n  }\n}\n\u2192 Reload Config\n</code></pre></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#reload-vs-restart","title":"Reload vs Restart","text":"Aspect Reload Config Restart Application Speed Instant (&lt; 1 second) Slow (3-5 seconds) System Tray Stays in tray Disappears briefly Safety Automatic rollback Manual recovery When to Use Quick config changes Major troubleshooting <p>Best Practice</p> <p>Use Reload Config for configuration changes during development or testing. Only restart the application if reload fails or you encounter unexpected behavior.</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#configuration-file-not-found","title":"Configuration File Not Found","text":"<p>Problem: Application can't find config file.</p> <p>Solution: Run the setup wizard: <pre><code>rm -rf ~/.config/voice-transcriber/config.json\nmake run  # Will trigger first-run setup\n</code></pre></p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#invalid-json-format","title":"Invalid JSON Format","text":"<p>Problem: Config file has syntax errors.</p> <p>Solution: Validate JSON: <pre><code>cat ~/.config/voice-transcriber/config.json | jq .\n</code></pre></p> <p>If invalid, use one of the complete examples above or recreate the file.</p>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>First Run Guide - Complete setup walkthrough</li> <li>Transcription Backends - OpenAI vs Speaches</li> <li>Language Support - Multilingual transcription</li> </ul>","tags":["intermediate","reference","configuration"]},{"location":"getting-started/first-run/","title":"First Run Guide","text":"<p>This guide walks you through your first recording with Voice Transcriber.</p>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you've completed the Installation Guide:</p> <ul> <li>\u2705 Bun runtime installed</li> <li>\u2705 System dependencies (arecord, xsel) installed</li> <li>\u2705 Voice Transcriber installed (<code>make setup</code>)</li> <li>\u2705 Configuration file created with OpenAI API key</li> </ul> <p>Quick Setup Reminder</p> <pre><code>make setup  # One command to install everything\n</code></pre>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#step-1-start-the-application","title":"Step 1: Start the Application","text":"Global InstallationLocal InstallationDebug Mode (Recommended for First Run) <pre><code>voice-transcriber\n</code></pre> <pre><code>cd voice-transcriber\nmake run\n</code></pre> <pre><code># Global\nvoice-transcriber --debug\n\n# Local\nmake run ARGS=\"--debug\"\n</code></pre>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#step-2-configuration-wizard","title":"Step 2: Configuration Wizard","text":"<p>If this is your first run, you'll see the Configuration Wizard:</p> <pre><code>\ud83c\udfa4 Voice Transcriber - First Run Setup\n\nNo configuration found. Let's set up your OpenAI API key.\n\n\ud83d\udcdd Get your API key at: https://platform.openai.com/api-keys\n\nEnter your OpenAI API key: _\n</code></pre> <p>Enter your API key when prompted. The wizard will:</p> <ol> <li>Validate your API key</li> <li>Create configuration file at <code>~/.config/voice-transcriber/config.json</code></li> <li>Set default language to English</li> <li>Enable text formatting by default</li> </ol> <p>Setup Complete</p> <p>Once configured, you'll see: \"\u2705 Configuration saved successfully!\"</p>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#step-3-locate-the-system-tray-icon","title":"Step 3: Locate the System Tray Icon","text":"<p>Look for the green circle icon in your system tray:</p> <ul> <li> <p> IDLE (Green)</p> <p>Ready to record. Click to start recording.</p> </li> <li> <p> RECORDING (Red)</p> <p>Currently recording audio. Click to stop.</p> </li> <li> <p> PROCESSING (Purple)</p> <p>Transcribing audio. Wait for completion.</p> </li> </ul> <p>System Tray Location</p> <ul> <li>GNOME: Top-right corner (may need \"AppIndicator Support\" extension)</li> <li>KDE Plasma: Bottom-right panel</li> <li>XFCE/MATE: Top or bottom panel (near clock)</li> </ul>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#step-4-your-first-recording","title":"Step 4: Your First Recording","text":"","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#record-audio","title":"Record Audio","text":"<ol> <li>Click the system tray icon (or select \"Start Recording\" from menu)</li> <li>Icon changes to red circle \ud83d\udd34</li> <li>Speak into your microphone</li> <li>Click again to stop recording</li> </ol> <p>Example Recording</p> <p>\"Hello, this is my first test recording with Voice Transcriber.\"</p>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#processing","title":"Processing","text":"<ol> <li>Icon changes to purple circle \ud83d\udfe3</li> <li>Audio is transcribed by OpenAI Whisper</li> <li>Text is formatted by GPT (if enabled)</li> <li>Result is copied to your clipboard automatically</li> </ol>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#paste-result","title":"Paste Result","text":"<ol> <li>Open any text editor (e.g., gedit, VS Code, browser)</li> <li>Paste (Ctrl+V) the transcribed text</li> </ol> <p>Expected Result</p> <p>\"Hello, this is my first test recording with Voice Transcriber.\"</p>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#step-5-test-different-languages-optional","title":"Step 5: Test Different Languages (Optional)","text":"","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#configure-french","title":"Configure French","text":"<p>Edit your configuration:</p> <pre><code>nano ~/.config/voice-transcriber/config.json\n</code></pre> <p>Change language to French:</p> <pre><code>{\n  \"language\": \"fr\",\n  \"formatterEnabled\": true,\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\"\n    }\n  }\n}\n</code></pre> <p>Restart the application and try a French recording:</p> <p>French Recording</p> <p>\"Bonjour, ceci est un test de transcription en fran\u00e7ais.\"</p> <p>Expected paste result: <pre><code>Bonjour, ceci est un test de transcription en fran\u00e7ais.\n</code></pre></p>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#step-6-explore-menu-options","title":"Step 6: Explore Menu Options","text":"<p>Right-click the system tray icon to see available options:</p> <pre><code>\ud83c\udfa4 Voice Transcriber\n\u251c\u2500\u2500 \ud83c\udf99\ufe0f Start Recording\n\u251c\u2500\u2500 \u23f9\ufe0f Stop Recording\n\u2514\u2500\u2500 \u274c Exit\n</code></pre>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#menu-actions","title":"Menu Actions","text":"<ul> <li>Start Recording: Begin audio capture (disabled while recording)</li> <li>Stop Recording: End recording and transcribe (enabled only while recording)</li> <li>Exit: Exit the application gracefully</li> </ul> <p>Menu State</p> <p>The menu items change state automatically: - When idle: \"Start Recording\" is enabled, \"Stop Recording\" is disabled - When recording: \"Start Recording\" is disabled, \"Stop Recording\" is enabled</p>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#common-first-run-issues","title":"Common First-Run Issues","text":"","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#icon-not-visible","title":"Icon Not Visible","text":"<p>System Tray Not Showing</p> <p>GNOME Users: Install \"AppIndicator Support\" extension</p> <pre><code># Install extension\nsudo apt-get install gnome-shell-extension-appindicator\n\n# Restart GNOME Shell\n# Press Alt+F2, type 'r', press Enter\n</code></pre>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#audio-recording-fails","title":"Audio Recording Fails","text":"<p>arecord: device not found</p> <p>Solution: Check audio devices</p> <pre><code># List audio devices\narecord -l\n\n# Test recording manually\narecord -d 5 test.wav\nplay test.wav\n</code></pre>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#api-key-invalid","title":"API Key Invalid","text":"<p>OpenAI API Error: Invalid API key</p> <p>Solutions:</p> <ol> <li>Verify your API key at OpenAI Platform</li> <li>Check for extra spaces in config file</li> <li>Ensure key starts with <code>sk-</code></li> <li>Verify API key has Whisper API access</li> </ol>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#transcription-in-wrong-language","title":"Transcription in Wrong Language","text":"<p>French recorded but English transcribed</p> <p>Solution: Set language explicitly in config</p> <pre><code>{\n  \"language\": \"fr\"\n}\n</code></pre> <p>Restart the application after config changes.</p>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#debug-mode","title":"Debug Mode","text":"<p>Enable debug mode for detailed logging:</p> <pre><code># Global installation\nvoice-transcriber --debug\n\n# Local installation\nmake run ARGS=\"--debug\"\n</code></pre> <p>Debug output example:</p> <pre><code>2025-10-11T10:30:15.123Z [DEBUG] WAV file size: 2.45 MB\n2025-10-11T10:30:15.234Z [DEBUG] MP3 compression: 74.7% reduction\n2025-10-11T10:30:16.789Z [INFO] OpenAI transcription completed in 1.55s\n2025-10-11T10:30:16.789Z [DEBUG]   \u2514\u2500 Transcription: 142 characters\n</code></pre>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#next-steps","title":"Next Steps","text":"<p>Now that you've completed your first recording, explore more features:</p> <ul> <li>Basic Usage - Learn all recording options</li> <li>Language Support - Multilingual transcription</li> <li>Configuration - Advanced settings and custom prompts</li> <li>Self-Hosted Setup - Run 100% offline</li> </ul>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#quick-reference-card","title":"Quick Reference Card","text":"","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#essential-commands","title":"Essential Commands","text":"<pre><code># Run application\nmake run                       # From project directory\nvoice-transcriber              # If installed globally\n\n# Enable debug mode\nmake run ARGS=\"--debug\"        # From project directory\nvoice-transcriber --debug      # If installed globally\n\n# Edit configuration\nnano ~/.config/voice-transcriber/config.json\n\n# Check system dependencies\nmake check-system-deps\n\n# Test audio devices\narecord -l\n\n# View all available commands\nmake help\n</code></pre>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/first-run/#recording-workflow","title":"Recording Workflow","text":"<pre><code>1. Click tray icon \u2192 \ud83d\udfe2 to \ud83d\udd34\n2. Speak into microphone\n3. Click again \u2192 \ud83d\udd34 to \ud83d\udfe3\n4. Wait for processing\n5. Paste result (Ctrl+V)\n</code></pre> <p>Need Help?</p> <ul> <li>Troubleshooting Guide</li> <li>GitHub Issues</li> </ul>","tags":["beginner","tutorial","usage"]},{"location":"getting-started/installation/","title":"Installation Guide","text":"<p>This guide will help you install Voice Transcriber on your Linux system.</p>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing Voice Transcriber, ensure you have the following:</p>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#1-bun-runtime","title":"1. Bun Runtime","text":"<p>Voice Transcriber requires Bun \u22651.2.0:</p> <pre><code># Install Bun\ncurl -fsSL https://bun.sh/install | bash\n\n# Verify installation\nbun --version  # Should output \u22651.2.0\n</code></pre> <p>Bun documentation: https://bun.sh</p>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#2-system-dependencies","title":"2. System Dependencies","text":"<p>Install required system packages:</p> <pre><code>sudo apt-get update\nsudo apt-get install alsa-utils xsel\n</code></pre> <p>Package purposes:</p> <ul> <li><code>alsa-utils</code>: Provides <code>arecord</code> for audio recording</li> <li><code>xsel</code>: Cross-platform clipboard integration</li> </ul> <p>Verify installation:</p> <pre><code>which arecord  # Should output: /usr/bin/arecord\nwhich xsel     # Should output: /usr/bin/xsel\n</code></pre> <p>Quick Check</p> <p>You can verify all prerequisites at once with: <pre><code>make check-system-deps\n</code></pre></p>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#installation-methods","title":"Installation Methods","text":"","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#automated-setup-recommended","title":"Automated Setup (Recommended)","text":"<p>The fastest way to get started - one command does everything:</p> <pre><code># Step 1: Clone the repository\ngit clone https://github.com/Nouuu/voice-transcriber.git\ncd voice-transcriber\n\n# Step 2: Run automated setup\nmake setup\n</code></pre> <p>What <code>make setup</code> does:</p> <ul> <li>\u2705 Checks all system dependencies (Bun, arecord, xsel)</li> <li>\u2705 Installs Bun dependencies</li> <li>\u2705 Creates configuration file at <code>~/.config/voice-transcriber/config.json</code></li> <li>\u2705 Displays next steps</li> </ul>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#manual-setup","title":"Manual Setup","text":"<p>If you prefer step-by-step installation:</p> <pre><code># Step 1: Clone repository\ngit clone https://github.com/Nouuu/voice-transcriber.git\ncd voice-transcriber\n\n# Step 2: Check system dependencies\nmake check-system-deps\n\n# Step 3: Install Bun dependencies\nmake install\n\n# Step 4: Initialize configuration file\nmake init-config\n</code></pre>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#configuration","title":"Configuration","text":"<p>After installation, configure your OpenAI API key:</p> <pre><code># Edit configuration file\nnano ~/.config/voice-transcriber/config.json\n</code></pre> <p>Add your OpenAI API key:</p> <pre><code>{\n  \"language\": \"en\",\n  \"formatterEnabled\": true,\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-your-api-key-here\"\n    }\n  }\n}\n</code></pre> <p>Get your OpenAI API key: https://platform.openai.com/api-keys</p> <p>Configuration Options</p> <p>See the Configuration Guide for detailed configuration options including language settings, custom prompts, and self-hosted backends.</p>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#global-installation-optional","title":"Global Installation (Optional)","text":"<p>Install the <code>voice-transcriber</code> command globally:</p> <pre><code>make install-global\n</code></pre> <p>This allows you to run the application from anywhere:</p> <pre><code># Run from any directory\nvoice-transcriber\n\n# Enable debug mode\nvoice-transcriber --debug\n</code></pre>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#uninstall-global-command","title":"Uninstall Global Command","text":"<p>To remove the global command:</p> <pre><code>make uninstall-global\n</code></pre>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#running-the-application","title":"Running the Application","text":"","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#production-mode","title":"Production Mode","text":"<p>Run the application normally:</p> <pre><code># If installed globally\nvoice-transcriber\n\n# Or from project directory\nmake run\n</code></pre>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#development-mode","title":"Development Mode","text":"<p>Run with auto-reload for development:</p> <pre><code>make dev\n</code></pre>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed logging for troubleshooting:</p> <pre><code># Global installation\nvoice-transcriber --debug\n\n# Or from project directory\nmake run ARGS=\"--debug\"\n</code></pre> <p>Debug output includes:</p> <ul> <li>File sizes (WAV and MP3 compression ratios)</li> <li>Audio format details (sample rate, channels)</li> <li>Processing times (upload, processing, response)</li> <li>Transcription metrics (character count, duration)</li> </ul>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>Verify your installation:</p> <pre><code># 1. Check all system dependencies at once\nmake check-system-deps\n\n# 2. Verify configuration exists\ncat ~/.config/voice-transcriber/config.json\n\n# 3. Test audio recording\narecord -l  # Should list your audio devices\n\n# 4. Run the application\nmake run\n</code></pre> <p>Look for the green circle system tray icon indicating the app is ready.</p>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#platform-specific-notes","title":"Platform-Specific Notes","text":"","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#ubuntu-2204","title":"Ubuntu 22.04+","text":"<p>Fully supported with default installation steps.</p>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#other-linux-distributions","title":"Other Linux Distributions","text":"<ul> <li>Debian/Mint: Same as Ubuntu instructions</li> <li>Arch/Manjaro: Use <code>pacman -S alsa-utils xsel</code></li> <li>Fedora/RHEL: Use <code>dnf install alsa-utils xsel</code></li> </ul>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#wayland-vs-x11","title":"Wayland vs X11","text":"<p>Works on both Wayland and X11 desktop environments. System tray integration tested on:</p> <ul> <li>GNOME (Wayland and X11)</li> <li>KDE Plasma</li> <li>XFCE</li> <li>MATE</li> </ul> <p>Windows and macOS Support</p> <p>Currently, Voice Transcriber only supports Linux. Windows and macOS support is planned for future releases.</p>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#troubleshooting-installation","title":"Troubleshooting Installation","text":"","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#bun-installation-fails","title":"Bun Installation Fails","text":"<p>If Bun installation fails:</p> <pre><code># Try alternative installation method\nnpm install -g bun\n\n# Or download binary directly\ncurl -fsSL https://bun.sh/install | bash -s \"bun-v1.2.0\"\n</code></pre>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#system-dependencies-not-found","title":"System Dependencies Not Found","text":"<p>If <code>arecord</code> or <code>xsel</code> are not found:</p> <pre><code># Verify package manager\nwhich apt-get  # Debian/Ubuntu\nwhich pacman   # Arch\nwhich dnf      # Fedora\n\n# Update package cache\nsudo apt-get update  # Ubuntu\n</code></pre>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#permission-issues","title":"Permission Issues","text":"<p>If you encounter permission errors:</p> <pre><code># Ensure user is in audio group\nsudo usermod -a -G audio $USER\n\n# Log out and log back in for changes to take effect\n</code></pre>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#config-file-not-created","title":"Config File Not Created","text":"<p>If config file isn't created automatically:</p> <pre><code># Create directory and initialize config manually\nmake init-config\n</code></pre>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#available-make-commands","title":"Available Make Commands","text":"<p>Voice Transcriber includes many helpful make commands:</p> <pre><code># View all available commands\nmake help\n\n# Setup &amp; Installation\nmake setup              # Complete automated setup\nmake check-system-deps  # Verify system dependencies\nmake install            # Install Bun dependencies only\nmake init-config        # Create config file\n\n# Running\nmake run                # Run the application\nmake dev                # Development mode with watch\n\n# Testing &amp; Quality\nmake test               # Run all tests\nmake lint               # Run ESLint linting\nmake format             # Format code with Prettier\n\n# Documentation\nmake docs-serve         # Serve documentation locally\n</code></pre>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Guide - Configure languages and backends</li> <li>First Run - First-time setup walkthrough</li> <li>Basic Usage - Learn how to use the app</li> </ul> <p>Need Help?</p> <ul> <li>Troubleshooting Guide - Common issues and solutions</li> <li>GitHub Issues - Report bugs or request features</li> </ul>","tags":["beginner","guide","setup","installation"]},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>Get started with Voice Transcriber in 5 minutes or less.</p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#tldr-3-commands","title":"TL;DR - 3 Commands","text":"<pre><code># 1. Setup\nmake setup\n\n# 2. Configure API key\nnano ~/.config/voice-transcriber/config.json\n# Add your OpenAI API key\n\n# 3. Run\nmake run\n</code></pre> <p>Click the system tray icon to record. Click again to stop and transcribe.</p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#visual-workflow","title":"Visual Workflow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  STEP 1: Setup                                              \u2502\n\u2502  $ make setup                                               \u2502\n\u2502    \u2713 Check system dependencies (Bun, arecord, xsel)       \u2502\n\u2502    \u2713 Install Bun dependencies                              \u2502\n\u2502    \u2713 Create config file                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  STEP 2: Configure                                          \u2502\n\u2502  $ nano ~/.config/voice-transcriber/config.json            \u2502\n\u2502    {                                                        \u2502\n\u2502      \"language\": \"en\",                                      \u2502\n\u2502      \"transcription\": {                                     \u2502\n\u2502        \"backend\": \"openai\",                                 \u2502\n\u2502        \"openai\": {                                          \u2502\n\u2502          \"apiKey\": \"sk-...\"  \u2190 ADD YOUR KEY HERE          \u2502\n\u2502        }                                                    \u2502\n\u2502      }                                                      \u2502\n\u2502    }                                                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  STEP 3: Run                                                \u2502\n\u2502  $ make run                                                 \u2502\n\u2502    \u2713 App starts in system tray                             \u2502\n\u2502    \u26ab Idle icon appears in tray                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  STEP 4: Record                                             \u2502\n\u2502  Click tray icon                                            \u2502\n\u2502    \ud83d\udd34 Recording... (red icon)                              \u2502\n\u2502    [Speak your message]                                     \u2502\n\u2502  Click again to stop                                        \u2502\n\u2502    \u23f3 Processing... (hourglass icon)                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  STEP 5: Result                                             \u2502\n\u2502    \u2705 Transcription copied to clipboard                    \u2502\n\u2502    \u26ab Ready for next recording                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#minimal-configuration","title":"Minimal Configuration","text":"<p>The absolute minimum config to get started:</p> <pre><code>{\n  \"language\": \"en\",\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-your-api-key-here\"\n    }\n  }\n}\n</code></pre> <p>Save to: <code>~/.config/voice-transcriber/config.json</code></p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#get-your-openai-api-key","title":"Get Your OpenAI API Key","text":"<ol> <li>Go to platform.openai.com/api-keys</li> <li>Click \"Create new secret key\"</li> <li>Copy the key (starts with <code>sk-</code>)</li> <li>Paste it into your config file</li> </ol>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#first-recording-walkthrough","title":"First Recording Walkthrough","text":"","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#1-start-the-app","title":"1. Start the App","text":"<pre><code>make run\n</code></pre> <p>Look for the \u26ab black circle icon in your system tray (usually top-right corner).</p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#2-click-to-record","title":"2. Click to Record","text":"<p>Click the tray icon once \u2192 Icon changes to \ud83d\udd34 red (recording in progress)</p> <p>Speak clearly into your microphone:</p> <pre><code>\"Hello, this is a test of the voice transcription system.\"\n</code></pre>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#3-click-to-stop","title":"3. Click to Stop","text":"<p>Click the tray icon again \u2192 Icon changes to \u23f3 hourglass (processing)</p> <p>Processing usually takes 2-3 seconds for a 30-second recording.</p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#4-get-result","title":"4. Get Result","text":"<p>Icon returns to \u26ab black \u2192 Transcription is now in your clipboard!</p> <p>Paste anywhere (<code>Ctrl+V</code>):</p> <pre><code>Hello, this is a test of the voice transcription system.\n</code></pre>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#5-next-recording","title":"5. Next Recording","text":"<p>Click the tray icon again to start a new recording. Repeat!</p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#top-3-beginner-issues","title":"Top 3 Beginner Issues","text":"","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#issue-1-no-system-tray-icon-appears","title":"Issue 1: \"No system tray icon appears\"","text":"<p>Check your desktop environment:</p> <pre><code>echo $XDG_CURRENT_DESKTOP\n</code></pre> <p>Solutions:</p> <ul> <li>Gnome: Install AppIndicator extension</li> <li>KDE: System tray should work out of the box</li> <li>XFCE: Install <code>xfce4-indicator-plugin</code></li> </ul>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#issue-2-recording-failed-arecord-command-not-found","title":"Issue 2: \"Recording failed - arecord: command not found\"","text":"<p>Install ALSA utils:</p> <pre><code>sudo apt-get update\nsudo apt-get install alsa-utils\n</code></pre> <p>Verify installation:</p> <pre><code>arecord -l  # Should list your microphones\n</code></pre>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#issue-3-openai-api-error-invalid-api-key","title":"Issue 3: \"OpenAI API error: Invalid API key\"","text":"<p>Check your key format:</p> <ul> <li>Should start with <code>sk-</code></li> <li>Should be about 50 characters long</li> <li>No extra spaces or quotes in config file</li> </ul> <p>Verify in config:</p> <pre><code>cat ~/.config/voice-transcriber/config.json | grep apiKey\n</code></pre> <p>Should show: <code>\"apiKey\": \"sk-proj...\"</code></p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#quick-tips","title":"Quick Tips","text":"","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#change-language","title":"Change Language","text":"<p>Edit config to use French:</p> <pre><code>{\n  \"language\": \"fr\"\n}\n</code></pre> <p>Supported: <code>en</code>, <code>fr</code>, <code>es</code>, <code>de</code>, <code>it</code></p> <p>Reload config from system tray menu (right-click icon \u2192 Reload Configuration)</p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#use-formatting","title":"Use Formatting","text":"<p>Enable text formatting with personalities:</p> <pre><code>{\n  \"activePersonalities\": [\n    \"builtin:professional\"\n  ],\n  \"formatter\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\"\n    }\n  }\n}\n</code></pre>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#debug-mode","title":"Debug Mode","text":"<p>See what's happening under the hood:</p> <pre><code>make run -- --debug\n</code></pre> <p>Shows:</p> <ul> <li>Configuration loading</li> <li>Recording start/stop</li> <li>Transcription progress</li> <li>API responses</li> </ul>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#stop-the-app","title":"Stop the App","text":"<p>From system tray: Right-click icon \u2192 Quit</p> <p>From terminal: Press <code>Ctrl+C</code></p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#whats-next","title":"What's Next?","text":"","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#for-basic-users","title":"For Basic Users","text":"<ul> <li>Basic Usage - System tray controls, keyboard shortcuts</li> <li>Language Support - Multilingual transcription</li> <li>Troubleshooting - Common issues and solutions</li> </ul>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#for-advanced-users","title":"For Advanced Users","text":"<ul> <li>Configuration Guide - Complete configuration reference</li> <li>Formatting Personalities - Customize text formatting</li> <li>Transcription Backends - OpenAI vs Speaches</li> </ul>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#for-power-users","title":"For Power Users","text":"<ul> <li>Speaches Integration - Self-hosted, offline transcription</li> <li>Contributing Guide - Build from source, contribute</li> </ul>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#common-workflows","title":"Common Workflows","text":"","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#quick-note-taking","title":"Quick Note Taking","text":"<ol> <li>Click tray icon</li> <li>Dictate your note</li> <li>Click to stop</li> <li>Paste into your note app</li> </ol> <p>Average time: ~5 seconds from recording to clipboard</p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#email-drafting","title":"Email Drafting","text":"<ol> <li>Configure professional formatting:    <pre><code>{\n  \"activePersonalities\": [\"builtin:professional\"]\n}\n</code></pre></li> <li>Dictate email content</li> <li>Paste into email client</li> <li>Minor edits if needed</li> </ol>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#multilingual-documentation","title":"Multilingual Documentation","text":"<ol> <li>Switch language for each section:    <pre><code>{ \"language\": \"fr\" }  // French section\n{ \"language\": \"en\" }  // English section\n</code></pre></li> <li>Reload config between languages</li> <li>Dictate in target language</li> </ol>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#performance-expectations","title":"Performance Expectations","text":"Metric Expected Value Recording \u2192 Clipboard 2-3 seconds (30s audio) First startup time 1-2 seconds Memory usage ~50-100MB CPU usage (recording) &lt;5% CPU usage (processing) 15-30% (brief spike)","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#need-help","title":"Need Help?","text":"<p>Didn't work? Check:</p> <ol> <li>\u2705 System dependencies installed (<code>make check-system-deps</code>)</li> <li>\u2705 Config file exists (<code>cat ~/.config/voice-transcriber/config.json</code>)</li> <li>\u2705 OpenAI API key is valid (starts with <code>sk-</code>)</li> <li>\u2705 Microphone permissions granted</li> <li>\u2705 System tray is supported by your desktop environment</li> </ol> <p>Still stuck?</p> <ul> <li>Troubleshooting Guide - Detailed solutions</li> <li>GitHub Issues - Report bugs or ask questions</li> </ul> <p>Ready to dive deeper? Check out the Complete Installation Guide for advanced setup options.</p>","tags":["beginner","guide","setup","tutorial"]},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Complete Installation Guide - Detailed installation with all options</li> <li>Configuration Guide - All configuration options and settings</li> <li>First Run Guide - Step-by-step first recording walkthrough</li> <li>Basic Usage - Learn all features and workflows</li> </ul>","tags":["beginner","guide","setup","tutorial"]},{"location":"user-guide/basic-usage/","title":"Basic Usage Guide","text":"<p>Learn how to use Voice Transcriber effectively for everyday voice-to-text transcription.</p>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#system-tray-interface","title":"System Tray Interface","text":"<p>Voice Transcriber operates through a system tray icon with three visual states:</p> <ul> <li> <p> IDLE</p> <p>Green circle - Ready to record</p> <p>Click to start recording</p> </li> <li> <p> RECORDING</p> <p>Red circle - Currently recording</p> <p>Speak into microphone, click to stop</p> </li> <li> <p> PROCESSING</p> <p>Purple circle - Transcribing audio</p> <p>Wait for completion, result copied to clipboard</p> </li> </ul>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#recording-audio","title":"Recording Audio","text":"","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#start-recording","title":"Start Recording","text":"<p>Method 1: Click tray icon</p> <ol> <li>Left-click the system tray icon (green circle)</li> <li>Icon changes to red</li> <li>Start speaking into your microphone</li> </ol> <p>Method 2: Context menu</p> <ol> <li>Right-click the system tray icon</li> <li>Select \"Start Recording\"</li> <li>Icon changes to red</li> <li>Start speaking</li> </ol> <p>Microphone Position</p> <p>For best results, position your microphone 15-30 cm from your mouth</p>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#stop-recording","title":"Stop Recording","text":"<p>Method 1: Click tray icon again</p> <ol> <li>Left-click the system tray icon (red circle)</li> <li>Icon changes to purple (processing)</li> <li>Wait for transcription</li> </ol> <p>Method 2: Context menu</p> <ol> <li>Right-click the system tray icon</li> <li>Select \"Stop Recording\"</li> <li>Icon changes to purple (processing)</li> </ol>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#automatic-clipboard-copy","title":"Automatic Clipboard Copy","text":"<p>Once processing completes:</p> <ol> <li>Icon returns to green (idle)</li> <li>Transcribed text is automatically copied to your clipboard</li> <li>Paste anywhere with <code>Ctrl+V</code> (Linux) or <code>Cmd+V</code> (macOS)</li> </ol>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#example-workflow","title":"Example Workflow","text":"Quick NoteEmail DictationMeeting Notes <pre><code>1. Click tray icon (\ud83d\udfe2 \u2192 \ud83d\udd34)\n2. \"Make a note to follow up with the client tomorrow\"\n3. Click again (\ud83d\udd34 \u2192 \ud83d\udfe3)\n4. Wait 2-3 seconds\n5. Paste in your notes app: \"Make a note to follow up with the client tomorrow.\"\n</code></pre> <pre><code>1. Click tray icon\n2. \"Hi team, I wanted to share an update on the project...\"\n3. Click again\n4. Wait for processing\n5. Paste in email client: \"Hi team, I wanted to share an update on the project...\"\n</code></pre> <pre><code>1. Start recording at beginning of meeting\n2. Let meeting proceed naturally\n3. Stop recording at end\n4. Paste transcription in notes document\n5. Review and edit as needed\n</code></pre>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#context-menu-options","title":"Context Menu Options","text":"<p>Right-click the tray icon for available actions:</p> <pre><code>\ud83c\udfa4 Voice Transcriber\n\u251c\u2500\u2500 \ud83c\udf99\ufe0f Start Recording\n\u251c\u2500\u2500 \u23f9\ufe0f Stop Recording\n\u251c\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u251c\u2500\u2500 \u2611 Default\n\u251c\u2500\u2500 \u2610 Professional\n\u251c\u2500\u2500 \u2610 Technical\n\u251c\u2500\u2500 \u2610 Creative\n\u251c\u2500\u2500 \u2610 Emojify\n\u251c\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u251c\u2500\u2500 \ud83d\udcbe Save as Default\n\u251c\u2500\u2500 \u2699\ufe0f Open Config\n\u251c\u2500\u2500 \ud83d\udd04 Reload Config\n\u2514\u2500\u2500 \u274c Exit\n</code></pre>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#core-actions","title":"Core Actions","text":"Start Recording Begin audio capture (disabled while recording) Same as left-click when idle Stop Recording End recording and transcribe (enabled only while recording) Same as left-click when recording","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#formatting-personalities","title":"Formatting Personalities","text":"Personality Checkboxes (Default, Professional, Technical, Creative, Emojify) Toggle formatting styles on/off Multiple personalities can be active simultaneously See Formatting Personalities for details \ud83d\udcbe Save as Default Save your current personality preferences to config file No need to manually edit <code>config.json</code> Changes persist across restarts <p>Quick Personality Changes</p> <ol> <li>Check/uncheck personalities to test different combinations</li> <li>Click \"\ud83d\udcbe Save as Default\" when you find your favorite setup</li> <li>Restart \u2192 Your preferences are restored automatically</li> </ol>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#configuration-actions","title":"Configuration Actions","text":"Open Config Opens configuration file in your default text editor Always available Reload Config Reloads configuration without restarting Only available when idle (not recording or processing) See Configuration Management for details Exit Exit the application gracefully <p>Menu State Management</p> <p>Menu items automatically enable/disable based on application state to prevent accidental errors.</p> Menu Item Idle (\ud83d\udfe2) Recording (\ud83d\udd34) Processing (\ud83d\udfe3) Start Recording \u2705 Enabled \u274c Disabled \u274c Disabled Stop Recording \u274c Disabled \u2705 Enabled \u274c Disabled Personalities \u2705 Enabled \u2705 Enabled \u2705 Enabled Save as Default \u2705 Enabled \u274c Disabled \u274c Disabled Open Config \u2705 Enabled \u2705 Enabled \u2705 Enabled Reload Config \u2705 Enabled \u274c Disabled \u274c Disabled Exit \u2705 Enabled \u2705 Enabled \u2705 Enabled","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#advanced-features","title":"Advanced Features","text":"","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#configuration-reload","title":"Configuration Reload","text":"<p>You can modify your configuration and reload it without restarting:</p> <ol> <li>Right-click \u2192 \"\u2699\ufe0f Open Config\"</li> <li>Edit settings (language, backend, etc.)</li> <li>Save the file</li> <li>Right-click \u2192 \"\ud83d\udd04 Reload Config\"</li> </ol> <p>Changes take effect immediately!</p> <p>For Advanced Users</p> <p>See Configuration Management for:</p> <ul> <li>Change detection (debug mode)</li> <li>Safety features and validation</li> <li>Advanced workflows</li> <li>Troubleshooting reload issues</li> </ul>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed logging for troubleshooting:</p> <pre><code>voice-transcriber --debug\n</code></pre> <p>Shows performance metrics, file sizes, processing times, and more.</p> <p>For Advanced Users</p> <p>See Debug Mode for:</p> <ul> <li>Complete debug output reference</li> <li>Performance analysis</li> <li>Backend comparison</li> <li>Benchmark mode</li> </ul>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#best-practices","title":"Best Practices","text":"","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#for-accuracy","title":"For Accuracy","text":"<p>Improve Transcription Quality</p> <ul> <li>Speak clearly at a moderate pace</li> <li>Minimize background noise when possible</li> <li>Use a quality microphone for best results</li> <li>Pause between sentences for better formatting</li> </ul>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#for-efficiency","title":"For Efficiency","text":"<p>Maximize Productivity</p> <ul> <li>Use keyboard shortcuts (if your desktop environment supports global hotkeys)</li> <li>Record in chunks for long dictations (easier to review)</li> <li>Review transcriptions before using (especially for technical content)</li> <li>Customize language settings for consistent results</li> </ul>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#for-multilingual-use","title":"For Multilingual Use","text":"<p>Language Consistency</p> <ul> <li>Set primary language in config file</li> <li>Restart after language changes for prompts to take effect</li> <li>Avoid language mixing for best accuracy</li> <li>See Language Support for details</li> </ul>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#common-use-cases","title":"Common Use Cases","text":"","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#note-taking","title":"Note Taking","text":"<p>Perfect for: Meeting notes, lecture notes, brainstorming sessions</p> <p>Tips: - Record entire meeting or lecture - Transcribe in segments for easier review - Edit transcription afterward for clarity</p>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#message-dictation","title":"Message Dictation","text":"<p>Perfect for: Emails, chat messages, social media posts</p> <p>Tips: - Speak naturally but with clear punctuation - Enable formatter for proper capitalization - Review before sending</p>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#content-creation","title":"Content Creation","text":"<p>Perfect for: Blog posts, articles, scripts</p> <p>Tips: - Outline first, then dictate sections - Use short recordings for easier editing - Transcribe ideas quickly without typing</p>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#accessibility","title":"Accessibility","text":"<p>Perfect for: Users with typing difficulties, RSI, or mobility issues</p> <p>Tips: - Configure comfortable microphone position - Use voice commands in conjunction with transcription - Combine with accessibility tools in your OS</p>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#performance-expectations","title":"Performance Expectations","text":"","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#transcription-speed","title":"Transcription Speed","text":"Recording Length Processing Time Notes 5-10 seconds 1-2 seconds Near-instant 30 seconds 2-4 seconds Very fast 1 minute 3-6 seconds Fast 5 minutes 10-20 seconds Moderate 10+ minutes 20-40 seconds Longer wait <p>Processing Time Factors</p> <ul> <li>OpenAI API response time</li> <li>Audio file size and compression</li> <li>Internet connection speed</li> <li>GPT formatting (adds 1-2 seconds if enabled)</li> </ul>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#accuracy-expectations","title":"Accuracy Expectations","text":"Content Type Expected Accuracy Notes Clear speech 95-98% Excellent Technical terms 85-95% Good, may need review Accented speech 80-95% Varies by accent Noisy environment 70-85% Reduced accuracy Mixed languages 75-90% See language support","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#keyboard-shortcuts-future-feature","title":"Keyboard Shortcuts (Future Feature)","text":"<p>Coming Soon</p> <p>Global keyboard shortcuts are planned for a future release. Currently, Wayland security restrictions prevent global hotkey registration. This feature will be available when Wayland adds proper hotkey support.</p>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Language Support - Multilingual transcription</li> <li>Transcription Backends - OpenAI vs Speaches</li> <li>Troubleshooting - Common issues and solutions</li> </ul> <p>Need Help?</p> <ul> <li>Troubleshooting Guide</li> <li>GitHub Issues</li> </ul>","tags":["beginner","guide","usage","tutorial"]},{"location":"user-guide/formatting-personalities/","title":"Formatting Personalities","text":"<p>Voice Transcriber uses \"personalities\" to format transcribed text according to different styles. You can use multiple personalities simultaneously, and they can be quickly toggled from the system tray menu.</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#overview","title":"\ud83c\udfaf Overview","text":"","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#what-are-personalities","title":"What are Personalities?","text":"<p>Personalities are formatting styles that transform raw transcriptions into polished text. Each personality contains:</p> <ul> <li>Name: Display name in the menu</li> <li>Description: What the personality does</li> <li>Prompt: Instructions sent to the LLM (GPT/Ollama)</li> </ul>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#how-they-work","title":"How They Work","text":"<pre><code>Raw Transcription\n    \u2193\nPersonality Prompts (concatenated)\n    \u2193\nLLM (GPT-4o-mini / Ollama)\n    \u2193\nFormatted Text\n    \u2193\nClipboard\n</code></pre> <p>Single Request</p> <p>Multiple personalities are combined into one LLM request (not applied sequentially). This is faster and cheaper, but means personalities should be complementary.</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#built-in-personalities","title":"\ud83d\udce6 Built-in Personalities","text":"<p>Voice Transcriber includes 5 built-in personalities ready to use:</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#default","title":"Default","text":"<p>ID: <code>builtin:default</code></p> <p>Style: Minimal formatting - Fix grammar only</p> <p>Use cases: - Quick notes - When you want minimal changes - Preserving original speaking style</p> <p>Example: <pre><code>Input:  \"um so basically I think we should uh maybe try the new approach\"\nOutput: \"I think we should try the new approach.\"\n</code></pre></p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#professional","title":"Professional","text":"<p>ID: <code>builtin:professional</code></p> <p>Style: Business communication</p> <p>Use cases: - Work emails - Business reports - Meeting summaries - Professional correspondence</p> <p>Example: <pre><code>Input:  \"hey can you send me that report we talked about yesterday\"\nOutput: \"Could you please send me the report we discussed yesterday?\"\n</code></pre></p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#technical","title":"Technical","text":"<p>ID: <code>builtin:technical</code></p> <p>Style: Technical documentation</p> <p>Use cases: - Code documentation - Technical specifications - Bug reports - API documentation</p> <p>Example: <pre><code>Input:  \"so the function takes a string and returns um like a boolean\"\nOutput: \"The function accepts a string parameter and returns a boolean value.\"\n</code></pre></p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#creative","title":"Creative","text":"<p>ID: <code>builtin:creative</code></p> <p>Style: Expressive and natural</p> <p>Use cases: - Blog posts - Creative writing - Social media - Personal notes</p> <p>Example: <pre><code>Input:  \"it was really amazing the sunset was beautiful\"\nOutput: \"It was truly amazing! The sunset painted the sky in beautiful colors.\"\n</code></pre></p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#emojify","title":"Emojify","text":"<p>ID: <code>builtin:emojify</code></p> <p>Style: Add context-appropriate emojis (max 3)</p> <p>Use cases: - Social media posts - Casual messages - Adding visual flair</p> <p>Rules: - Very short text (&lt; 40 chars): max 1 emoji - Medium text (40-120 chars): max 2 emojis - Long text (&gt; 120 chars): max 3 emojis</p> <p>Example: <pre><code>Input:  \"the meeting went great we got approval for the project\"\nOutput: \"The meeting went great! \ud83c\udf89 We got approval for the project. \u2705\"\n</code></pre></p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#configuration","title":"\u2699\ufe0f Configuration","text":"","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#basic-setup","title":"Basic Setup","text":"<p>Edit <code>~/.config/voice-transcriber/config.json</code>:</p> <pre><code>{\n  \"activePersonalities\": [\"builtin:professional\"],\n  \"selectedPersonalities\": [\n    \"builtin:default\",\n    \"builtin:professional\",\n    \"builtin:technical\"\n  ]\n}\n</code></pre> <ul> <li><code>activePersonalities</code>: Which personalities are checked (applied to transcriptions)</li> <li><code>selectedPersonalities</code>: Which personalities appear in the menu</li> </ul>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#using-the-system-tray","title":"Using the System Tray","text":"<p>Quick Toggle (no config editing needed):</p> <ol> <li>Right-click system tray icon</li> <li>Check/uncheck personalities</li> <li>Click \"\ud83d\udcbe Save as Default\" to persist</li> <li>Restart \u2192 Your preferences are restored</li> </ol> <p>Live Changes</p> <p>Changes via the menu take effect immediately. No need to restart until you want to persist them with \"Save as Default\".</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#custom-personalities","title":"\ud83c\udfa8 Custom Personalities","text":"","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#creating-custom-personalities","title":"Creating Custom Personalities","text":"<p>Add to <code>customPersonalities</code> in config:</p> <pre><code>{\n  \"customPersonalities\": {\n    \"code-review\": {\n      \"name\": \"Code Review\",\n      \"description\": \"Concise code review comments\",\n      \"prompt\": \"Format as a concise code review comment. Be constructive and specific. Include suggestions for improvement. Do not translate the text; keep it in the original language.\"\n    }\n  },\n  \"selectedPersonalities\": [\n    \"builtin:default\",\n    \"custom:code-review\"\n  ]\n}\n</code></pre>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#custom-personality-template","title":"Custom Personality Template","text":"<pre><code>{\n  \"customPersonalities\": {\n    \"YOUR_ID_HERE\": {\n      \"name\": \"Display Name in Menu\",\n      \"description\": \"What this personality does\",\n      \"prompt\": \"Detailed instructions for the LLM...\"\n    }\n  }\n}\n</code></pre> <p>Best practices for prompts: - Be specific about the desired output format - Include examples if needed - Specify tone (formal, casual, technical, etc.) - Mention any constraints (length, structure) - Always end with: \"Do not translate the text; keep it in the original language.\"</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#real-world-examples","title":"Real-World Examples","text":"","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#email-response","title":"Email Response","text":"<pre><code>{\n  \"email-response\": {\n    \"name\": \"Email Response\",\n    \"description\": \"Professional email reply format\",\n    \"prompt\": \"Format as a professional email response. Include greeting, body, and closing. Use polite and concise language. Maintain professional tone. Do not translate the text; keep it in the original language.\"\n  }\n}\n</code></pre>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#meeting-notes","title":"Meeting Notes","text":"<pre><code>{\n  \"meeting-notes\": {\n    \"name\": \"Meeting Notes\",\n    \"description\": \"Structured meeting summary\",\n    \"prompt\": \"Format as structured meeting notes with sections: Discussion Points, Decisions Made, Action Items. Use bullet points. Be concise and clear. Do not translate the text; keep it in the original language.\"\n  }\n}\n</code></pre>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#social-media","title":"Social Media","text":"<pre><code>{\n  \"social-media\": {\n    \"name\": \"Social Media\",\n    \"description\": \"Engaging social post\",\n    \"prompt\": \"Format for social media. Make it engaging and conversational. Add relevant hashtags. Keep it concise (under 280 characters). Do not translate the text; keep it in the original language.\"\n  }\n}\n</code></pre>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#french-technical","title":"French Technical","text":"<pre><code>{\n  \"technical-fr\": {\n    \"name\": \"Technical FR\",\n    \"description\": \"French technical documentation\",\n    \"prompt\": \"Formate en style documentation technique fran\u00e7aise. Utilise un vocabulaire pr\u00e9cis et professionnel. Garde les termes techniques anglais courants. Utilise le vouvoiement. Ne traduis pas le texte; garde-le dans sa langue d'origine.\"\n  }\n}\n</code></pre>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#multiple-personalities","title":"\ud83d\udd04 Multiple Personalities","text":"","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#how-concatenation-works","title":"How Concatenation Works","text":"<p>When you activate multiple personalities, their prompts are combined with a separator:</p> <pre><code>Professional Prompt\n---\nEmojify Prompt\n---\nYour Text Here\n</code></pre> <p>Result: One LLM request with combined instructions</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#best-combinations","title":"Best Combinations","text":"","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#work-mode","title":"Work Mode","text":"<p><pre><code>{\n  \"activePersonalities\": [\n    \"builtin:professional\",\n    \"builtin:technical\"\n  ]\n}\n</code></pre> Use for: Technical work emails, documentation</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#social-mode","title":"Social Mode","text":"<p><pre><code>{\n  \"activePersonalities\": [\n    \"builtin:creative\",\n    \"builtin:emojify\"\n  ]\n}\n</code></pre> Use for: Social media, casual communication</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#documentation-mode","title":"Documentation Mode","text":"<p><pre><code>{\n  \"activePersonalities\": [\n    \"builtin:technical\",\n    \"custom:meeting-notes\"\n  ]\n}\n</code></pre> Use for: Meeting documentation, technical specs</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#combinations-to-avoid","title":"Combinations to Avoid","text":"<p>\u274c Conflicting styles: <pre><code>{\n  \"activePersonalities\": [\n    \"builtin:professional\",  // Formal\n    \"builtin:creative\"        // Expressive\n  ]\n}\n</code></pre> Problem: Contradictory instructions may confuse the LLM</p> <p>\u274c Too many personalities: <pre><code>{\n  \"activePersonalities\": [\n    \"builtin:default\",\n    \"builtin:professional\",\n    \"builtin:technical\",\n    \"builtin:creative\",\n    \"custom:style1\",\n    \"custom:style2\"\n  ]\n}\n</code></pre> Problem: May exceed <code>maxPromptLength</code>, inconsistent output</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#advanced-configuration","title":"\u26a1 Advanced Configuration","text":"","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#prompt-length-limit","title":"Prompt Length Limit","text":"<p>Control maximum combined prompt length:</p> <pre><code>{\n  \"maxPromptLength\": 4000,\n  \"activePersonalities\": [\n    \"builtin:professional\",\n    \"builtin:technical\",\n    \"custom:detailed-style\"\n  ]\n}\n</code></pre> <p>What happens: - Prompts are added one by one - If adding a prompt exceeds <code>maxPromptLength</code>, concatenation stops - Remaining personalities are skipped</p> <p>Default: <code>4000</code> characters</p> <p>When to increase: - Using many custom personalities with long prompts - Need very detailed instructions</p> <p>When to decrease: - Want to ensure faster processing - Using simpler personality combinations</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#disable-formatting","title":"Disable Formatting","text":"<p>To transcribe without formatting, use empty <code>activePersonalities</code>:</p> <pre><code>{\n  \"activePersonalities\": []\n}\n</code></pre> <p>Result: Raw transcription only, no GPT/Ollama call</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#tips-tricks","title":"\ud83d\udca1 Tips &amp; Tricks","text":"","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#tip-1-start-simple","title":"Tip 1: Start Simple","text":"<p>Begin with one personality, test it, then add more:</p> <pre><code>{\n  \"activePersonalities\": [\"builtin:professional\"]\n}\n</code></pre> <p>Test thoroughly before adding combinations.</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#tip-2-keep-menu-clean","title":"Tip 2: Keep Menu Clean","text":"<p>Only show personalities you actually use:</p> <pre><code>{\n  \"selectedPersonalities\": [\n    \"builtin:default\",\n    \"builtin:professional\"\n  ]\n}\n</code></pre> <p>Cleaner menu = faster selection</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#tip-3-test-custom-personalities","title":"Tip 3: Test Custom Personalities","text":"<p>Before saving permanently: 1. Add custom personality to config 2. Reload config (<code>\ud83d\udd04</code> in menu) 3. Test it 4. If good \u2192 \"\ud83d\udcbe Save as Default\" 5. If not \u2192 Edit and reload again</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#tip-4-debug-mode","title":"Tip 4: Debug Mode","text":"<p>See which personalities are being used:</p> <pre><code>voice-transcriber --debug\n</code></pre> <p>Logs show: <pre><code>[INFO] Formatting text with personalities: builtin:professional, builtin:emojify\n</code></pre></p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#tip-5-backup-custom-personalities","title":"Tip 5: Backup Custom Personalities","text":"<pre><code># Save your custom personalities\ncp ~/.config/voice-transcriber/config.json ~/my-personalities-backup.json\n\n# Or use Git\ncd ~/.config/voice-transcriber\ngit init\ngit add config.json\ngit commit -m \"My custom personalities\"\n</code></pre>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":"","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#formatting-not-applied","title":"Formatting Not Applied","text":"<p>Problem: Text not formatted</p> <p>Check: 1. <code>activePersonalities</code> not empty? 2. Formatter backend configured (OpenAI API key or Ollama)? 3. Check logs for errors</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#unexpected-results","title":"Unexpected Results","text":"<p>Problem: Formatting doesn't match expectations</p> <p>Solutions: 1. Test personality individually (disable others) 2. Refine custom personality prompt 3. Check for conflicting personality combinations 4. Verify <code>maxPromptLength</code> not being exceeded</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#custom-personality-not-showing","title":"Custom Personality Not Showing","text":"<p>Problem: Custom personality not in menu</p> <p>Check: 1. Added to <code>customPersonalities</code>? 2. Added to <code>selectedPersonalities</code> with <code>custom:</code> prefix? 3. Reloaded config after changes?</p> <p>Example: <pre><code>{\n  \"customPersonalities\": {\n    \"myStyle\": { ... }\n  },\n  \"selectedPersonalities\": [\n    \"custom:myStyle\"  // \u2190 Must have \"custom:\" prefix\n  ]\n}\n</code></pre></p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#prompts-too-long","title":"Prompts Too Long","text":"<p>Problem: <code>[DEBUG] Stopped concatenating: would exceed maxPromptLength</code></p> <p>Solutions: 1. Increase <code>maxPromptLength</code> 2. Use fewer personalities 3. Shorten custom personality prompts 4. Prioritize: put most important personalities first in <code>activePersonalities</code></p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#personality-comparison","title":"\ud83d\udcca Personality Comparison","text":"Personality Tone Length Use Case Emoji Default Neutral Same General No Professional Formal Similar Business No Technical Precise Structured Documentation No Creative Expressive Variable Content No Emojify Same Same Social Yes","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#quick-reference","title":"\ud83d\ude80 Quick Reference","text":"","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#via-system-tray-recommended","title":"Via System Tray (Recommended)","text":"<pre><code>1. Right-click tray icon\n2. Check/uncheck personalities\n3. Click \"\ud83d\udcbe Save as Default\"\n4. Done!\n</code></pre>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#via-config-file","title":"Via Config File","text":"<pre><code>{\n  \"activePersonalities\": [\"builtin:professional\"],\n  \"selectedPersonalities\": [\n    \"builtin:default\",\n    \"builtin:professional\",\n    \"builtin:technical\"\n  ],\n  \"customPersonalities\": {\n    \"myStyle\": {\n      \"name\": \"My Style\",\n      \"description\": \"...\",\n      \"prompt\": \"...\"\n    }\n  }\n}\n</code></pre> <p>Then: <code>\ud83d\udd04 Reload Config</code> in system tray</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/formatting-personalities/#see-also","title":"\ud83d\udcda See Also","text":"<ul> <li>Configuration Guide - Full configuration reference</li> <li>Basic Usage - How to use the application</li> <li>Examples - Real-world personality examples</li> </ul> <p>Last updated: 2025-10-29</p>","tags":["intermediate","guide","formatting","personalities","configuration"]},{"location":"user-guide/language-support/","title":"Language Support","text":"<p>Voice Transcriber supports multiple languages with strong language enforcement to prevent unwanted language switching during transcription.</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#supported-languages","title":"Supported Languages","text":"Language Code Quality Notes English <code>en</code> \u2b50\u2b50\u2b50\u2b50\u2b50 Default, excellent accuracy French <code>fr</code> \u2b50\u2b50\u2b50\u2b50\u2b50 Excellent, strong enforcement Spanish <code>es</code> \u2b50\u2b50\u2b50\u2b50\u2b50 Excellent support German <code>de</code> \u2b50\u2b50\u2b50\u2b50\u2b50 Excellent support Italian <code>it</code> \u2b50\u2b50\u2b50\u2b50\u2b50 Excellent support","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#configuring-language","title":"Configuring Language","text":"<p>Edit your configuration file:</p> <pre><code>nano ~/.config/voice-transcriber/config.json\n</code></pre> <p>Set the <code>language</code> field:</p> <pre><code>{\n  \"language\": \"fr\",\n  \"activePersonalities\": [\"builtin:default\"],\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\"\n    }\n  },\n  \"formatter\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\"\n    }\n  }\n}\n</code></pre> <p>Restart the application for changes to take effect.</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#language-enforcement","title":"Language Enforcement","text":"<p>Voice Transcriber uses strong language-specific prompts to prevent Whisper from switching languages mid-transcription.</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#how-it-works","title":"How It Works","text":"<p>When you set a language (e.g., French):</p> <ol> <li> <p>Transcription prompt explicitly instructs Whisper:    <pre><code>This is a French audio recording. Transcribe the entire audio in French only.\nDo NOT switch to English or translate. Keep all content in French.\n</code></pre></p> </li> <li> <p>Formatting prompt maintains the language:    <pre><code>Format this French text with proper grammar and punctuation.\nKeep the text in French. Do not translate.\n</code></pre></p> </li> </ol> <p>This dual-layer enforcement ensures your transcriptions stay in the configured language.</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#examples-by-language","title":"Examples by Language","text":"","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#english","title":"English","text":"<p>Recording: \"Hello, this is a test of the transcription system\"</p> <p>Result: \"Hello, this is a test of the transcription system.\"</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#french","title":"French","text":"<p>Recording: \"Bonjour, ceci est un test du syst\u00e8me de transcription\"</p> <p>Result: \"Bonjour, ceci est un test du syst\u00e8me de transcription.\"</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#spanish","title":"Spanish","text":"<p>Recording: \"Hola, esta es una prueba del sistema de transcripci\u00f3n\"</p> <p>Result: \"Hola, esta es una prueba del sistema de transcripci\u00f3n.\"</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#mixed-language-content","title":"Mixed-Language Content","text":"<p>For recordings with technical English terms in French sentences (common in tech contexts):</p> <p>Configuration: <pre><code>{\n  \"language\": \"fr\",\n  \"transcriptionPrompt\": \"Transcribe this French audio. Keep technical English terms but preserve French grammar.\",\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\"\n    }\n  }\n}\n</code></pre></p> <p>Recording: \"J'utilise React avec TypeScript pour d\u00e9velopper l'application\"</p> <p>Result: \"J'utilise React avec TypeScript pour d\u00e9velopper l'application.\"</p> <p>Custom Prompts</p> <p>See Configuration Guide for advanced mixed-language scenarios.</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#troubleshooting-language-issues","title":"Troubleshooting Language Issues","text":"","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#french-transcription-switches-to-english","title":"French Transcription Switches to English","text":"<p>Problem: Long French recordings switch to English mid-way</p> <p>Solution: Ensure language is set explicitly:</p> <pre><code>{\n  \"language\": \"fr\",\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\"\n    }\n  }\n}\n</code></pre> <p>Restart the application after config changes.</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#technical-terms-not-recognized","title":"Technical Terms Not Recognized","text":"<p>Problem: Technical English terms in French speech are poorly transcribed</p> <p>Solution: Use custom transcription prompt:</p> <pre><code>{\n  \"language\": \"fr\",\n  \"transcriptionPrompt\": \"Transcribe this French technical audio. Keep common English technical terms as-is.\",\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\"\n    }\n  }\n}\n</code></pre>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#accent-not-recognized-well","title":"Accent Not Recognized Well","text":"<p>Problem: Strong accent reduces accuracy</p> <p>Solutions: - Speak slightly slower and more clearly - Reduce background noise for better recognition - Try self-hosted Speaches with different models (see Speaches Integration)</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#language-specific-tips","title":"Language-Specific Tips","text":"","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#french_1","title":"French","text":"<ul> <li>Accents (\u00e9, \u00e8, \u00e0, \u00e7) are generally recognized well</li> <li>Homophones (ou/o\u00f9, a/\u00e0) may need manual correction</li> <li>Long compound sentences benefit from formatting</li> </ul>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#spanish_1","title":"Spanish","text":"<ul> <li>Accents and \u00f1 are well recognized</li> <li>Regional variations (Spain vs Latin America) work well</li> <li>Inverted question marks may need manual addition</li> </ul>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#german","title":"German","text":"<ul> <li>Umlauts (\u00e4, \u00f6, \u00fc, \u00df) are recognized accurately</li> <li>Compound words are usually transcribed correctly</li> <li>Formal/informal you (Sie/du) preserved correctly</li> </ul>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#italian","title":"Italian","text":"<ul> <li>Accents (\u00e0, \u00e8, \u00ec, \u00f2, \u00f9) are well recognized</li> <li>Double consonants are usually correct</li> <li>Regional variations work well</li> </ul>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#performance-by-language","title":"Performance by Language","text":"<p>All supported languages have similar processing times:</p> Language Avg Processing Time Accuracy English 1.5-2.5s per 30s 95-98% French 1.5-2.5s per 30s 93-97% Spanish 1.5-2.5s per 30s 93-97% German 1.5-2.5s per 30s 92-96% Italian 1.5-2.5s per 30s 93-97%","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#adding-more-languages","title":"Adding More Languages","text":"<p>While only 5 languages have strong enforcement prompts, Whisper supports many more:</p> <p>Other supported codes: <code>ja</code>, <code>zh</code>, <code>pt</code>, <code>ru</code>, <code>ko</code>, <code>ar</code>, <code>nl</code>, <code>pl</code>, <code>tr</code>, etc.</p> <p>To use unsupported language:</p> <pre><code>{\n  \"language\": \"pt\",\n  \"transcriptionPrompt\": \"Transcribe this Portuguese audio completely in Portuguese. Do not switch languages.\",\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\"\n    }\n  }\n}\n</code></pre> <p>Community Contributions</p> <p>If you use Voice Transcriber in other languages and develop effective prompts, please contribute them via GitHub Pull Request!</p>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/language-support/#next-steps","title":"Next Steps","text":"<ul> <li>Basic Usage - Learn recording workflow</li> <li>Configuration Guide - Custom prompts and settings</li> <li>Transcription Backends - OpenAI vs Speaches</li> </ul> <p>Need Help?</p> <ul> <li>Troubleshooting Guide</li> <li>GitHub Issues</li> </ul>","tags":["intermediate","guide","languages","transcription"]},{"location":"user-guide/transcription-backends/","title":"Transcription Backends","text":"<p>Voice Transcriber supports two transcription backends: OpenAI Whisper (cloud) and Speaches (self-hosted).</p>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#backend-comparison","title":"Backend Comparison","text":"Feature OpenAI Whisper \u2601\ufe0f Speaches \ud83c\udfe0 Setup Zero setup Docker required Cost ~$0.006/minute Free (self-hosted) Privacy Audio sent to OpenAI 100% offline Speed Very fast (1.5-2.5s/30s) Comparable with base model Accuracy Excellent (95-98%) Excellent (91-100%) Internet Required Not required","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#openai-whisper-cloud","title":"OpenAI Whisper (Cloud)","text":"<p>Best for: Quick setup, occasional use, no local resources</p>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#configuration","title":"Configuration","text":"<pre><code>{\n  \"language\": \"en\",\n  \"transcription\": {\n    \"backend\": \"openai\"\n  }\n}\n</code></pre>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#pros","title":"Pros","text":"<ul> <li>\u2705 Zero setup required</li> <li>\u2705 No local resources needed</li> <li>\u2705 Consistently fast processing</li> <li>\u2705 High accuracy across languages</li> </ul>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#cons","title":"Cons","text":"<ul> <li>\u274c Requires internet connection</li> <li>\u274c API costs ($0.006 per minute of audio)</li> <li>\u274c Audio data sent to OpenAI servers</li> <li>\u274c Subject to OpenAI API rate limits</li> </ul>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#speaches-self-hosted","title":"Speaches (Self-Hosted)","text":"<p>Best for: Privacy-conscious users, high-volume use, offline operation</p> <p>Powered by Speaches - OpenAI-compatible speech-to-text server</p>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#quick-setup-3-commands","title":"Quick Setup (3 commands)","text":"<pre><code># 1. Create docker-compose.speaches.yml\ndocker compose -f docker-compose.speaches.yml up -d\n\n# 2. Update config\nnano ~/.config/voice-transcriber/config.json\n# Change \"backend\": \"openai\" to \"backend\": \"speaches\"\n\n# 3. Done! First transcription downloads model (~140MB)\n</code></pre>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#configuration_1","title":"Configuration","text":"<pre><code>{\n  \"language\": \"fr\",\n  \"activePersonalities\": [\"builtin:default\"],\n  \"transcription\": {\n    \"backend\": \"speaches\",\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"apiKey\": \"none\",\n      \"model\": \"Systran/faster-whisper-base\"\n    }\n  },\n  \"formatter\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\"\n    }\n  }\n}\n</code></pre>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#pros_1","title":"Pros","text":"<ul> <li>\u2705 Zero cost - No API fees</li> <li>\u2705 Complete privacy - Audio never leaves your machine</li> <li>\u2705 Offline operation - No internet required after model download</li> <li>\u2705 Same speed - Base model comparable to OpenAI (3.7s vs 3.8s)</li> <li>\u2705 High accuracy - 91-100% similarity depending on model</li> </ul>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#cons_1","title":"Cons","text":"<ul> <li>\u274c Requires Docker setup</li> <li>\u274c Initial model download (~140MB-2.9GB depending on model)</li> <li>\u274c Requires local compute resources</li> <li>\u274c Larger models need more RAM/CPU</li> </ul>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#performance-comparison","title":"Performance Comparison","text":"<p>Benchmark: 30s French audio, Remote server (8 CPU / 8GB RAM)</p> Model OpenAI Speaches (CPU) Speed Ratio Accuracy tiny 1.98s 2.81s 0.70x 92.4% base \u2b50 3.70s 3.81s 0.97x 91.4% small 2.23s 7.15s 0.31x 97.4% medium 3.70s 25.82s 0.14x 96.1% large-v3 2.55s 30.80s 0.08x 100.0% <p>Recommendation: Base Model</p> <p>The base model offers the best balance: nearly identical speed to OpenAI, 91% accuracy, and zero cost.</p>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#choosing-a-backend","title":"Choosing a Backend","text":"","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#use-openai-whisper-if","title":"Use OpenAI Whisper if:","text":"<ul> <li>\ud83d\udcf1 You want zero setup and immediate use</li> <li>\ud83c\udf10 You always have internet connection</li> <li>\ud83d\udcb5 Cost is acceptable for your usage volume</li> <li>\ud83c\udfaf You prioritize convenience over privacy</li> </ul>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#use-speaches-if","title":"Use Speaches if:","text":"<ul> <li>\ud83d\udd12 Privacy is important (audio never leaves your machine)</li> <li>\ud83d\udcb0 You transcribe frequently (avoid API costs)</li> <li>\ud83d\udcf4 You need offline operation</li> <li>\ud83c\udfe0 You have local compute resources (or can spin up a VPS)</li> </ul>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#switching-backends","title":"Switching Backends","text":"","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#openai-speaches","title":"OpenAI \u2192 Speaches","text":"<pre><code># 1. Setup Speaches with Docker\ndocker compose -f docker-compose.speaches.yml up -d\n\n# 2. Update config\nnano ~/.config/voice-transcriber/config.json\n</code></pre> <p>Change: <pre><code>{\n  \"transcription\": {\n    \"backend\": \"speaches\"\n  }\n}\n</code></pre></p> <p>Restart the application.</p>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#speaches-openai","title":"Speaches \u2192 OpenAI","text":"<pre><code># Update config\nnano ~/.config/voice-transcriber/config.json\n</code></pre> <p>Change: <pre><code>{\n  \"language\": \"en\",\n  \"activePersonalities\": [\"builtin:default\"],\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-your-api-key-here\"\n    }\n  },\n  \"formatter\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-your-api-key-here\"\n    }\n  }\n}\n</code></pre></p> <p>Restart the application.</p>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#benchmark-mode","title":"Benchmark Mode","text":"<p>Compare both backends side-by-side. Requires both OpenAI and Speaches configured.</p>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#configuration_2","title":"Configuration","text":"<pre><code>{\n  \"benchmarkMode\": true,\n  \"transcription\": {\n    \"backend\": \"speaches\",\n    \"openai\": {\n      \"apiKey\": \"sk-...\",\n      \"model\": \"whisper-1\"\n    },\n    \"speaches\": {\n      \"url\": \"http://localhost:8000/v1\",\n      \"apiKey\": \"none\",\n      \"model\": \"Systran/faster-whisper-base\"\n    }\n  }\n}\n</code></pre>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#running-benchmarks","title":"Running Benchmarks","text":"<p>Run with <code>--debug</code> flag to see detailed comparison:</p> <pre><code>voice-transcriber --debug\n</code></pre>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#benchmark-output","title":"Benchmark Output","text":"<p>Example output: <pre><code>\ud83d\udd2c BENCHMARK: Comparing OpenAI and Speaches\n\u23f1\ufe0f  Performance:\n   OpenAI Whisper:   2.45s\n   Speaches:         0.87s\n   Speedup:          2.82x faster\n\n\ud83d\udccf Text Length:\n   OpenAI:   142 chars\n   Speaches: 145 chars\n   Difference: 3 chars (2.1%)\n\n\ud83c\udfaf Similarity: 97.2% match\n</code></pre></p>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#what-benchmark-mode-does","title":"What Benchmark Mode Does","text":"<p>When enabled, the application:</p> <ol> <li>Transcribes with both backends simultaneously</li> <li>Measures performance - Processing time for each backend</li> <li>Compares accuracy - Text similarity calculation between results</li> <li>Shows differences - Character count and text length comparison</li> <li>Uses primary backend result - The configured <code>backend</code> result is copied to clipboard</li> </ol>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#use-cases","title":"Use Cases","text":"<p>When to Use Benchmark Mode</p> <ul> <li>Evaluate models: Test different Speaches models against OpenAI</li> <li>Verify accuracy: Ensure Speaches meets your quality requirements</li> <li>Optimize performance: Find the best speed/accuracy balance</li> <li>Document results: Generate comparison data for your use case</li> </ul>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#disabling-benchmark-mode","title":"Disabling Benchmark Mode","text":"<p>Set to <code>false</code> in config:</p> <pre><code>{\n  \"benchmarkMode\": false\n}\n</code></pre> <p>Restart the application for changes to take effect.</p> <p>Benchmark Mode Costs</p> <p>Benchmark mode calls both OpenAI and Speaches, so you'll incur OpenAI API costs even when using Speaches as your primary backend. Use only for testing and evaluation.</p>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/transcription-backends/#next-steps","title":"Next Steps","text":"<ul> <li>Speaches Integration Guide - Detailed setup</li> <li>Whisper Models Comparison - Model selection</li> <li>Configuration Guide - Advanced settings</li> </ul> <p>Need Help?</p> <ul> <li>Troubleshooting Guide</li> <li>GitHub Issues</li> </ul>","tags":["intermediate","guide","backends","transcription","integration"]},{"location":"user-guide/troubleshooting/","title":"Voice Transcriber - Troubleshooting Guide","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#quick-diagnostics","title":"Quick Diagnostics","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#first-steps-for-any-issue","title":"First Steps for Any Issue","text":"<pre><code># 1. Check system dependencies\nmake check-deps\n\n# 2. Verify configuration\ncat ~/.config/voice-transcriber/config.json\n\n# 3. Check recent logs\nmake dev  # Watch console output\n\n# 4. Test with minimal setup\nmake test\n</code></pre>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#health-check-commands","title":"Health Check Commands","text":"<pre><code># System Dependencies\nwhich arecord    # Should return /usr/bin/arecord\nwhich xsel       # Should return /usr/bin/xsel\narecord -l       # List audio devices\n\n# Application Status\nmake run         # Check startup logs\nls -la ~/.config/voice-transcriber/  # Check config directory\nls -la /tmp/transcriber/  # Check temp files\n</code></pre>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#application-wont-start","title":"\ud83d\udea8 Application Won't Start","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom","title":"Symptom","text":"<pre><code>$ make run\nFailed to start: OpenAI API key not configured\n</code></pre> <p>Solution 1: Missing API Key <pre><code># Check configuration\ncat ~/.config/voice-transcriber/config.json\n\n# If file missing or empty, add API key:\n{\n  \"language\": \"en\",\n  \"formatterEnabled\": true,\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"sk-your-api-key-here\"\n    }\n  }\n}\n\n# Get API key from: https://platform.openai.com/api-keys\n</code></pre></p> <p>Solution 2: Invalid Configuration Format <pre><code># Validate JSON format\ncat ~/.config/voice-transcriber/config.json | jq .\n\n# If JSON is invalid, recreate:\nrm ~/.config/voice-transcriber/config.json\nmake run  # Will trigger setup wizard\n</code></pre></p> <p>Solution 3: Permission Issues <pre><code># Check directory permissions\nls -la ~/.config/voice-transcriber/\n\n# Fix permissions if needed\nchmod 755 ~/.config/voice-transcriber/\nchmod 600 ~/.config/voice-transcriber/config.json\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#system-tray-not-visible","title":"\ud83d\udd07 System Tray Not Visible","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_1","title":"Symptom","text":"<p>App starts successfully but no tray icon appears.</p> <p>Solution 1: Desktop Environment Check <pre><code># Check desktop environment\necho $XDG_CURRENT_DESKTOP\n\n# Known working environments:\n# - GNOME (with gnome-shell-extension-appindicator)\n# - KDE Plasma\n# - XFCE with xfce4-indicator-plugin\n# - MATE\n</code></pre></p> <p>Solution 2: Install System Tray Support <pre><code># GNOME - Install AppIndicator extension\n# Via GNOME Extensions website or:\nsudo apt install gnome-shell-extension-appindicator\n\n# XFCE - Install indicator plugin\nsudo apt install xfce4-indicator-plugin\n\n# After installation, restart desktop session\n</code></pre></p> <p>Solution 3: Alternative Desktop Environments <pre><code># Some minimal window managers don't support system trays\n# Try running with stalonetray or similar:\nsudo apt install stalonetray\nstalonetray &amp;  # Run in background\nmake run       # Then start voice transcriber\n</code></pre></p> <p>Solution 4: Check Tray Area - Look in different corners of your screen - Try right-clicking in the system tray area - Check if icons are hidden in an overflow menu - Some desktop themes hide the system tray by default</p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#audio-recording-issues","title":"\ud83c\udfa4 Audio Recording Issues","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_2","title":"Symptom","text":"<pre><code>Recording failed: Failed to start recording: spawn arecord ENOENT\n</code></pre> <p>Solution 1: Install ALSA Utils <pre><code># Install required audio tools\nsudo apt-get update\nsudo apt-get install alsa-utils\n\n# Verify installation\nwhich arecord  # Should return /usr/bin/arecord\narecord --version\n</code></pre></p> <p>Solution 2: Audio Device Configuration <pre><code># List available audio devices\narecord -l\n\n# Test recording manually\narecord -D default -f cd -t wav /tmp/test.wav\n# Speak for a few seconds, then Ctrl+C\n\n# Play back to verify\naplay /tmp/test.wav\n</code></pre></p> <p>Solution 3: Permission Issues <pre><code># Add user to audio group\nsudo usermod -a -G audio $USER\n\n# Logout and login again for changes to take effect\n# Or run: newgrp audio\n\n# Verify group membership\ngroups | grep audio\n</code></pre></p> <p>Solution 4: PulseAudio Configuration <pre><code># If using PulseAudio, check status\npulseaudio --check -v\n\n# Restart PulseAudio if needed\npulseaudio -k\npulseaudio --start\n\n# Test with PulseAudio-specific device\narecord -D pulse -f cd -t wav /tmp/test-pulse.wav\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_3","title":"Symptom","text":"<p>Recording starts but no audio is captured (empty/silent files).</p> <p>Solution 1: Microphone Level <pre><code># Open audio mixer\nalsamixer\n\n# Navigate to microphone/capture controls\n# Press Tab to switch to capture view\n# Use arrow keys to adjust levels\n# Ensure microphone is not muted (no MM indicator)\n</code></pre></p> <p>Solution 2: Default Input Device <pre><code># Check default input device\ncat /proc/asound/cards\n\n# Set specific device in arecord command\n# Edit src/services/audio-recorder.ts if needed:\n# Change \"-D\", \"default\" to \"-D\", \"hw:1,0\" (for example)\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#api-connection-issues","title":"\ud83c\udf10 API Connection Issues","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_4","title":"Symptom","text":"<pre><code>Transcription failed: Failed to transcribe audio: Request failed with status 401\n</code></pre> <p>Solution 1: Invalid API Key <pre><code># Test API key manually\ncurl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  https://api.openai.com/v1/models\n\n# Should return list of models, not error\n# If error, get new API key from: https://platform.openai.com/api-keys\n</code></pre></p> <p>Solution 2: Rate Limiting <pre><code># Check OpenAI usage dashboard\n# Visit: https://platform.openai.com/usage\n\n# Wait for rate limit reset or upgrade plan\n# Monitor usage to avoid limits\n</code></pre></p> <p>Solution 3: Network Issues <pre><code># Test connectivity\ncurl -I https://api.openai.com\n\n# Check proxy settings if behind corporate firewall\necho $HTTP_PROXY\necho $HTTPS_PROXY\n\n# Configure proxy in environment if needed\nexport HTTPS_PROXY=http://proxy.company.com:8080\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_5","title":"Symptom","text":"<pre><code>Transcription failed: Network timeout\n</code></pre> <p>Solution: Network Configuration <pre><code># Increase timeout (if needed, modify transcription service)\n# Check network stability\nping -c 4 api.openai.com\n\n# Test with smaller audio files first\n# Large files may timeout on slow connections\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#clipboard-issues","title":"\ud83d\udccb Clipboard Issues","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_6","title":"Symptom","text":"<pre><code>Clipboard failed: Failed to write to clipboard: xsel: command not found\n</code></pre> <p>Solution 1: Install Clipboard Tools <pre><code># Install xsel (preferred) or xclip\nsudo apt-get install xsel\n\n# Or alternative:\nsudo apt-get install xclip\n\n# Verify installation\nwhich xsel\n</code></pre></p> <p>Solution 2: Display Environment <pre><code># Ensure DISPLAY is set for X11\necho $DISPLAY  # Should show :0 or similar\n\n# For Wayland, some clipboard tools need special handling\n# Try wl-clipboard instead:\nsudo apt-get install wl-clipboard\n</code></pre></p> <p>Solution 3: Permission Issues <pre><code># Test clipboard manually\necho \"test\" | xsel -ib  # Copy to clipboard\nxsel -ob               # Paste from clipboard\n\n# Should echo \"test\" if working correctly\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#system-performance-issues","title":"\ud83d\udd04 System Performance Issues","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_7","title":"Symptom","text":"<p>High memory usage or slow performance.</p> <p>Solution 1: Monitor Resource Usage <pre><code># Monitor while running\nhtop\n# Look for voice-transcriber process\n\n# Check memory usage\nps aux | grep voice-transcriber\n\n# Monitor disk I/O\niotop\n</code></pre></p> <p>Solution 2: Cleanup Temporary Files <pre><code># Clean temp directory\nrm -rf /tmp/transcriber/*\n\n# Set cleanup cron job if needed\ncrontab -e\n# Add: 0 2 * * * rm -rf /tmp/transcriber/*\n</code></pre></p> <p>Solution 3: Reduce Resource Usage <pre><code># Disable text formatting to reduce API calls\n# Edit ~/.config/voice-transcriber/config.json:\n{\n  \"formatterEnabled\": false,\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": {\n      \"apiKey\": \"your-key\"\n    }\n  }\n}\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#development-issues","title":"\ud83d\udd27 Development Issues","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_8","title":"Symptom","text":"<pre><code>$ make test\nCommand not found: bun\n</code></pre> <p>Solution 1: Install Bun <pre><code># Install Bun runtime\ncurl -fsSL https://bun.sh/install | bash\n\n# Reload shell\nsource ~/.bashrc  # or restart terminal\n\n# Verify installation\nbun --version\n</code></pre></p> <p>Solution 2: Use Node.js Alternative <pre><code># If Bun unavailable, use Node.js\nnpm install\nnpm test\nnpm run dev\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_9","title":"Symptom","text":"<pre><code>Tests failing with mock errors\n</code></pre> <p>Solution: Reset Development Environment <pre><code># Clean and reinstall\nmake clean\nrm -rf node_modules\nmake install\n\n# Run tests individually to isolate issues\nmake test-file FILE=src/services/system-tray.test.ts\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#build-and-distribution-issues","title":"\ud83d\udce6 Build and Distribution Issues","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_10","title":"Symptom","text":"<pre><code>Build fails with missing dependencies\n</code></pre> <p>Solution 1: Dependency Issues <pre><code># Verify all dependencies installed\nbun install\n\n# Check for peer dependency warnings\nbun install --production=false\n\n# Update dependencies if needed\nbun update\n</code></pre></p> <p>Solution 2: Asset Loading Issues <pre><code># Verify assets are included in build\nls -la dist/\ncat dist/index.js | grep -i icon\n\n# Check asset paths in production\nnode dist/index.js\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#configuration-management-issues","title":"Configuration Management Issues","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#open-config-button-does-nothing","title":"\ud83d\udd27 \"Open Config\" Button Does Nothing","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_11","title":"Symptom","text":"<p>Clicking \"Open Config\" in the system tray menu has no visible effect.</p> <p>Solution 1: Default Text Editor Not Configured <pre><code># Check if xdg-open is working\nxdg-open ~/.config/voice-transcriber/config.json\n\n# If it fails, set default text editor\nxdg-mime default org.gnome.gedit.desktop text/plain\n# Or for other editors:\nxdg-mime default code.desktop text/plain  # VS Code\n</code></pre></p> <p>Solution 2: Configuration File Missing <pre><code># Check if file exists\nls -la ~/.config/voice-transcriber/config.json\n\n# If missing, run setup wizard\nrm -rf ~/.config/voice-transcriber/\nmake run  # Triggers first-run setup\n</code></pre></p> <p>Solution 3: File Permissions <pre><code># Check file permissions\nls -la ~/.config/voice-transcriber/\n\n# Fix if needed\nchmod 644 ~/.config/voice-transcriber/config.json\nchmod 755 ~/.config/voice-transcriber/\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#reload-config-button-always-disabled","title":"\ud83d\udd04 \"Reload Config\" Button Always Disabled","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_12","title":"Symptom","text":"<p>The \"Reload Config\" menu item is always grayed out.</p> <p>Solution: Application Not in Idle State</p> <p>The reload button is only enabled when idle (green icon). It's disabled during:</p> <ul> <li>Recording (\ud83d\udd34): Would interrupt audio capture</li> <li>Processing (\ud83d\udfe3): Would interfere with transcription</li> </ul> <p>How to enable reload: 1. Wait for current operation to complete 2. Ensure tray icon is green (idle) 3. Right-click and check if \"Reload Config\" is now enabled</p> <p>Check application state: <pre><code># Run in debug mode to see state changes\nvoice-transcriber --debug\n# Watch for: \"State changed from X to idle\"\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#reload-failed-invalid-configuration","title":"\u274c Reload Failed: Invalid Configuration","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_13","title":"Symptom","text":"<pre><code>Failed to reload configuration: API key not configured for openai backend\n</code></pre> <p>Solution: Validate Configuration Before Reload</p> <p>Validation Checklist: <pre><code>{\n  \"language\": \"en\",              // \u2705 Required\n  \"formatterEnabled\": true,      // \u2705 Required\n  \"transcription\": {             // \u2705 Required\n    \"backend\": \"openai\",         // \u2705 Required: \"openai\" or \"speaches\"\n    \"openai\": {\n      \"apiKey\": \"sk-proj-...\"    // \u2705 Required if backend=openai\n    }\n  }\n}\n</code></pre></p> <p>Common validation errors:</p> <ol> <li> <p>Missing API Key <pre><code>// \u274c Wrong\n{ \"transcription\": { \"backend\": \"openai\" } }\n\n// \u2705 Correct\n{\n  \"transcription\": {\n    \"backend\": \"openai\",\n    \"openai\": { \"apiKey\": \"sk-proj-...\" }\n  }\n}\n</code></pre></p> </li> <li> <p>Invalid Backend <pre><code>// \u274c Wrong\n{ \"transcription\": { \"backend\": \"whisper\" } }\n\n// \u2705 Correct\n{ \"transcription\": { \"backend\": \"openai\" } }\n// or\n{ \"transcription\": { \"backend\": \"speaches\" } }\n</code></pre></p> </li> <li> <p>Invalid JSON Syntax <pre><code># Validate JSON before reload\ncat ~/.config/voice-transcriber/config.json | jq .\n# If it shows errors, fix syntax\n</code></pre></p> </li> </ol>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#configuration-reloaded-but-changes-not-taking-effect","title":"\ud83d\udd01 Configuration Reloaded But Changes Not Taking Effect","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_14","title":"Symptom","text":"<p>Changed configuration and reloaded, but application still uses old settings.</p> <p>Solution 1: Check Configuration Syntax <pre><code># Verify your changes were saved\ncat ~/.config/voice-transcriber/config.json\n\n# Validate JSON\njq . ~/.config/voice-transcriber/config.json\n</code></pre></p> <p>Solution 2: Invalid Configuration Values</p> <p>Some values may be ignored if invalid: <pre><code>// \u274c Invalid language (will use default \"en\")\n{ \"language\": \"japanese\" }\n\n// \u2705 Supported languages only\n{ \"language\": \"fr\" }  // fr, en, es, de, it\n</code></pre></p> <p>Solution 3: Service Initialization Failed</p> <p>Check console for errors: <pre><code># Run in debug mode\nvoice-transcriber --debug\n\n# Look for error messages like:\n# \"Failed to reload configuration: ...\"\n# \"Rolling back to previous configuration...\"\n</code></pre></p> <p>Solution 4: Reload Was Rolled Back</p> <p>If configuration validation failed, the reload was automatically rolled back:</p> <ol> <li>Check console logs for error message</li> <li>Fix the configuration issue</li> <li>Save the file</li> <li>Try reload again</li> </ol>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#application-crashes-after-reload","title":"\ud83d\udca5 Application Crashes After Reload","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#symptom_15","title":"Symptom","text":"<p>Application exits unexpectedly after clicking \"Reload Config\".</p> <p>Solution 1: Check Recent Changes</p> <p>Reload automatically rolls back on error, but if crash persists:</p> <pre><code># Restore backup if you have one\ncp ~/.config/voice-transcriber/config.json.bak \\\n   ~/.config/voice-transcriber/config.json\n\n# Or reset to defaults\nrm ~/.config/voice-transcriber/config.json\nmake run  # Triggers setup wizard\n</code></pre> <p>Solution 2: Debug the Crash <pre><code># Run with debug logging\nvoice-transcriber --debug 2&gt;&amp;1 | tee crash.log\n\n# Try reload\n# After crash, check crash.log for error details\n</code></pre></p> <p>Solution 3: Report the Bug</p> <p>If crash persists with valid configuration:</p> <ol> <li>Save your configuration file</li> <li>Save debug logs</li> <li>Report issue at: GitHub Issues</li> <li>Include:</li> <li>Configuration file (remove API keys!)</li> <li>Debug logs</li> <li>Steps to reproduce</li> </ol>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#best-practices-for-configuration-changes","title":"\ud83d\udcdd Best Practices for Configuration Changes","text":"<p>To avoid issues when modifying configuration:</p> <ol> <li> <p>Test Changes Incrementally <pre><code># Change one setting at a time\n# Reload and test\n# If works, change next setting\n</code></pre></p> </li> <li> <p>Validate JSON Before Reload <pre><code># Always validate after editing\njq . ~/.config/voice-transcriber/config.json\n</code></pre></p> </li> <li> <p>Keep Backups <pre><code># Backup before major changes\ncp ~/.config/voice-transcriber/config.json \\\n   ~/.config/voice-transcriber/config.json.bak\n</code></pre></p> </li> <li> <p>Use Reload During Idle</p> </li> <li>Wait for green icon (idle state)</li> <li>Don't reload during recording or processing</li> <li> <p>Check console for reload success message</p> </li> <li> <p>Monitor Logs <pre><code># Watch logs during reload\nvoice-transcriber --debug\n# Look for: \"\u2705 Configuration reloaded successfully\"\n</code></pre></p> </li> </ol>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#advanced-troubleshooting","title":"Advanced Troubleshooting","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed logging for debugging:</p> <pre><code>// Temporary debug logging in services\nconsole.log(\"Debug: service state\", { variable, state });\n\n// Or modify logger to show debug messages\n// In src/utils/logger.ts, add debug level\n</code></pre>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#system-integration-testing","title":"System Integration Testing","text":"<pre><code># Test each component independently\n\n# 1. Test audio recording\narecord -D default -f cd -t wav /tmp/manual-test.wav\n# Speak for 5 seconds, then Ctrl+C\n\n# 2. Test API connection\ncurl -X POST https://api.openai.com/v1/audio/transcriptions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/tmp/manual-test.wav\" \\\n  -F model=\"whisper-1\"\n\n# 3. Test clipboard\necho \"test clipboard\" | xsel -ib\nxsel -ob  # Should output \"test clipboard\"\n</code></pre>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#log-analysis","title":"Log Analysis","text":"<pre><code># Capture detailed logs\nmake dev 2&gt;&amp;1 | tee debug.log\n\n# Analyze patterns\ngrep -i error debug.log\ngrep -i failed debug.log\ngrep -i timeout debug.log\n\n# Monitor in real-time\ntail -f debug.log | grep -E \"(error|failed|timeout)\"\n</code></pre>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#network-debugging","title":"Network Debugging","text":"<pre><code># Monitor network traffic\nsudo tcpdump -i any host api.openai.com\n\n# Check DNS resolution\nnslookup api.openai.com\n\n# Test with verbose curl\ncurl -v https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n</code></pre>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#error-codes-reference","title":"Error Codes Reference","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#application-error-codes","title":"Application Error Codes","text":"<ul> <li><code>OpenAI API key not configured</code>: Missing or empty API key in config</li> <li><code>System tray failed</code>: Desktop environment doesn't support system tray</li> <li><code>Recording failed</code>: Audio system not available or misconfigured</li> <li><code>Transcription failed</code>: API error or network issue</li> <li><code>Clipboard failed</code>: Clipboard tools not installed or display issue</li> </ul>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#exit-codes","title":"Exit Codes","text":"<ul> <li><code>0</code>: Normal exit</li> <li><code>1</code>: Configuration error or initialization failure</li> <li><code>130</code>: Interrupted by user (Ctrl+C)</li> </ul>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#log-message-patterns","title":"Log Message Patterns","text":"<pre><code># Normal operation\n[INFO] Voice Transcriber initialized successfully\n[INFO] Starting recording...\n[INFO] Transcribing audio...\n[INFO] Text copied to clipboard successfully\n\n# Error patterns\n[ERROR] Recording failed: ...\n[ERROR] Transcription failed: ...\n[ERROR] Clipboard failed: ...\n[ERROR] System tray failed: ...\n</code></pre>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#getting-help","title":"Getting Help","text":"","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#before-reporting-issues","title":"Before Reporting Issues","text":"<ol> <li>Check Known Issues: Review this troubleshooting guide</li> <li>Test Basic Functionality: Run <code>make test</code> and <code>make check-deps</code></li> <li>Gather System Information:    <pre><code># System info\nuname -a\nlsb_release -a\necho $XDG_CURRENT_DESKTOP\n\n# Audio info\narecord -l\npactl info  # If using PulseAudio\n\n# Application info\nbun --version\nmake get-version\n</code></pre></li> </ol>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#issue-reporting-template","title":"Issue Reporting Template","text":"<p>When reporting issues, include:</p> <p><pre><code>**Environment:**\n- OS: Ubuntu 22.04\n- Desktop: GNOME 42\n- Bun version: 1.2.0\n- Audio system: PulseAudio\n\n**Issue:**\nBrief description of the problem\n\n**Steps to Reproduce:**\n1. Step one\n2. Step two\n3. Step three\n\n**Expected Behavior:**\nWhat should happen\n\n**Actual Behavior:**\nWhat actually happens\n\n**Logs:**\n</code></pre> Paste relevant log output here <pre><code>**System Check:**\n</code></pre> Output of: make check-deps <pre><code>\n</code></pre></p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#community-resources","title":"Community Resources","text":"<ul> <li>GitHub Issues: https://github.com/Nouuu/voice-transcriber/issues</li> <li>Documentation: https://github.com/Nouuu/voice-transcriber#readme</li> <li>npm Package: https://www.npmjs.com/package/voice-transcriber</li> </ul> <p>This troubleshooting guide covers the most common issues encountered with Voice Transcriber. Most problems can be resolved by following these step-by-step solutions.</p>","tags":["troubleshooting","reference","debugging"]},{"location":"user-guide/troubleshooting/#related-pages","title":"Related Pages","text":"<ul> <li>Installation Guide - System dependencies and setup</li> <li>Configuration Guide - Configuration options and validation</li> <li>Debug Mode - Advanced debugging and performance analysis</li> <li>Basic Usage - How to use Voice Transcriber effectively</li> </ul>","tags":["troubleshooting","reference","debugging"]}]}